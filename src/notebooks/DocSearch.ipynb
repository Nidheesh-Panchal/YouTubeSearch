{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# DocSearch\n",
        "\n",
        "Experimental"
      ],
      "metadata": {
        "id": "T2V4GcAfFfw4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gp8yV9EvF3HY",
        "outputId": "9f586978-9669-4df2-8bd0-fbd56849dca2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU huggingface_hub\n",
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gp9oq-UXRtE5",
        "outputId": "4a9552dc-e27c-4180-8db4-76ce45be741e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers\n",
            "  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, safetensors, transformers\n",
            "Successfully installed safetensors-0.3.1 tokenizers-0.13.3 transformers-4.30.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install faiss-cpu\n",
        "#Gives so much trouble this chromadb\n",
        "# !pip install chromadb\n",
        "# !pip install \"docarray\"\n",
        "!pip install lark qdrant-client"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esm7LumFEq8r",
        "outputId": "787e9fdd-4a2c-4296-dba6-def36da06418"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lark\n",
            "  Downloading lark-1.1.5-py3-none-any.whl (107 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting qdrant-client\n",
            "  Downloading qdrant_client-1.3.1-py3-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.9/132.9 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.41.0 in /usr/local/lib/python3.10/dist-packages (from qdrant-client) (1.56.0)\n",
            "Collecting grpcio-tools>=1.41.0 (from qdrant-client)\n",
            "  Downloading grpcio_tools-1.56.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx[http2]>=0.14.0 (from qdrant-client)\n",
            "  Downloading httpx-0.24.1-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/dist-packages (from qdrant-client) (1.22.4)\n",
            "Collecting portalocker<3.0.0,>=2.7.0 (from qdrant-client)\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: pydantic<2.0,>=1.8 in /usr/local/lib/python3.10/dist-packages (from qdrant-client) (1.10.9)\n",
            "Collecting typing-extensions<4.6.0,>=4.0.0 (from qdrant-client)\n",
            "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: urllib3<2.0.0,>=1.26.14 in /usr/local/lib/python3.10/dist-packages (from qdrant-client) (1.26.16)\n",
            "Collecting protobuf<5.0dev,>=4.21.6 (from grpcio-tools>=1.41.0->qdrant-client)\n",
            "  Downloading protobuf-4.23.4-cp37-abi3-manylinux2014_x86_64.whl (304 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.5/304.5 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from grpcio-tools>=1.41.0->qdrant-client) (67.7.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx[http2]>=0.14.0->qdrant-client) (2023.5.7)\n",
            "Collecting httpcore<0.18.0,>=0.15.0 (from httpx[http2]>=0.14.0->qdrant-client)\n",
            "  Downloading httpcore-0.17.3-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx[http2]>=0.14.0->qdrant-client) (3.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx[http2]>=0.14.0->qdrant-client) (1.3.0)\n",
            "Collecting h2<5,>=3 (from httpx[http2]>=0.14.0->qdrant-client)\n",
            "  Downloading h2-4.1.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hyperframe<7,>=6.0 (from h2<5,>=3->httpx[http2]>=0.14.0->qdrant-client)\n",
            "  Downloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\n",
            "Collecting hpack<5,>=4.0 (from h2<5,>=3->httpx[http2]>=0.14.0->qdrant-client)\n",
            "  Downloading hpack-4.0.0-py3-none-any.whl (32 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore<0.18.0,>=0.15.0->httpx[http2]>=0.14.0->qdrant-client)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx[http2]>=0.14.0->qdrant-client) (3.7.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->httpcore<0.18.0,>=0.15.0->httpx[http2]>=0.14.0->qdrant-client) (1.1.1)\n",
            "Installing collected packages: lark, typing-extensions, protobuf, portalocker, hyperframe, hpack, h11, httpcore, h2, grpcio-tools, httpx, qdrant-client\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.6.3\n",
            "    Uninstalling typing_extensions-4.6.3:\n",
            "      Successfully uninstalled typing_extensions-4.6.3\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "Successfully installed grpcio-tools-1.56.0 h11-0.14.0 h2-4.1.0 hpack-4.0.0 httpcore-0.17.3 httpx-0.24.1 hyperframe-6.0.1 lark-1.1.5 portalocker-2.7.0 protobuf-4.23.4 qdrant-client-1.3.1 typing-extensions-4.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence_transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vjag9qdmc8s",
        "outputId": "70fa4545-ac52-4b89-a9ee-be12974c4d26"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentence_transformers\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/86.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.30.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.65.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.15.2+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.22.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.10.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (3.8.1)\n",
            "Collecting sentencepiece (from sentence_transformers)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.16.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.12.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.27.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (23.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence_transformers) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence_transformers) (16.0.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2022.10.31)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.3.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence_transformers) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence_transformers) (2.1.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence_transformers) (1.3.0)\n",
            "Building wheels for collected packages: sentence_transformers\n",
            "  Building wheel for sentence_transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence_transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125926 sha256=2922e3ac5512917f7d4d4a7380a32a83e8fa8cf4e6d41bf2100fcfeff3dd1c20\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
            "Successfully built sentence_transformers\n",
            "Installing collected packages: sentencepiece, sentence_transformers\n",
            "Successfully installed sentence_transformers-2.2.2 sentencepiece-0.1.99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QsUJP8rXZ84",
        "outputId": "000ca4a4-5347-46d1-8907-61b9005d4e91"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install youtube-transcript-api\n",
        "!pip install pytube\n",
        "\n",
        "!pip install yt_dlp\n",
        "!pip install pydub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69C1gEBljtj3",
        "outputId": "36728aea-18c7-4191-e9fd-94ab6de62e4d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting youtube-transcript-api\n",
            "  Downloading youtube_transcript_api-0.6.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from youtube-transcript-api) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (3.4)\n",
            "Installing collected packages: youtube-transcript-api\n",
            "Successfully installed youtube-transcript-api-0.6.1\n",
            "Collecting pytube\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytube\n",
            "Successfully installed pytube-15.0.0\n",
            "Collecting yt_dlp\n",
            "  Downloading yt_dlp-2023.7.6-py2.py3-none-any.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mutagen (from yt_dlp)\n",
            "  Downloading mutagen-1.46.0-py3-none-any.whl (193 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycryptodomex (from yt_dlp)\n",
            "  Downloading pycryptodomex-3.18.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets (from yt_dlp)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from yt_dlp) (2023.5.7)\n",
            "Collecting brotli (from yt_dlp)\n",
            "  Downloading Brotli-1.0.9-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m74.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: brotli, websockets, pycryptodomex, mutagen, yt_dlp\n",
            "Successfully installed brotli-1.0.9 mutagen-1.46.0 pycryptodomex-3.18.0 websockets-11.0.3 yt_dlp-2023.7.6\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv, find_dotenv\n",
        "import os\n",
        "_ = load_dotenv(find_dotenv(filename=\"/content/drive/MyDrive/token/api_token.env\")) # read local .env file\n",
        "\n",
        "# openai.api_key  = os.environ['OPENAI_API_KEY']\n",
        "# os.environ['HUGGINGFACEHUB_API_TOKEN'] = 'HF_API_KEY'"
      ],
      "metadata": {
        "id": "cF988qtvUfZh"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate, HuggingFaceHub, LLMChain\n",
        "\n",
        "flan_t5 = HuggingFaceHub(\n",
        "    repo_id=\"google/flan-t5-large\",\n",
        "    model_kwargs={\"temperature\":1e-10}\n",
        ")"
      ],
      "metadata": {
        "id": "nPHrOCi-Xnhb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"\n",
        "Context: {context}\n",
        "Question: {question}\n",
        "\n",
        "Answer: \"\"\"\n",
        "prompt = PromptTemplate(template=template, input_variables=[\"context\",\"question\"])\n",
        "\n",
        "llm_chain = LLMChain(\n",
        "    prompt=prompt,\n",
        "    llm=flan_t5\n",
        ")"
      ],
      "metadata": {
        "id": "d2zPWiVpbBSB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = {\"context\": \"Sachin Tendulkar is God of cricket.\",\n",
        "         \"question\": \"Who is God of cricket\"}\n",
        "\n",
        "print(llm_chain.run(query))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWt4oCHzYPfs",
        "outputId": "7102ec7f-de11-43b1-9fdc-5066e5dbaa08"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sachin Tendulkar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from transformers import pipeline\n",
        "# too large model\n",
        "# pipe = pipeline(\"automatic-speech-recognition\", \"openai/whisper-large-v2\")\n",
        "# pipe(\"/content/drive/MyDrive/data/LangChain/sample.wav\")"
      ],
      "metadata": {
        "id": "WB0Ctf2wc_o4"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import requests\n",
        "\n",
        "API_TOKEN = os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]\n",
        "headers = {\"Authorization\": f\"Bearer {API_TOKEN}\"}\n",
        "API_URL = \"https://api-inference.huggingface.co/models/openai/whisper-large-v2\"\n",
        "\n",
        "def query(filename):\n",
        "    with open(filename, \"rb\") as f:\n",
        "        data = f.read()\n",
        "    response = requests.request(\"POST\", API_URL, headers=headers, data=data)\n",
        "    return json.loads(response.content.decode(\"utf-8\"))\n",
        "\n",
        "data = query(\"/content/drive/MyDrive/data/LangChain/sample.wav\")"
      ],
      "metadata": {
        "id": "yBx8_OkNehVj"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaMOrPq_goms",
        "outputId": "7f069b18-cd87-4a3b-9a48-b8a8e0fc9e5b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': ' Hello, welcome to Deep Learning AI.'}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Too large model, Colab crashes\n",
        "# from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
        "# processor = WhisperProcessor.from_pretrained(\"openai/whisper-large-v2\")\n",
        "# model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-large-v2\")\n",
        "# model.config.forced_decoder_ids = None"
      ],
      "metadata": {
        "id": "KmEkFJofg1dZ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# input_features = processor(sample[\"array\"], sampling_rate=sample[\"sampling_rate\"], return_tensors=\"pt\").input_features\n",
        "\n",
        "# predicted_ids = model.generate(input_features)\n",
        "# transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)\n",
        "# transcription"
      ],
      "metadata": {
        "id": "TOu78_eKg1bB"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import YoutubeLoader"
      ],
      "metadata": {
        "id": "-qY9SkcAg1Yh"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = YoutubeLoader.from_youtube_url(\n",
        "    \"https://www.youtube.com/watch?v=QsYGlZkevEg\", add_video_info=True\n",
        ")"
      ],
      "metadata": {
        "id": "TXlDc3gLjm15"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader.load()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73YKrZgtjnRU",
        "outputId": "ff89449b-1495-40fe-fdf0-70dbf06965f4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='LADIES AND GENTLEMEN, PEDRO PASCAL! [ CHEERS AND APPLAUSE ] >> THANK YOU, THANK YOU. THANK YOU VERY MUCH. I\\'M SO EXCITED TO BE HERE. THANK YOU. I SPENT THE LAST YEAR SHOOTING A SHOW CALLED \"THE LAST OF US\" ON HBO. FOR SOME HBO SHOES, YOU GET TO SHOOT IN A FIVE STAR ITALIAN RESORT SURROUNDED BY BEAUTIFUL PEOPLE, BUT I SAID, NO, THAT\\'S TOO EASY. I WANT TO SHOOT IN A FREEZING CANADIAN FOREST WHILE BEING CHASED AROUND BY A GUY WHOSE HEAD LOOKS LIKE A GENITAL WART. IT IS AN HONOR BEING A PART OF THESE HUGE FRANCHISEs LIKE \"GAME OF THRONES\" AND \"STAR WARS,\" BUT I\\'M STILL GETTING USED TO PEOPLE RECOGNIZING ME. THE OTHER DAY, A GUY STOPPED ME ON THE STREET AND SAYS, MY SON LOVES \"THE MANDALORIAN\" AND THE NEXT THING I KNOW, I\\'M FACE TIMING WITH A 6-YEAR-OLD WHO HAS NO IDEA WHO I AM BECAUSE MY CHARACTER WEARS A MASK THE ENTIRE SHOW. THE GUY IS LIKE, DO THE MANDO VOICE, BUT IT\\'S LIKE A BEDROOM VOICE. WITHOUT THE MASK, IT JUST SOUNDS PORNY. PEOPLE WALKING BY ON THE STREET SEE ME WHISPERING TO A 6-YEAR-OLD KID. I CAN BRING YOU IN WARM, OR I CAN BRING YOU IN COLD. EVEN THOUGH I CAME TO THE U.S. WHEN I WAS LITTLE, I WAS BORN IN CHILE, AND I HAVE 34 FIRST COUSINS WHO ARE STILL THERE. THEY\\'RE VERY PROUD OF ME. I KNOW THEY\\'RE PROUD BECAUSE THEY GIVE MY PHONE NUMBER TO EVERY PERSON THEY MEET, WHICH MEANS EVERY DAY, SOMEONE IN SANTIAGO WILL TEXT ME STUFF LIKE, CAN YOU COME TO MY WEDDING, OR CAN YOU SING MY PRIEST HAPPY BIRTHDAY, OR IS BABY YODA MEAN IN REAL LIFE. SO I HAVE TO BE LIKE NO, NO, AND HIS NAME IS GROGU. BUT MY COUSINS WEREN\\'T ALWAYS SO PROUD. EARLY IN MY CAREER, I PLAYED SMALL PARTS IN EVERY CRIME SHOW. I EVEN PLAYED TWO DIFFERENT CHARACTERS ON \"LAW AND ORDER.\" TITO CABASSA WHO LOOKED LIKE THIS. AND ONE YEAR LATER, I PLAYED REGGIE LUCKMAN WHO LOOKS LIKE THIS. AND THAT, MY FRIENDS, IS CALLED RANGE. BUT IT IS AMAZING TO BE HERE, LIKE I SAID. I WAS BORN IN CHILE, AND NINE MONTHS LATER, MY PARENTS FLED AND BROUGHT ME AND MY SISTER TO THE U.S. THEY WERE SO BRAVE, AND WITHOUT THEM, I WOULDN\\'T BE HERE IN THIS WONDERFUL COUNTRY, AND I CERTAINLY WOULDN\\'T BE STANDING HERE WITH YOU ALL TONIGHT. SO TO ALL MY FAMILY WATCHING IN CHILE, I WANT TO SAY [ SPEAKING NON-ENGLISH ] WHICH MEANS, I LOVE YOU, I MISS YOU, AND STOP GIVING OUT MY PHONE NUMBER. WE\\'VE GOT AN AMAZING SHOW FOR YOU TONIGHT. COLDPLAY IS HERE, SO STICK', metadata={'source': 'QsYGlZkevEg', 'title': 'Pedro Pascal Monologue - SNL', 'description': 'Unknown', 'view_count': 1743814, 'thumbnail_url': 'https://i.ytimg.com/vi/QsYGlZkevEg/hq720.jpg', 'publish_date': '2023-02-04 00:00:00', 'length': 224, 'author': 'Saturday Night Live'})]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders.generic import GenericLoader\n",
        "from langchain.document_loaders.parsers import OpenAIWhisperParser\n",
        "from langchain.document_loaders.blob_loaders.youtube_audio import YoutubeAudioLoader"
      ],
      "metadata": {
        "id": "aCK0lV8ljpih"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "urls = [\"https://www.youtube.com/watch?v=NgWujOrCZFo\",\n",
        "\"https://www.youtube.com/watch?v=e69ZWbbsGng\",\n",
        "\"https://www.youtube.com/watch?v=YJsRD_hU4tc\",\n",
        "\"https://www.youtube.com/watch?v=1zhmudvZAs4\",\n",
        "\"https://www.youtube.com/watch?v=UyEtTyeahus\",\n",
        "\"https://www.youtube.com/watch?v=ErNp43wcudY\",\n",
        "\"https://www.youtube.com/watch?v=hq_XyP9y0xg\",\n",
        "\"https://www.youtube.com/watch?v=79UqdjnPEZ0\",\n",
        "\"https://www.youtube.com/watch?v=lHXd2hBnlJk\",\n",
        "\"https://www.youtube.com/watch?v=oBB47VrQucA\",\n",
        "\"https://www.youtube.com/watch?v=fiDmWKh_WeQ\",\n",
        "\"https://www.youtube.com/watch?v=O5mqR4EFBQk\",\n",
        "\"https://www.youtube.com/watch?v=8Covj8F-NNc\",\n",
        "\"https://www.youtube.com/watch?v=quEHyoA94rw\",\n",
        "\"https://www.youtube.com/watch?v=BdZ6bjcixhk\",\n",
        "\"https://www.youtube.com/watch?v=BlxnbyvHTyI\",\n",
        "\"https://www.youtube.com/watch?v=o4je1lSpyaw\",\n",
        "\"https://www.youtube.com/watch?v=k3UYUmp3Bi4\",\n",
        "\"https://www.youtube.com/watch?v=uot5sbPz1NQ\",\n",
        "\"https://www.youtube.com/watch?v=foCIxwn7VpI\",\n",
        "\"https://www.youtube.com/watch?v=O9ZrPXPLmWg\",\n",
        "\"https://www.youtube.com/watch?v=DTd7TyY7a-0\",\n",
        "\"https://www.youtube.com/watch?v=A2bnWAIpLIo\",\n",
        "\"https://www.youtube.com/watch?v=qOEeK1SNF3k\",\n",
        "\"https://www.youtube.com/watch?v=0aDhjrs8FMw\",\n",
        "\"https://www.youtube.com/watch?v=mzv1mkJRA10\",\n",
        "\"https://www.youtube.com/watch?v=s5qFpEPNXEY\",\n",
        "\"https://www.youtube.com/watch?v=f5sN3xAEAWQ\",\n",
        "\"https://www.youtube.com/watch?v=a-oCxdzFapE\",\n",
        "\"https://www.youtube.com/watch?v=eW546hpa744\",\n",
        "\"https://www.youtube.com/watch?v=Ny970B12IQk\",\n",
        "\"https://www.youtube.com/watch?v=qt9tXjtlQt4\",\n",
        "\"https://www.youtube.com/watch?v=gz-44N3MMOA\",\n",
        "\"https://www.youtube.com/watch?v=hbqxEJisBHo\",\n",
        "\"https://www.youtube.com/watch?v=mFD5hUZubTI\",\n",
        "\"https://www.youtube.com/watch?v=UEMMOdFbT94\",\n",
        "\"https://www.youtube.com/watch?v=43CZ0HjIC7U\",\n",
        "\"https://www.youtube.com/watch?v=opWrnW5v25w\",\n",
        "\"https://www.youtube.com/watch?v=CEBwVqRdKWc\",\n",
        "\"https://www.youtube.com/watch?v=9p7WWapTrpA\"]"
      ],
      "metadata": {
        "id": "b9JaMdWknZC2"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# urls = [\"https://youtu.be/kCc8FmEb1nY\", \"https://youtu.be/VMj-3S1tku0\"]\n",
        "\n",
        "# Directory to save audio files\n",
        "save_dir = \"/content/drive/MyDrive/data/LangChain/YouTube\"\n",
        "youtube_loader = YoutubeLoader(urls, save_dir)\n",
        "\n",
        "# Cannot use this as it requires openAI API key. Cannot use huggingfacehub whiper model as its not supported yet in langchain\n",
        "# Transcribe the videos to text\n",
        "# loader = GenericLoader(YoutubeAudioLoader(urls, save_dir), OpenAIWhisperParser())\n",
        "# docs = loader.load()"
      ],
      "metadata": {
        "id": "eY8ok7FXkn2m"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = []\n",
        "for url in urls:\n",
        "    loader = YoutubeLoader.from_youtube_url(url, add_video_info=True)\n",
        "    docs.extend(loader.load())"
      ],
      "metadata": {
        "id": "42-fqPyYniRp"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RtNve-qpTP3",
        "outputId": "fce8b138-fd51-4164-9d73-99cfee8ad365"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uWx9P6fpUt_",
        "outputId": "73c6008d-15c7-46fd-db28-cb54eed1a2ac"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content=\"hi and welcome to machine learning engineering for production a lot of learners have asked me hey andrew i've learned to train a machine learning model now what do i do machine learning models are great but unless you know how to put them into production it's hard to get them to create the maximum amount of possible value or for those of you that may be looking for position in machine learning many interviewers will ask have you ever deployed a machine learning algorithm in this full course specialization the first course taught by me the second third and fourth courses taught by robert crowe who's an expert at this from google we hope to share with you the practical hands-on skills and techniques you need to not just build a machine learning model but also to put them into production and so by the end of this first course and by the end of this specialization i hope you have a good sense of the entire life cycle of machine learning project from training model to put into production and really how to manage the entire machine learning project let's jump in let's start with an example let's say you're using computer vision to inspect phones coming off the manufacturing line to see if there are defects on them so this film shown on the left doesn't have any scratches on it but if there was a scratch or crack or something a computer vision algorithm would hopefully be able to find this type of scratch or defect and maybe put the bounding box around it as part of quality control if you get a data set of scratch phones you can train a computer vision algorithm maybe in your network to detect these types of defects but what do you now need to do in order to put this into production deployment this would be an example of how you could deploy a system like this you might have an edge device by edge device i mean a device that is living inside the factory that is manufacturing these smartphones and that edge device would have a piece of inspection software whose job it is to take a picture of the phone see if there's a scratch and then make a decision on whether this phone is acceptable or not this is actually commonly done in factories this is called automated visual defect inspection what the inspection software does is it will control camera that will take a picture of the smartphone as it rolls off the manufacturing line and it then has to make an api call to pass this picture to a prediction server and the job of the prediction server is to accept these api calls you know receive an image make a decision as to whether or not this phone is effective and return this prediction and then the inspection software can make the appropriate control decision whether to let the stone move on in the manufacturing line or whether to shove it to a side because you know was defective and not acceptable so after you have trained a learning algorithm maybe trained in your network to take as input x pictures of phones and map them to why predictions about whether the phone is defective or not you still have to take this machine learning model puts it in a prediction server set up api interfaces and really write all of the rest of the software in order to deploy this learning algorithm into production this prediction server is sometimes in the cloud and sometimes the prediction server is actually at the edge as well in fact in manufacturing we use edge deployments a lot because you can't have your factory go down every time your internet access goes down but cloud deployments with prediction server is a server in the cloud is also used for many applications let's say you write all the software what could possibly go wrong it turns out that just because you've trained a learning algorithm that does well on your test set which is to be celebrated it's great when you do well when you hold a test set unfortunately reaching that milestone doesn't mean you're done there can still be quite a lot of work and challenges ahead to get a valuable production deployment running for example let's say your training set has images that look like this there's a good phone on the left the one in the middle has a big scratch across it and you've trained your learning algorithm to recognize that phones like this on the left are okay meaning that no defects and maybe draw bounding boxes around scratches or other defects it finds in phones when you deploy it in the factory you may find that the real-life production deployment gives you back images like this much darker ones because the lighting factory because the lighting conditions in the factory have changed for some reason compared to the time when the training set was collected this problem is sometimes called concept drift or data drift you learn more about these terms later in this week but this is one example of the many practical problems that we as machine learning engineers should step up to solve if we want to make sure that we don't just do well on the hold out test set but that our systems actually create value in a practical production deployment environment i've worked on quite a few projects where my machine learning team and i would successfully know a proof of concept and by that i mean we train a model in jupiter notebook and it will work great and we will celebrate that you know you should celebrate it when you have a learning algorithm work well in a jupiter notebook or in a development environment but it turns out that sometimes i'll see many projects where that success which is a great success to the practical deployment is still maybe another six months of work and this is just one of many of the practical things that a machine learning team has to watch out for and handle in order to actually deploy these systems some machine learning engineers will say is not a machine learning problem to access these problems you know the data set changes some machine engineers think well is that a machine learning problem my point of view is that our job is to make these things work um and so if the data set has changed is i think of it as my responsibility when i work on a project to step in and do what i can to adjust the data distribution as it is rather than as i wish it is so this specialization will teach you about a lot of these important practical things for building machine learning systems that work not just in the lab not just in the jupyter notebook but in a production deployment environment a second challenge of deploying machine learning models in production is that it takes a lot more than machine learning code over the last decade there's been a lot of attention on machine learning models so your neural network or other algorithm that learns a function mapping from some input to some output and there's been amazing progress in machine learning models but it turns out that if you look at a machine learning system in production if this little orange rectangle represents the machine learning code the machine learning model code then this is all the code you need for the entire machine learning project i feel like for many machine learning projects maybe only five to ten percent maybe even less of the code is machine learning code and and i think this is one of the reasons why when you have a proof of concept model working maybe in jupiter notebook it can still be a lot of work to go from that initial proof of concept to the production deployment so sometimes people refer to the poc or the proof of concept to production gap and a lot of that gap is sometimes just the sheer amount of work it is to also write all of this code out here beyond the initial machine learning model code so what is all this other stuff this is a diagram that i've adapted from a paper by d scully and others beyond the machine learning code there are also many components especially components for managing the data such as data collection data verification feature extraction and after you are serving it how to monitor the system well monitor the data comes back help you analyze it but there are often many other components that need to be built to enable a working production deployment so in this course you learn what are all of these other pieces of software needed for a valuable production deployment but rather than looking at all of these complex pieces one of the most useful frameworks i found for organizing the workflow of a machine learning project is to systematically plan out the life cycle of a machine learning project let's go to the next video to dive in to what is the full life cycle of a machine learning project and i hope this framework will be very useful for all of your machine learning projects that you plan to deploy in the future let's go to the next video\", metadata={'source': 'NgWujOrCZFo', 'title': '#1 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 1, Lesson 1]', 'description': 'Unknown', 'view_count': 64901, 'thumbnail_url': 'https://i.ytimg.com/vi/NgWujOrCZFo/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVihBMA8=&rs=AOn4CLD0OTUfsVbchzFkcRWBQAoDN7d2Vw', 'publish_date': '2022-04-20 00:00:00', 'length': 583, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"when on building a machine learning system i found that thinking through the machine learning project life cycle is a effective way for me to plan out all the steps that i need to work on and when you are working machine learning system i think you find too that this framework allows you to plan out all the important things you need to do in order to get the system to work and also to minimize surprises so let's dive in these are the major steps of a machine learning project first is scoping in which you have to define the project just decide what to work on what exactly do you want to apply machine learning to and what is x and what is why after having chosen the project you then have to collect data or acquire the data you need for your algorithm this includes defining the data and establishing a baseline and then also labeling and organizing the data there's some best practices for this that are not intuitive that you learn more about later in this week after you have your data you then have to train the model during the model phase you have to select and train the model and also perform error analysis you might know that machine learning is often a highly iterative task so during the process of error analysis you may go back and update the model or you might also go back to the earlier phase and decide you need to collect more data as well as part of error analysis before taking the system to deployments i'll often also carry out a final check or maybe a final audit to make sure that the system's performance is good enough and that is sufficiently reliable for the application sometimes an engineer things that when you deploy a system you're done i now tell most people when you deploy a system for the first time you're maybe about halfway to the finish line because it's often only after you turn on live traffic that you then learn the second half of the important lessons needed in order to get the system to perform well to carry out the deployment step you have to deploy it in production write the software needed to put into production and then also monitor the system track the data that continues to come in and maintain the system for example if the data distribution changes you may need to update the model and so after the initial deployment maintenance will often mean going back to perform more error analysis and maybe retrain the model or it might mean taking the data you get back now that the system is deployed and is running on live data and feeding that back into your data set to then potentially update your data retrain the model and so on until you can put an updated model into deployment i found this framework useful for a very large variety of machine learning projects from computer vision to audio data to structured data to many other applications so feel free to take a screenshot of this image and use it with your friends or by yourself to plan out your machine learning projects as well thanks also to landing ai's dylan laird and daniel biberiata who are instrumental to developing this diagram in this video we quickly went through the machine learning project life cycle in order to deepen our understanding of this project life cycle it'll be useful to walk through a concrete example so in the next video let's step through what these different steps of machine learning project life cycle look like in the context of a speech recognition application let's go on to the next video\", metadata={'source': 'e69ZWbbsGng', 'title': '#2 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 1, Lesson 2]', 'description': 'Unknown', 'view_count': 17867, 'thumbnail_url': 'https://i.ytimg.com/vi/e69ZWbbsGng/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGEIgSyhlMA8=&rs=AOn4CLA8kWPqqdWaNG7RqHwYKsKN6DUZUA', 'publish_date': '2022-04-20 00:00:00', 'length': 235, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"one of the successes of deep learning has been speech recognition deep learning has made speech recognition much more accurate than you know maybe a decade ago and this is allowing many of us to use speech recognition in our smart speakers on our smartphones for voice search and in other contexts you may have heard occasionally about the research work that goes into building better speech models but what else is needed to actually build a valuable production deployment speech recognition system let's use the machine learning project life cycle to set through a speech recognition example so you can understand all the steps needed to actually build and deploy such a system i've worked on speech recognition systems in a commercial context before and so the first step of that was scoping have to first define the project and just make a decision to work on speech recognition say for voice search as part of defining the project i'd also encourage you to try to estimate or maybe at least guesstimate the key metrics this will be very problem dependent almost every application will have its own unique set of goals and metrics but in case of speech recognition some things i cared about were how accurate is the speech system was the latency how long does the system take to transcribe speech and what is the throughput how many queries per second could we handle and then if possible you might also try to estimate the resources needed so how much time how much compute how much budget as well as timeline how long would it take to carry out this project i'll have a lot more to say on scoping in week 3 of this course so we'll come back to this topic and describe this in greater detail as well the next step is the data stage where you have to define the data and establish a baseline and also label and organize the data what's hard about this one of the challenges of practical speech recognition systems is is the data label consistently here's an audio clip of a fairly typical recording you might get if you're working on speech recognition for voice search let me play this audio clip um today's weather and the question is given this audio clip that you just heard um today's weather would you want to transcribe it like that which if you have transcriptionists label the data this would be a perfectly reasonable transcription or would you want to transcribe it like that which is also a completely reasonable transcription or should the transcriptionist say well there's often a lot of noise in audio you know maybe there's a sound of a clunk if something fell down and you don't want to transcribe noise so maybe it's just noise and you should transcribe it like that it turns out that any of these three ways of transcribing the audio is just fine i would probably prefer either the first or the second not the third but what would hurt your learning algorithms performance is if one third of the transcription is used the first one third the second and one third the third way of transcribing because then your data is inconsistent and confusing for the learning algorithm because how is the learning algorithm supposed to guess which one of these conventions a specific transcriptionist happened to use for an audio clip so spotting correcting consistencies like that maybe just asking everyone to standardize on this first convention that can have a significant impact on your learning album's performance so we'll come back later in this course to dive into some best practices for how to spot inconsistencies and how to address them other examples of data definition questions for an audio clip like today's weather how much silence do you want before and after each clip after a speaker has stopped speaking do you want to include another 100 milliseconds of silence after that or 300 milliseconds or 500 milliseconds half a second or how do you perform volume normalization some speakers speak loudly some are less loud and then there's actually a tricky case of if you have a single audio clip with some really loud volume and some really soft volume all within the same audio clip so how do you perform volume normalization questions like all of these are data definition questions a lot of progress in machine learning that is a lot of machine learning research was driven by researchers working to improve performance on benchmark data sets in that model researchers might download the data set and just work on that fixed data set and this mindset has led to tremendous progress in machine learning so no complaints at all about this mindset but if you are working on a production system then you don't have to keep the data set fixed i often edit the training sets or even at the test set if that's what's needed in order to improve the data quality to get a production system to work better so what a practical ways to do this effectively not an ad hoc way but systematic frameworks for making sure you have high quality data you learn more about this later in this course and later in the specialization as well after you've collected your data set the next step is modeling in which you have to select and train the model and perform error analysis the three key inputs that go into training a machine learning model are the code that is the algorithm or the neural network model architecture that you might choose you also have to pick hyper parameters and then there's the data and running the codes with your hyperparameters on your data gives you the machine learning model the accelerated machine learning model for learning from say audio clips to text transcripts i've found that in a lot of research work or academic work you tend to hold the data fixed and vary the code and maybe vary the hyperparameters in order to try to get good performance in contrast i found that for a lot of product teams if your main goal is to just build and deploy a working valuable machine learning system i found that it can be even more effective to hold the code fixed and to instead focus on optimizing the data and maybe the hyper parameters in order to get a high performing model a machine learning system [Music] includes both code and data and also hyper parameters but they're maybe a bit easier to optimize than the code or data and i found that rather than taking a model centric view of trying to optimize the code to your fixed data set for many problems you can use an open source implementation of something that you download off github and instead just focus on optimizing the data so during modeling you have to select and train some model architecture maybe some neural network architecture error analysis can then tell you where your model still falls short and if you can use that error analysis to tell you how to systematically improve your data maybe improve the code too that's okay but often if air analysis can tell you how to systematically improve the data that can be a very efficient way for you to get to a high accuracy model and part of the trick is you don't want to just feel like you need to collect more data all the time because we could always use more data but rather than just trying to collect more and more and more data which is helpful but can be expensive if error analysis can help you be more targeted in exactly what data to collect that can help you be much more efficient in building an accurate model finally when you have trained the model and when error analysis seems to suggest it's working well enough you're then ready to go into deployment check speech recognition this is how you might deploy a speech system you have a mobile phone this would be an edge device with software running locally on your phone that software taps into the microphone to record what someone is saying maybe for voice search and in a typical implementation of speech recognition you would use a vad module vad stands for voice activity detection and it's usually a relatively simple algorithm maybe a learning algorithm and the job of the vid allows the smartphone to select out just the audio that contains hopefully someone speaking so that you can send only that audio clip to your prediction server and in this case maybe the prediction server lives in the cloud this would be a common deployment pattern the prediction server then returns both the transcript so the user so you can see what the system thinks you said and it also returns the search results if you're doing voice search and the transcript and search results are then displayed in the front end code running on your mobile phone so implementing this type of system would be the work needed to deploy a speech model in production even after it's running though you still have to monitor and maintain the system so here's something that happened to me once my team had built a speech recognition system and it was trained mainly on adult voices we pushed it to production ran into production and we found that over time more and more young individuals kind of teenagers you know sometimes even younger seem to be using our speech recognition system and the voices of very young individuals just sound different and so my speech systems performance started to degrade we just were not that good at recognizing speech as spoken by younger voices and so we had to go back and find a way you know collect more data other things in order to fix it so one of the key challenges when it comes to deployment is concept drift or data drift which is what happens when the data distribution changes such as there are more and more young voices being fed to the speech recognition system and knowing how to put in place appropriate monitors to spot such problems and then also how to fix them in a timely way is a key skill needed to make sure your production deployment creates a value you hope it will to recap in this video you saw the full life cycle of a machine learning project using speech recognition as the running example so from scoping to data to modeling to deployment next i want to briefly share with you the major concepts and sequencing you learn about in this course so come with me to the next video\", metadata={'source': 'YJsRD_hU4tc', 'title': '#3 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 1, Lesson 3]', 'description': 'Unknown', 'view_count': 15612, 'thumbnail_url': 'https://i.ytimg.com/vi/YJsRD_hU4tc/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgWyhEMA8=&rs=AOn4CLAQfNBgyjpOwU5T3OkoP8ckWEpJWQ', 'publish_date': '2022-04-20 00:00:00', 'length': 723, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"you've seen the machine learning project lifecycle let's briefly go over what you learned in the rest of this course even though i presented the lifecycle going from left to right i found that for learning these materials it'll be more efficient for you to start at the end go and start from deployment and then work backwards to modeling data and then scoping so in the rest of this week starting with the next video you learn about the most important ideas in deployment next week in week 2 you learn about modeling you may have learned about how to train the machine learning model from other courses in this video i'll share some new ideas that you may not have heard before of how to systematically use a data centric approach to be more efficient in how you improve the performance of your model then in the third and final week of this course you learn about data how to define data and establish a baseline and how to label and organize your data in a way that is systematic not ad hoc not hacking around in the jupyter notebook in the hope that you stumble on the right insights but in a more systematic way that helps you be more efficient in defining the data that will help the modeling to help you get to deployment and then finally in week three we'll also have an optional section on scoping in which i hope to share with you some tips i've learned on how to define effective machine learning projects throughout this course you also learn about ml ops or machine learning operations which is an emerging discipline that comprises a set of tools and principles to support progress through the machine learning project life cycle but especially these three steps for example at landing ai where on co we used to do a lot of these steps manually which is okay but slow but after building an emma ops 2 called landing lens for computer vision applications all these steps became much quicker the key idea in ml ops is that systematic ways to think about scoping data modeling and deployment and also software tools to support the best practices so that's it in this course we're going to start at the end goal start from deployment and then work our way backwards as you already know being the deploy a system is one of the most important and valuable skills in machine learning today so let's go on to the next video where we'll dive deep into the most important lessons most important ideas needed to deploy machine learning systems i will see you in the next video\", metadata={'source': '1zhmudvZAs4', 'title': '#4 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 1, Lesson 4]', 'description': 'Unknown', 'view_count': 10354, 'thumbnail_url': 'https://i.ytimg.com/vi/1zhmudvZAs4/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgVSg_MA8=&rs=AOn4CLCjx3M4zOGG3DUM828U49cMKTa7eA', 'publish_date': '2022-04-20 00:00:00', 'length': 163, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"one of the most exciting moments of any machine learning project is when you get to deploy your model but what makes deployment hard i think there are two major categories of challenges in deploying a machine learning model first are the machine learning or the statistical issues and second are the software engine issues let's step through both of these so you can understand what you need to do to make sure that you have a successful deployment of your system one of the challenges of a lot of deployments is concept drift and data drift loosely this means what if your data changes after your system has already been deployed i had previously given an example from manufacturing where you might have trained a learning algorithm to detect scratches on smartphones under one set of lighting conditions and then maybe the lighting and the factory changes that's one example of the distribution of data changes let's walk through a second example using speech recognition i've trained a few speech recognition systems and when i built speech systems quite often i would have some purchase data so this would be some purchase or license data which includes both the input x the audio as well as the transcript y that the speech system is supposed to output and in addition to data that you might purchase from a vendor you might also have historical user data of user speaking to your application together with transcripts of that real user data and such user data of course should be collected with very clear user opt-in permission and clear safeguards for user privacy after you've trained your speech recognition system on a data set like this you might then evaluate it on a test set but because speech data does change over time when i build speech recognition systems sometimes i will collect a def set or hold up validation set as well as test set comprising data from just the last few months so you can test it on fairly recent data to make sure your system works even on relatively recent data and then after you push the system to deployments the question is will the data change or after you've run it for a few weeks for a few months has the data changed yet again because of the data has changed such as the language changes or maybe people are using a brand new model of smartphone which has a different microphone so the audio sounds different then the performance of your speech recognition system can degrade and it's important for you to recognize how the data has changed and if you need to update your learning algorithm as a result when data changes sometimes it is a gradual change such as the english language which does change but changes very slowly with new vocabulary introduced at a relatively slow rate and sometimes data changes very suddenly where there's a sudden shock to a system for example when covet 19 the pandemic hit a lot of credit card fraud systems started to not work because the purchase patents of individuals suddenly change many people that did relatively little online shopping suddenly started to use much more online shopping and so the way that people were using credit cards changed very suddenly and this actually tripped up a lot of anti-fraud systems and this very sudden shift to the data distribution meant that many machine learning teams were scrambling a little bit at the start of covid to collect new data and retrain systems in order to make them adapt to this very new data distribution sometimes the terminology of how to describe these data changes is not used completely consistently but sometimes the term data drift is used to describe if the input distribution x changes such as if a new politician or celebrity suddenly becomes well known and is mentioned much more than before and the term concept drift refers to if the desired mapping from x to y changes such as if before covert 19 perhaps for a given user a lot of surprising online purchases should have flagged that account for fraud but after the starter cover 19 maybe those same purchases would not have really been any calls for alarming in terms of flagging that the credit card may have been stolen or another example of concept drift let's say that x is the size of a house and y is the price of a house because you're trying to estimate housing prices well if because of inflation or changes in the market houses maybe become more expensive over time then the same size hulls will end up with a higher price and so that would be concept drift maybe the size of houses haven't changed but the price of a given house changes whereas data drift would be if say people start building larger houses or start building smaller houses and thus the input distribution of the sizes and houses actually changes over time so when you deploy a machine learning system one of the most important tasks will often be to make sure you can detect and manage any changes including both concept drift which is when the definition of what is y given x changes as well as data drift which is if the distribution of x changes even if the mapping from x and y does not change in addition to managing these changes to the data a second set of issues that you will have to manage to deploy a system successfully are software engineering issues when you are implementing a prediction service whose job it is to take queries x and output prediction y you have a lot of design choices as to how to implement this piece of software here's a checklist of questions that might help you with making the appropriate decisions for managing the software engineering issues one decision you have to make for your application is do you need real-time predictions or are batch predictions okay for example if you are building a speech recognition system where the user speaks and you need to get a response back in half a second then clearly you need real-time predictions in contrast i have also built systems for hospitals that take patient records take electronic health records and run an overnight batch process to see if there's something associated with the patients that we can spot so in that type of system it was fine if we just ran it in a batch of patient records once per night and so whether you need to write real-time software they can respond within you know hundreds of milliseconds or whether you can write software that just does a lot of computation overnight that will affect how you implement your software and by the way later this week you also get to step through an optional programming exercise where you get to implement a real-time prediction service on your own computer you see that at the optional exercise at the end of this week so second question you need to ask is does your prediction service run in the cloud or does it run at the edge or maybe even in a web browser today there are many speech recognition systems that run in the cloud because having the compute resources of the cloud allows for more accurate speech recognition but there are also some speech systems for example a lot of speech systems within cars actually run at the edge and there are also some mobile speech recognition systems that work even if your internet even if your wi-fi is turned off so those would be examples of speech systems that run at the edge when i'm deploying visual inspection systems in factories i pretty much almost always run that at the edge as well because sometimes unavoidably the internet connection between the factory and you know the rest of the internet may go down and you just can't afford to shut down the factory whenever this internet connection goes down which which happens very rarely but maybe sometimes does happen and with the rise of modern web browsers there are better and better tools for deploying learning algorithms right there within a web browser as well when building a prediction service is also useful to take into account how much compute resources you have there have been quite a few times where i trained the neural network on a very powerful gpu only to realize that i couldn't afford an equally powerful set of gpus for deployment and wound up having to do something else to compress or reduce the model complexity so if you know how much cpu or gpu resources and maybe also how much memory resources you have for your prediction service then that could help you choose the right software architecture depending on your application especially if it's real-time application latency and throughput such as measure in terms of qps queries per second will be other software entering metrics you may need to hit in speech recognition it's not uncommon to want to get an answer back to the user within half a second or 500 milliseconds and of this 500 millisecond budget you may be able to allocate only say 300 milliseconds to your speech recognition and so that gives a latency requirement for your system and throughput refers to how many queries per second do you need to handle given your compute resources maybe given a certain number of cloud servers so for example if you're building a system that needs to handle a thousand queries per second it would be useful to make sure to spec out your system so that you have enough compute resources to hit the qps requirement next is logging when building your system it may be useful to log as much of the data as possible for analysis and review as well as to provide more data for retraining your learning algorithm in the future finally security and privacy i find that for different applications the required levels of security and privacy can be very different for example when i was working on electronic health records patient records clearly the requirements for security and privacy were very high because patient records are very highly sensitive information and depending on your application you might want to design in the appropriate level of security and privacy based on how sensitive that data is and also sometimes based on regulatory requirements so if you save this checklist somewhere going through this when you're designing your software might help you to make the appropriate software engineering choices when implementing your prediction service so to summarize deploying a system requires two broad sets of tools there is writing the software to enable you to deploy the system in production and there is what you need to do to monitor the system performance and to continue to maintain it especially in the phase of concept drift as well as data drift one of the things you see when you're building machine learning systems is that the practices for the very first deployments will be quite different compared to when you are updating or maintaining a system that has already previously been deployed i know that there's some engineers that view deploying the machine learning model as getting to the finish line unfortunately i think the first deployment means you may be only about halfway there and the second half of your work is just starting only after your first deployment because even after you've deployed there's a lot of work to feed the data back and maybe to update the model to keep on maintaining the model even in the phase of changes to the data one of the things we'll touch on in later videos is some of the differences between the first deployment such as if your product never had a speech recognition system but you've trained the speech recognition system and you're deploying it for the first time versus you already have had the learning algorithm running for some time and you want to maintain or update that implementation to summarize in this video you saw some of the machine learning or statistical related issues such as concept driven data drift as well as some of the software engineering related issues such as whether you need a batch or real-time prediction service and what are the compute and memory requirements you have to take into account now it turns out that when you're deploying a machine learning model there are a number of common design patterns the common deployment patterns that are used in many applications across many different industries in the next video you see what are some of the most common deployment patterns so that you can hopefully pick the right one for your application let's go on to the next video\", metadata={'source': 'UyEtTyeahus', 'title': '#5 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 1, Lesson 5]', 'description': 'Unknown', 'view_count': 11572, 'thumbnail_url': 'https://i.ytimg.com/vi/UyEtTyeahus/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGEogSihlMA8=&rs=AOn4CLC7sJtZTLBF7HIaUAQtjjaYBM3pfQ', 'publish_date': '2022-04-20 00:00:00', 'length': 862, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"when you've trained the learning algorithm the best way to deploy it is usually not to just turn it on and hope for the best because well what if something goes wrong when deploying systems there are a number of common use cases or types of use cases as well as different patterns for how you deploy depending on your use case let's go through that in this video in the last video i alluded to some of the differences between a first deployment versus a maintenance or an update deployment let's flesh this out into a little bit more detail one type of deployment is if you are offering a new product or capability that you had not previously offered for example if you're offering a speech recognition service that you had not offered before in this case a common design pattern is to start with a small amount of traffic and then gradually ramp it up a second common deployment use case is if there's something that's already being done by a person but we would now like to use a learning algorithm to either automate or assist with that task for example if you had people in a factory inspecting smartphones or scratches but now you would like to use a learning algorithm to either assist or automate that task the fact that people were previously doing this gives you a few more options for how you deploy and you see shadow mode deployment takes advantage of this and finally a third common deployment case is if you've already been doing this task with a previous implementation of a machine learning system but you now want to replace it with hopefully an even better one in these cases two recurring themes you see are that you often want a gradual ramp up with monitoring in other words rather than sending tons of traffic to a maybe not fully proven learning algorithm you may send it only a small amount of traffic and monitor it and then ramp up the percentage or amount of traffic and the second idea you see a few times is rollback meaning that if for some reason the album isn't working it's nice if you can revert back to the previous system if indeed there was an earlier system let's start with an example in visual inspection where perhaps you've had human inspectors inspect smartphones for defects for stretches and you would now like to automate some of this work with a learning algorithm when you have people initially doing a task one common deployment pattern is to use shadow mode deployment and what that means is that you will start by having a machine learning algorithm shadow the human inspector and run in parallel with the human inspector during this initial phase the learning algorithm's output is not used for any decision in the factory so whatever the learning algorithm says we're going to go over the human judgment for now so let's say for this smartphone the human says it's fine no defect the learning algorithm says it's fine maybe for this example a big scratch down the middle person says it's not okay and the learning algorithm agrees and maybe for this example with a smaller scratch maybe the person says this is not okay but the learning algorithm makes a mistake and actually thinks this is okay the purpose of a shadow mode deployment is that it allows you to gather data of how the learning algorithm is performing and how that compares to the human judgments and by sampling the opus you can then verify if the learning algorithms predictions are accurate and therefore use that to decide whether or not to maybe allow the learning algorithms to make some real decisions in the future so when you already have some system that is making good decisions and that system can be human inspectors or even an older implementation of a learning algorithm using a shadow mode deployments can be a very effective way to let you verify the performance of a learning algorithm before letting it make any real decisions when you are ready to let a learning algorithm start making real decisions a common deployment pattern is to use a canary deployment so there's a phone album says is okay rejects that says okay rejects that rejects that and in the country deployments you would roll out to a small fraction maybe five percent maybe even less of traffic initially and stop let the algorithm making real decisions but by running this on only a small percentage of the traffic hopefully if the album makes any mistakes it will affect only a small fraction of the traffic and this gives you more of an opportunity to monitor the system and ramp up the percentage of traffic it gets only gradually and only when you have greater confidence in this performance the phrase can redeployment is a reference to the english idiom or the english phrase can be in a coal mine which refers to how coal miners used to use canneries to spot if there's a gas leak but with academy deployment hopefully this allows you to spot problems early on before there are maybe overly large consequences to your factory or other context in which you're deploying you're learning algorithm another deployment pattern that is sometimes used is a blue green deployment let me explain with a picture say you have a system a camera software for collecting phone pictures in your factory these phone images are sent to a piece of software that takes these images and routes them into some visual inspection system in the terminology of a blue green deployments the old version of your software is called the blue version and the new version the learning algorithm you just implemented is called the green version in a blue green deployment what you do is have the router send images to the old or the blue version and have that make decisions and then when you want to switch over to the new version what you would do is have the router stop sending images to the old one and suddenly switch over to the new version so the way a blue green deployment is implemented is you would have an old prediction service maybe running on some set of service you then spin up a new prediction service the green version and you would have the router suddenly switch the traffic over from the old one to the new one the advantage of a blue green deployment is that there's an easy way to enable rollback if something goes wrong you can just very quickly have the router go back reconfigure the router to send traffic back to the old or the blue version assuming that you kept your blue version of the prediction service running in a typical implementation of a blue green deployment people think of switching over the traffic 100 all at the same time but of course you can also use a more gradual version where you slowly send traffic over as you can imagine whether you use shadow mode canon remote blue green or some other deployment pattern quite a lot of software is needed to execute this emma ops tools can help with implementing these deployment patterns or you can implement it yourself one of the most useful frameworks i have found for thinking about how to deploy a system is to think about deployment not as a zero one is either deploy or not deploy but instead to design a system thinking about what is the appropriate degree of automation for example in visual inspection of smartphones one extreme would be if there's no automation so the human only system slightly more automated would be if your system is running in shadow mode so your learning albums are putting predictions but it's not actually used in the factory so that would be shadow mode a slightly greater degree of automation would be ai assistance in which given a picture like this of a smartphone you may have a human inspector make the decision but maybe an ai system can affect the user interface to highlight the regions where there's a scratch to help draw the person's attention to where it may be most useful for them to look the user interface or ui design is critical for human assistance but this could be a way to get a slightly greater degree of automation while still keeping the human in the loop an even greater degree of automation may be partial automation where given a smartphone if the learning algorithm is sure it's fine then that's his decision if it's sure it's defective then we just go with the ai already's decision but if the learning algorithm is not sure in other words if the learning album's prediction is not a confident zero or one maybe only then do we send this to a human so this would be partial automation where if the learning algorithm is confident of its prediction we go of the learning algorithm but for the hopefully small subset of images where the album is not sure we send that to a human to get their judgment and the human judgment can also be very valuable data to feedback to further train and improve the algorithm i find that this partial automation is sometimes a very good design point for applications where the learning algorithm's performance isn't good enough for full automation and then of course beyond partial automation there is full automation where we might have the learning algorithm make every single decision so there is a spectrum of using only human decisions on the left all the way to using only the ai systems decisions on the right and many deployment applications will start from the left and gradually move to the right and you do not have to get all the way to full automation you could choose to stop using ai assistance or partial automation or you could choose to go to full automation depending on the performance of your system and the needs of the application on this spectrum [Music] both ai assistance and partial automation are examples of human in the loop deployments i find that for consumer internet applications such as if you run a web search engine or an online speech recognition system a lot of consumer software internet businesses have to use full automation because it's just not feasible to have someone on the back end doing some work every time someone does a web search or does a product search but outside consumer software internet for example inspecting things in factories there are actually many applications where the best design point may be a human in the loop deployments rather than a full automation deployment in this video you saw a few patterns of deployments such as a shadow one deployment academy deployment a blue green deployment and you also saw how you can pick the most appropriate degree of automation depending on your application which could be a human in the loop deployments or for automation as we went through these ideas you heard me mention a few times the importance of monitoring to help you spot problems if any so they can address them let's dive into the details of how to monitor the system in the next video\", metadata={'source': 'ErNp43wcudY', 'title': '#6 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 1, Lesson 6]', 'description': 'Unknown', 'view_count': 9615, 'thumbnail_url': 'https://i.ytimg.com/vi/ErNp43wcudY/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgWShCMA8=&rs=AOn4CLDXpx65XXcQdGXgUMnu_TmwnkBCTQ', 'publish_date': '2022-04-20 00:00:00', 'length': 713, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"how can you monitor a machine learning system to make sure that it is meeting your performance expectations in this video you learned about best practices for monitoring deployed machine learning systems the most common way to monitor a machine learning system is to use a dashboard to track how it is doing over time depending on your application your dashboards may monitor different metrics for example you may have one dashboard to monitor the server load or a different dashboard to monitor the fraction of non-null outputs so sometimes the speed recognition system outputs no and it thinks the user didn't say anything so if this changes dramatically over time it may be an indication that something is wrong or one common one i've seen for a lot of structured data taught is monitoring the fraction of missing input values if that changes it may mean that something has changed about your data so when you're trying to decide what to monitor my recommendation is that you sit down with your team and brainstorm all the things that could possibly go wrong and that you want to know about if something does go wrong and for all the things that could go wrong brainstorm a few statistics or a few metrics that will detect that problem for example if you're worried about user traffic spiking causing the service to become overloaded then server loads would be maybe one metric you could track and so on for the other examples here and when i'm designing my monitoring dashboards for the first time i think it's okay to start off with a lot of different metrics and monitor a relatively large set and then gradually remove the ones that you find over time not to be particularly useful here are some examples of metrics i've used or i've seen others use on a variety of projects first are the software metrics such as memory compute latency throughput server load things that help you monitor the health of your software implementation of the prediction service or of other pieces of software around your learning algorithm but these software metrics will help you make sure that your software is running well many email ops tools will come out of the box already tracking these software metrics in addition to the software metrics i would often choose other metrics that help monitor the statistical health or the performance of the learning algorithm broadly there are two types of metrics you might brainstorm around one is input metrics which a metric set measure has your input distribution x change for example if you are building a speech recognition system you might monitor the average input length in seconds of the length of the audio clip fed to your system you might monitor the average input volume and if these change for some reason that might be something you would want to take a look at just to make sure this hasn't hurt the performance of your algorithm i mentioned just now number or percentage of missing values is a very common metric when using structured data some of which may have missing values or for the manufacturing visual inspection example you might monitor average image brightness if you think that lighting conditions could change and you want to make sure you know if it does so you can brainstorm different metrics to see if your input distribution x might have changed a second set of metrics that help you understand if your learning algorithm is performing well are output metrics such as how often does your speech recognition system return no the empty string because it thinks the user didn't say anything or if you have built a speech recognition system for voice search for web search using voice you might decide to see how often does a user do two very quick searches in a row with substantially the same input that might be a sign that you misrecognize their query the first time around is an imperfect signal but you could try this metric and see if it helps or you could monitor the number of times the user first try to use the speech system and then switches over to typing that could be a sign that the user got frustrated or gave up on your speech system and could indicate degrading performance and of course for web search you would also use maybe very course metrics like click-through rate or ctr just to make sure that the overall system is healthy so these output metrics can help you figure out if either your learning algorithm outputs y has changed in some way or if something that comes even after you're learning algorithms output such as a user switching over to typing has changed in some significant way because input and output metrics are application specific most demo ops tools will need to be configured specifically to track the input and output metrics for your application you may already know that machine learning modeling is a highly iterative process so is deployment take modeling you would come up with a machine learning model and some data train the model that's an experiment and then do error analysis and use the error analysis to go back to figure out how to improve the model or your data and is by iterating through this loop multiple times that you then hopefully get to a good model i encourage you to think of deployment as an iterative process as well when you get your first deployment up and running and put in place a set of monitoring dashboards that's only the start of this iterative process a running system allows you to get real user data or real traffic and it is by seeing how your learning algorithm performs on real data on real traffic that that allows you to do performance analysis and this in turn helps you to update your deployment and to keep on monitoring your system in my experience it usually takes a few tries to converge to the right set of metrics to monitor sometimes i've deployed the machine learning system and it's not uncommon for you to deploy a machine learning system with an initial set of metrics only to run the system for a few weeks and then to realize that something could go wrong with it that you hadn't thought of before and then to pick a new metric to monitor or for you to have some metric that you monitor for a few weeks and then decide that this metric hardly ever changes and does isn't useful and to get rid of that metric in favor of focusing attention on something else after you've chosen a set of metrics to monitor common practice would be to set thresholds for alarms so you may decide based on this that if the server load ever goes above 0.91 [Music] that may trigger an alarm or a notification to let you know or let the team know to see if there's a problem and maybe spin up some more servers or if the fraction of non-now opus goes above or beyond certain thresholds that might trigger an alarm or if the not fraction of missing values goes above or below some set of thresholds maybe that should trigger an alarm and it is okay if you adapt the metrics and the thresholds over time to make sure that they are flagging to you the most relevant cases of concern if something goes wrong with your learning algorithm if it's a software issue such as server load is too high then that may require changing the software implementation or if it is a performance problem associated with the accuracy of the learning algorithm then you may need to update your model or if the issue associated with the accuracy of the learning algorithm then you may need to go back to fix that and that's why many machine learning models will need a little bit of maintenance or retraining over time just like almost all software needs some level of maintenance as well when a model needs to be updated you can either retrain it manually where an engineer maybe you will retrain the model perform error analysis on the new model and make sure it looks okay before you push that to deployment or you could also put in place a system where there is automatic retraining today manual retraining is far more common than automatic retraining for many applications developers are reluctant to let the learning algorithm be fully automatic in terms of deciding to recreate and push a new model to production but there is there are some applications especially in consumer software internet where automatic retraining does happen we'll talk more about retraining and how to vet or verify a model's performance before pushing a new model out to production in next week's videos but the key takeaways are that it is only by monitoring the system that you can spot if there may be a problem that may cause you to go back to perform a deeper error analysis or that may cause you to go back to get more data with which you can update your model so as to maintain or improve your system's performance you learn more about how to update models in the next two weeks materials as well in this video you learn how to monitor the performance of a machine learning system so that in case something needs to be maintained or fixed you can be alerted so they can take the appropriate action we've talked about how to monitor the performance of a single machine learning model one of the most useful concepts is for more complex systems where you don't have just one model but a more complex machine learning pipeline how do you monitor the performance of that you learn about that in the next video\", metadata={'source': 'hq_XyP9y0xg', 'title': '#7 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 1, Lesson 7]', 'description': 'Unknown', 'view_count': 8091, 'thumbnail_url': 'https://i.ytimg.com/vi/hq_XyP9y0xg/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVSg_MA8=&rs=AOn4CLDhFYKPxWoK0h4-kR503svf0dwFuA', 'publish_date': '2022-04-20 00:00:00', 'length': 646, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"many ai systems are not just a single machine learning model running a prediction service but instead involves a pipeline of multiple steps so what are machine learning pipelines and how do you build monitoring systems for that let's learn about that in this video let's continue with our speech recognition example you've seen how a speech recognition system may take as input audio and output a transcript the way that speech recognition is typically implemented on mobile apps is not like this but instead is a slightly more complex pipeline where the audio is fed to a module called a vad or a voice activity detection module whose job it is to see if anyone is speaking and only if the vad module the voice activity detection module thinks someone is speaking does it then bother to pass the audio on to a speech recognition system whose job it is to then generate the transcript and the reason we use a voice activity detection or vad module is because if say your speech recognition system runs in the cloud you don't want to stream more bandwidth than you have to to your cloud server and so the voice activity detection module looks at the long stream of audio on your cell phone and clips or shortens the audio to just the part where someone is talking and streams only that to the cloud server to perform the speech recognition so this is an example of a machine learning pipeline where there is one step usually done by a learning alarm as well to decide if someone is talking or not and then the second step also done by a learning algorithm to generate the text transcript when you have two learning algorithms one that's learned to detect someone's talking and one that's learned to transcribe speech when you have two such modules working together changes to the first module may affect the performance of the second module as well for example let's say that because of the way a new cell phone's microphone works the vad module ends up clipping the audio differently maybe it leaves more silence at the start or end or less silence than the sound or end and thus if the vad's output changes that will cause the speech recognition system's input to change and that could cause the greater performance of the speech recognition system let's look at an example involving user profiles maybe you have user data such as click stream data showing what users are clicking on and this can be used to build a user profile that tries to capture key attributes or key characteristics of a user for example i once built user profiles that would try to estimate many attributes of users including whether or not the user seemed to own a car because this would help us decide if it was worth trying to offer car insurance office to that user and so whether the user owns a car could be yes or no or unknown or maybe other finer gradations and these and the typical way that the user profile is built is with a learning algorithm to try to predict if this user owns a call this type of user profile which can have a very long list of predicted attributes can then be fed to recommend a system another learning algorithm that then takes its understanding of the user to try to generate product recommendations now if something about the click stream data changes maybe this input distribution changes then maybe over time if we lose our ability to figure out if a user owns a car then the percentage of the unknown tag here may go up and because the user profiles output changes the input to the recommended system now changes and this might affect the quality of the product recommendations when you have machine learning pipelines these cascading effects in the pipeline can be complex to keep track of but if the percentage of unknown labels does go up this could be something that you want to be alerted to so that you can update the recommended system if needed to make sure you continue to generate high quality product recommendations so when building these complex machine learning pipelines which can have machine learning based components or non-machine learning based components throughout the pipeline i find it useful to brainstorm metrics to monitor that can detect changes including concept drift or data drive or both and multiple stages of the pipeline so metrics to monitor include software metrics for perhaps each of the components in the pipeline or perhaps for the overall pipeline as a whole as well as input metrics and potentially output metrics for each of the components of the pipeline and by brainstorming metrics associated with individual components of the pipeline as well this could help you spot problems such as the voice activity detection system of putting longer or shorter audio clips over time or the user profile system suddenly having more unknown attributes for whether the user owns a car and thereby alerts you to changes in the data that may require you to take action to maintain the model but the principle that you saw in the last video of brainstorm all the things that could go wrong including things that could go wrong with individual components of the pipeline and design metrics to track those that principle still applies only now you're looking at multiple components in the pipeline finally how quickly does data change the rate at which data changes is very problem dependent for example let's see a build to face recognition system then the rate at which people's appearances changes usually isn't that fast you know people's hairstyles and clothing does change with fashion changes and as cameras get better we've been getting higher and higher resolution pictures of people over time but for the most part people's appearances don't change that much but there are sometimes things that can change very quickly as well such as if a factory gets a new batch of material for how they make cell phones and so all the cell phones start to change in appearance so some applications will have data that changes over the time scale of months or even years and some applications with data that could suddenly change in a matter of minutes speaking in very broad generalities i find that on average user data generally changes relatively slowly if you run a consumer-facing business with a very large number of users then it is quite rare for millions of users to all suddenly change their behavior all at the same time and so user data if a large number of users will usually change relatively slowly there are a few exceptions of course covet 19 being one of them where a shock to society actually caused a lot of people's behavior that all change at the same time and if you look at web search traffic you will see trends maybe a holiday or a new movie and people start searching for something new they just became popular so there are exceptions but on average if you have a very large group of users there are only a few forces that can simultaneously change the behavior of a lot of people all at the same time in contrast if you work on a b2b or business to business application i find that enterprise data or business data can shift quite quickly because the factory making cell phones may suddenly decide to use a new coating for their cell phones and suddenly the entire data set changes because the cell phones suddenly all look different but if you're providing a machine learning system to a company then sometimes if the ceo of that company decides to change the way that business operates all of that data can shift very quickly i know that these two bullets are me speaking in generalities and there are certainly exceptions to both of these but maybe this will give you a way of thinking about how quickly your data is likely to change or not change so that's it congratulations on making it to the end of this first week's videos i hope you also take a look at the practice quizzes which will let you practice all these concepts and make sure you deeply understand them and if you want you can also take a look at this week's optional programming exercise which lets you deploy a machine learning model on your own computer and i also look forward to seeing you in next week's videos where we'll dive together much more deeply into the modeling part of the full cycle of machine learning project i look forward to seeing you next week\", metadata={'source': '79UqdjnPEZ0', 'title': '#8 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 1, Lesson 8]', 'description': 'Unknown', 'view_count': 7758, 'thumbnail_url': 'https://i.ytimg.com/vi/79UqdjnPEZ0/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgXShFMA8=&rs=AOn4CLAqXCTKfEKzDr-1CVkNX7ytvQQxUA', 'publish_date': '2022-04-20 00:00:00', 'length': 572, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"in this week you learned about some best practices for building a machine learning model that is worthy of a production deployment one of my friends adam coats joked that the way he listened to me give advice to machine learning teams he felt the way i gave advice was quite consistent from project to project so that he could almost replace me with an if then else sequence of statements and i found too when several senior machine learning engineers look at the project the advice they tend to give is also remarkably consistent what you learned in this week is what are some of the key challenges of trying to build a production ready machine learning model things like how do you handle skewed data sets or what if you do well in the test set but for some reason that still isn't good enough for your actual application and i hope that after this week's materials you'll be able to very efficiently know how to improve your machine learning model to solve the most important problems that then make it deployment ready let's dive in this week our focus will be on the modeling part of the full cycle of a machine learning project and you learn some suggestions for how to select and train the model and how to perform error analysis and use that to drive model improvements one of the themes you hear me refer to multiple times is model centric ai development versus data centric ai development the way that ai has grown up there's been a lot of emphasis on how to choose the right model such as maybe how to choose the right neural network architecture i found that for practical projects it can be even more useful to take a more data centric approach where you focus not just on improving the neural network architecture but on making sure you are feeding your algorithm high quality data and that ultimately lets you be more efficient in getting your system to perform well but the way i engage in data centric ai development is not to just go and try to collect more and more and more data which can be very time consuming but to instead use tools to help me improve the data in the most efficient possible way you learn some ways for how to do that in this week so i'm excited to go through this week's materials review on training models but first let's look at some key challenges that many teams face when building machine learning models by understanding these key challenges you'd be better able to spot them ahead of time and address them more efficiently for your projects let's go on to the next video\", metadata={'source': 'lHXd2hBnlJk', 'title': '#9 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 1]', 'description': 'Unknown', 'view_count': 5825, 'thumbnail_url': 'https://i.ytimg.com/vi/lHXd2hBnlJk/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgWyhCMA8=&rs=AOn4CLAFFQIYhlOu6kNiN2BZrc_RI1XamQ', 'publish_date': '2022-04-20 00:00:00', 'length': 161, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"what is hard about training a machine learning model that does well let's look at some key challenges one framework that i hope you keep in mind when developing machine learning systems is that ai systems and machine learning systems comprise both code meaning the algorithm or the model as well as data there's been a lot of emphasis in the last several decades on how to improve the code in fact a lot of ai research had grown up by researchers downloading data sets and trying to find an algorithm or model that does well on the data set but for many applications you have the flexibility to change the data if you don't like the data and so there are many projects where the algorithm or model is basically a solve problem some model you download off github will do well enough and it'd be more efficient to spend a lot of your time improving the data because the data usually has to be much more customized to your problem this is a view that will carry throughout this week and next week's materials diving into more detail when building a machine learning system you may have an algorithm or a model this would be your code and some data and it's by training your algorithm on the data that you then have your machine learning model that can make predictions and of course hyper parameters are an additional input to this process it is important for many applications to make sure you have a well-tuned learning rate and regularization parameter and maybe a few other things the hyper parameters are important but because the space of hyper parameters is usually relatively limited i'm going to spend more of our time focusing on the code and on the data so model development is a highly iterative process you usually start off with some model and hyper parameters and data train the model and then take the model to carrier error analysis and use that to help you decide how to improve the model or the hyper parameters or the data because machine learning is such an empirical process being able to go through this loop many times very quickly is key to improving performance but one of the things that will help you improve performance too is each time through the loop being able to make good choices about how to modify the data or how to modify the model or how to modify the hyper parameters after you've done this enough times and achieve a good model one last step that's often useful is to carry out a richer error analysis and have your system go through a final audit to make sure that it is working before you push it to a production deployment so why is model development hard when building a model i think there are three key milestones that most projects should aspire to accomplish first is you probably want to make sure you do well at least on the training set so if you're predicting housing prices as a function of the size of a house are you at least able to fit a line that fits your training set quite well after you've done well on the training set you then have to ask if your algorithm does well on the development set or the holdout cross-validation set and then also the test set if your algorithm isn't even doing well on the training set then it's very unlikely to do well on the def set or the test set so i think of step one as something you have to do first as a milestone on your way towards achieving step two and then after you do well on the dev set or test set you also have to make sure that your learning algorithm does well according to the business metrics or according to the project skills over the last several decades a lot of machine learning development was driven by the goal of doing well on the dev set or test set unfortunately for many problems having a high tested accuracy is not sufficient for achieving the goals of the project and this has led to a lot of frustration and disagreements between the machine learning team which is very good at doing this and business teams which care more about the business metrics or some other goals of a project so you may be wondering hey andrew how is it possibly true that achieving low average tested error isn't good enough for a project there are a few common patterns that i've seen across many projects where you need something beyond low average test set era and people to spot these issues will help you be more efficient in addressing them let's dive more into this topic in the next video\", metadata={'source': 'oBB47VrQucA', 'title': '#10 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 2]', 'description': 'Unknown', 'view_count': 5467, 'thumbnail_url': 'https://i.ytimg.com/vi/oBB47VrQucA/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVSg_MA8=&rs=AOn4CLArqsDgm2vaCSoI6RgV8v4SUm-f7Q', 'publish_date': '2022-04-20 00:00:00', 'length': 311, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"the job of a machine learning engineer would be much simpler if the only thing we ever had to do was do well on the holdout test set as hard as it is to do well in the holdout test set unfortunately sometimes that isn't enough let's take a look at some of the other things we sometimes need to accomplish in order to make a project successful we've already talked about concept drift and data drift last week but here are some additional challenges we may have to address for a production machine learning project first a machine learning system may have low average test set error but if its performance on a set of disproportionately important examples isn't good enough then the machine learning system will still not be acceptable for production deployment let me use an example from web search there are a lot of web search queries like these apple pie recipes latest movies wireless data plan i want to learn about the diwali festival these types of queries are sometimes called informational or transactional queries where i want to learn about apple pies or maybe i want to buy a new wireless data plan and and you might be willing to forgive a web search engine that this doesn't give you the best apple pie recipe because there are a lot of good apple pie recipes on the internet so for informational and transactional queries a web search engine wants to return the most relevant results but users are willing to forgive maybe ranking the best result number two or number three there's a different type of web search query such as stanford or reddit or youtube these are called navigational queries where the user has a very clear intent very clear desire to go to stanford.edu or reddit.com or youtube.com when a user has a very clear navigational intent they will tend to be very unforgiving if a web search engine does anything other than return standard.edu as the number one ranked results and the search engine that doesn't give the right results will quickly lose the trust of his users so navigational queries in this context are a disproportionately important set of examples and if you have a learning algorithm that improves your average test and accuracy for web search but messes up just a small handful of navigational queries that may not be acceptable for deployment and the challenge of course is that average test set accuracy tends to weight all examples equally whereas in web search some queries are disproportionately important now one thing you could do is try to give these examples a higher weight that could work for some applications but in my experience just changing the ways of different examples doesn't always solve the entire problem closely related to this is the question of performance on key slices of the data set for example let's say you built a machine learning algorithm for loan approval to decide who is likely to repay a loan and thus to recommend approving certain loans for approval for such a system you will probably want to make sure that your system does not unfairly discriminate against loan applicants according to the ethnicity gender maybe the location the language or other protected attributes many countries also have laws or regulations that mandate that financial systems and loan approval processes not discriminate on the basis of a certain set of attributes sometimes called protected attributes so even if a learning algorithm for loan approval achieves high average tested accuracy it would not be acceptable for production deployment if it exhibits an unacceptable level of bias or discrimination whereas the ai community has had a lot of discussion about fairness to individuals and rightly so because this is an important topic we have to address and do well on the issue of quote fairness or performance of key slices also occurs in other settings let's say you run an online shopping website so an e-commerce website where you aggregate and sell products from many different manufacturers and many different brands of retailers you might want to make sure that your system treats fairly all major user retailer and product categories for example even if a machine learning system has high average tested accuracy maybe it recommends better products on average if it gives really irrelevant recommendations to all users of one ethnicity that may be unacceptable or if it always pushes products from large retailers and ignores the smaller brands that could also be harmful to the business because you may then lose all the small retailers and it would also feel unfair to build a recommended system that only ever recommends products from the large brands that ignores the smaller businesses or if you had a product recommender that gave highly relevant recommendations but for some reason would never recommend electronics products then maybe the retailers that sell electronics would be quite reasonably upset and this may not be the right thing for the retailers on your platform or for the long term health of your business even if the average tested accuracy shows that by not recommending electronics products you are showing slightly more relevant results to use to your users for some reason one thing you learn later this week is how to carry out analysis on key slices of the data to make sure that you spot and address potential problems like these next is the issue of rare classes and specifically of skewed data distributions in medical diagnosis is not uncommon for many patients not to have a certain disease and so if you have a data set which is 99 negative examples because 99 of the population doesn't have a certain disease but one percent positive then you can achieve very good tested accuracy by writing a program that just says print zero don't need a learning algorithm just write this one line of code and you have 99 accuracy on your data set but clearly print 0 is not a very useful algorithm for disease diagnosis by the way this actually did happen to me once where my team had trained a huge neural network found we had 99 average accuracy and we found it achieved it by printing zero all the time so we basically trained a giant neural network that did exactly the same thing as print zero and of course when we discovered this we then went back to fix the problem but so hopefully this won't happen to you closely related to the issue of skewed data distributions which is often a discussion of positive and negatives is accuracy on rare clauses i was working with my friend pranav rashberger and others on diagnosis from chess x-rays and we were diagnosing clauses and we were working on deep learning to spot different conditions there were some relatively common conditions these are technical medical terminology but for medical condition called effusion we had about ten thousand images and so we're achieving we were able to achieve a high level of performance whereas for a much rarer condition hernia we had about 100 images and so performance was much worse and it turns out that from a medical standpoint it's not acceptable for a diagnosis system to ignore obvious cases of hernia if a patient shows up and an x-ray clearly shows they have hernia a learning algorithm that misses that diagnosis would be problematic but because this was a relatively rare class the overall average tested accuracy of the algorithm was not that bad and in fact diagram could have completely ignored all cases of hernia and it would have had only a modest impact on this average chest set accuracy because cases of hernia were rare and the algorithm could pretty much ignore it without hurting this average tested accuracy that much if average tested accuracy gives equal weight to every single example in the test set i have heard pretty much this exact same conversation too many times in too many companies and the conversation goes like this a machine learning engineer says i did well on the test set this works let's use it and a product owner or business owner says but this doesn't work for my application and the machine learning engineer replies but i did well on the test set my advice to you if you ever find yourself in this conversation is don't get defensive we as a community have built lots of tools for doing well on the test set and that's to be celebrated i think it's great but we often need to go beyond that because just doing well on the test set isn't enough for many production applications when i'm building a machine learning system i view it as my job not just to do well on the test set but to produce a machine learning system that solves the actual business or application need and i hope you take a similar view as well later this week we'll go through some techniques usually involving error analysis maybe error analysis on slices of the data that will allow you to spot some of these issues that require going beyond average tested accuracy and help you with tools to tackle these broader challenges as well\", metadata={'source': 'fiDmWKh_WeQ', 'title': '#11 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 3]', 'description': 'Unknown', 'view_count': 9812, 'thumbnail_url': 'https://i.ytimg.com/vi/fiDmWKh_WeQ/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVyhEMA8=&rs=AOn4CLAwmKPa4TeP1AkNe5G9v2o-XfdUvQ', 'publish_date': '2022-04-20 00:00:00', 'length': 641, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"when starting work on a machine learning project one of the most useful first step to take is to establish a baseline and it's usually only after you've established a baseline level of performance that you can then have tools to efficiently improve on that baseline level let's dive into some best practices for quickly establishing that baseline let me use the speech recognition example let's say you've established that there are four major categories of speech in your data clear speech which is when someone speaks without much background noise speech with colonoids in the background as if they were in a car when they use your speech recognition system speech with people noise in the background deliver their outdoors with other people talk in the background or speech on a low bandwidth connection kind of what it sounds like if you're using a cell phone with a very bad cell phone connection if your accuracy on these four categories of speeches 94 89 87 70 accuracy you might be tempted to say wow it does worse on low bandwidth audio so let's focus our attention on that but before leaping to that conclusion it'd be useful to establish a baseline level of performance on all four of these categories you can do that by asking some human transcriptionist to label your data and measuring their accuracy what is human level performance on these four calories of speech in this example we find that if we can improve our performance on clear speech up to human level performance looks like there's a potential for a one percent improvement there if we can raise our performance up to human level performance on audio of colonoids in the background maybe four percent improvement two percent improvement and essentially zero percent improvement on low bandwidth audio and so whereas we had previously said without the human level performance we may have thought working on low bandwidth audio was most promising with this analysis we realized that maybe the low bandwidth audio is so global even people humans can't recognize what was said and it may not be that fruitful to work on that instead it may be more fruitful to focus our attention on improving speech recognition with car noise in the background so in this example using human level performance which i'll sometimes abbreviate to hlp human level performance gives you a point of comparison or baseline that helps you decide where to focus your efforts on car noise data rather than on low bandwidth data it turns out the best practices for establishing a baseline are quite different depending on whether you're working on unstructured or structured data unstructured data refers to data sets like images maybe pictures of cats or audio like our speech recognition example or natural language like text from restaurant reviews unstructured data tends to be data that humans are very good at interpreting in fact humans evolve to be very good at understanding images and audio and maybe language as well and because humans are so good at unstructured data tasks measuring human level performance or hlp is often a good way to establish a baseline if you are working on unstructured data in contrast structured data are the giant databases or the giant excel spreadsheets you might have such as if you run an e-com website the data showing which user purchased what at what time and for what price that will be stored in a giant database and this type of data stored in a giant excel spreadsheet or some more robust database would be an example of structured data or your product and inventory data you know that would also be stored as structured data because humans are not as good at looking at data like this to make predictions we certainly didn't evolve to look at giant spreadsheets human level performance is usually a less useful baseline for structured data applications i find that machine learning developments best practice is quite different depending on whether you're working on an unstructured data or structured data problem keeping in mind this difference let's take a look at some ways to establish baselines for both of these types of problems we've already talked about human level performance as a baseline particularly for unstructured data problems another way to establish a baseline is to do a literature search for save the art or look at open source results to see what others report they are able to accomplish on this type of problem for example if you're building a speech recognition system and others report a certain level of accuracy on data that's similar to yours then that may give you a starting point using open source you may also consider coming out with a quick and dirty implementation not a cisco system but just a quick and dirty implementation that could start to give you a sense of what may be possible finally if you already have a machine learning system running for your application then the performance of your previous system performance of your older system can also help you establish a baseline that you can then aspire to improve on what a baseline system or a baseline level of performance does is it helps to indicate what might be possible in some cases such as if you're using human level performance especially on unstructured data problems this baseline can also give you a sense of what is the irreducible error or what is bayes error in other words what is the best that anyone could possibly hope for in terms of performance on this problem such as helping us realize that maybe the low bandwidth audio is so bad that it's just not possible to have more than 70 accuracy as in our earlier example and by helping us to get a very rough sense of what might be possible it can help us be much more efficient in terms of prioritizing what to work on sometimes i've seen some business teams push a machine learning team to guarantee that their learning algorithm will be 80 accurate or 90 or 99 accurate before the machine learning team has even had a chance to establish a rough baseline this unfortunately puts the machine learning team in a very difficult position if you are in that position i would urge you to consider pushing back and asking for time to establish a rough baseline level of performance before giving a more firm prediction about how accurate the machine learning system can eventually get to be uh it helps you to make your case feel free to tell them that i asked you to do so and i think establishing that baseline first will help set you and your team up better for long-term success now that talks about the importance of baseline there are few additional tips i want to share with you about how to get started quickly on the machine learning project let's go on to the next video to take a look at some of these tips\", metadata={'source': 'O5mqR4EFBQk', 'title': '#12 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 4]', 'description': 'Unknown', 'view_count': 6390, 'thumbnail_url': 'https://i.ytimg.com/vi/O5mqR4EFBQk/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgXShHMA8=&rs=AOn4CLB0TpVHG0zrvfDE5o4IpzIuPnF17g', 'publish_date': '2022-04-20 00:00:00', 'length': 461, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"let me share with you a few tips for getting started on the machine learning project this video will be a little bit of a grab bag of different ideas but i hope nonetheless many of these ideas will be useful to you we've talked about how machine learning is an iterative process where you start with a model data hyper parameters create a model carry out error analysis and then use that to drive further improvements and after you've done this a few times gone around the loop enough times when you have a good enough model you might then carry out a final performance audit before taking it to production in order to get started on this first step of coming with a model here are some suggestions when i'm starting on the machine learning project i almost always start with a quick literature search to see what's possible so you can look at online courses look at blogs look at open source projects and my advice to you if your goal is to build a practical production system and not to do research is don't obsess about finding the latest greatest algorithm instead spend half a day maybe a small number of days reading blog posts and pick something reasonable that lets you get started quickly if you can find an open source implementation that can also help you establish a baseline more efficiently i find that for many practical applications a reasonable algorithm with good data will often do just fine and will in fact outperform a great algorithm with not so good data so don't obsess about taking the algorithm that was just published in some conference last week that is the most cutting-edge algorithm is that find something reasonable find a good open source implementation and use that to get going quickly because being able to get started on this first step of this loop can make you more efficient in iterating through more times and that will help you get to good performance more quickly second question of often asked is hey andrew do i need to take into account deployment constraints such as compute constraints when picking a model my answer is yes you should take deployment constraints such as compute constraints into accounts if the baseline is already established and you're relatively confident that this project will work and does your goal is to build and deploy a system but if you've not yet even established a baseline or if you're not yet sure if this project will work and be worthy of deployment then i would say no or maybe not necessarily and if you are in a stage of the project where your first goal is to just establish a baseline and determine what is possible and if this project is even worth pursuing for the long term then it might be okay to ignore deployment constraints and just find some open source implementation and try it out to see what might be possible even if that open source implementation is so computationally intensive that you know you will never be able to deploy that of course no harm taking deployment constraints into account as well at this phase of the project but it might also be okay if you don't and focus on more efficiently establishing the baseline first finally when trying out the learning algorithm for the first time before running it on all your data i would urge you to run a few quick sanity checks for your code and your algorithm for example i will usually try to over fit a very small training data set before spending hours or sometimes even overnight or days trading the album on the large data set maybe even try to make sure you can fit one training example especially if the output is a complex output for example i was once working on a speech recognition system where the goal was to input audio and have a learning algorithm output a transcript when i trained my algorithm on just one example one audio clip when i trained my speech recognition system on just one audio clip on the training set which is just one audio clip my system outputs this and output space space space space space space so clearly it wasn't working and because my speech system couldn't even accurately transcribe one training example there wasn't much point to spending hours and hours training on a giant training set or for image segmentation if your goal is to take as input pictures like this and segment out the cats in the image then before spending hours training your system on hundreds or thousands of images a worthy sanity check would be to feed it just one image and see if it can at least overfit that one training example before scaling up to a larger data set and the advantage of this is you may be able to train your algorithm on one or a small handful of examples in just minutes or maybe even seconds and this lets you find bugs much more quickly finally for image classification problems even if you have 10 000 images or 100 000 images or a million images in your training set it might be worthwhile to very quickly train your algorithm on a small subset of just 10 or maybe 100 images because you can do that quickly and if your algorithm can't even do well on a hundred images well then it's clearly not going to do well on ten thousand images so this would be another useful sanity check for your code now after you've trained a machine learning model after you've trained your first model one of the most important things is how do you carry out error analysis to help you decide how to improve the performance of your algorithm let's go on to the next video to dive into error analysis and performance auditing\", metadata={'source': '8Covj8F-NNc', 'title': '#13 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 5]', 'description': 'Unknown', 'view_count': 5365, 'thumbnail_url': 'https://i.ytimg.com/vi/8Covj8F-NNc/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgWyhDMA8=&rs=AOn4CLApqhKPfzI_OtifKVnUCHZamvka8A', 'publish_date': '2022-04-20 00:00:00', 'length': 384, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"the first time you train a learning algorithm you can almost guarantee that it won't work not the first time out so i think of the heart of the machine learning development process as error analysis which if you do it well can tell you what's the most efficient use of your time in terms of what you should do to improve your learning algorithm's performance let's start with an example let me walk through an error analysis example using speech recognition when i'm carrying out error analysis this is pretty much what i would do myself in a spreadsheet to get a handle on one of the errors of the speech system you might listen to maybe a hundred mislabeled examples from your death set from the development set so let's say the first example was labels with the ground truth label stir-fried lettuce recipe but your learning album's prediction was stir fry lettuce recipe if you have a couple of hypotheses for what are the major types of data in your data set maybe you think some of the data has car noise some of the data has people noise then you can build a spreadsheet and i literally do this in a spreadsheet with a couple columns like this and when you listen to this example if this example has car noise in the background you can then make a check mark or other annotation in your spreadsheet to indicate that this example had car noise then you listen to the second example maybe sweetened coffee got mistranscribed as swedish coffee and maybe this example had people noise in the background and maybe one example with sail away song was miss transcribed as selwy song and this again had people noise and let's catch up with transdrive as less ketchup and maybe this example had both call noise and people noise note that these tags up on top don't have to be mutually exclusive during this process of error analysis as you listen to audio clips you may come up with ideas for additional tags let's say this fourth example had a very low bandwidth connection and reflecting on the areas you're spotting you remember huh maybe quite a few of the audio clips have a low bandwidth connection at this point you may decide to add a new column to your spreadsheet with one more tag that says low bandwidth and check that and maybe go back to see if some of the other examples also had a low bandwidth connection so even though i went through this example using a slide when i'm doing error analysis myself sometimes i'll literally fire up a spreadsheet program like google sheets or excel or on a mac the numbers program and do it like this in the spreadsheet this process helps you understand whether the categories as denoted by tags that may be the source of more of the errors and thus may be worthy of further effort and attention until now error analysis has typically been done via a manual process say in a jupyter notebook or tracking errors in the spreadsheet i still sometimes do that way and if that's how you're doing it too that's fine but there are also emerging emma ops tools that making this process easier for developers for example when my team landing ai works on computer vision applications the whole team now uses landing lens which makes this much easier than a spreadsheet you've heard me say that training a model is an initial a model is an iterative process maybe it should come as no surprise that error analysis is also an iterative process where what a typical process would be is you might examine and tag some set of examples with an initial set of tags such as call noise and people noise and based on examining this initial set of examples you may come back and say you want to propose some new tags with the new tags you can then go back to examine and tag even more examples let me step through a few other examples of what such tags could be tick visual inspection you know the problem of finding defects in smartphones some of the tags could be specific class labels such as does this phone have a scratch or does have a dent and so on so it's fine if some of these tags are associated with specific clause labels why or some of the tags could be image properties is this picture of the phone blurry is it against a dark background or light background is there a unwanted reflection in this picture the tags could also come from other forms of metadata what is the phone model what is the factory which is the manufacturing line that captured this specific image and the goal of this type of process where you come over tags label more data common attacks is to try to come up with a few categories where you could productively improve the algorithm such as in our earlier speech example deciding to work on speech with car noise in the background let me step through just one more example product recommendations for an online e-commerce site you might look at what products a system is recommending to users and find the clearly incorrect or irrelevant recommendations and try to figure out if there are specific user demographics such as are we really badly recommending products to younger women or to older men or to something else or are there specific product features or specific product categories where the recommendations are particularly poor and by iteratively brainstorming and applying such tags you can hopefully come up with a few ideas for calories of data that are worth trying to improve your algorithm's performance on as you go through these different tags here are some useful numbers to look at first what fraction of errors have that tagged for example if you listen to 100 audio clips and find that 12 percent of them were labeled with the car noise tag then that gives you a sense of how important is it to work on car noise it tells you also that even if you fix all of the car noise issues the performance may improve only by 12 which is actually not bad or you can ask of all the data with that tag what fraction is misclassified so far we've only talked about tagging the mislabeled examples for time efficiency you might focus your attention on tagging the mislabel the misclassified examples but if there's a tag you can apply to both correctly labeled and to mislabeled examples then you can ask of all the data of that tag what fraction is misclassified so for example if you find that of all the data with call noise 18 of it is mistranscribed then that tells you that the performance on data with this type of tag has only a certain level of accuracy and tells you how hard these examples with car noise really are you might also ask what fraction of all the data has that tagged this tells you how important relative to your entire data set are examples with that tag so what fraction of your entire data set has car noise and then lastly how much room for improvement is there on data with that tag and one example that you've already seen for how to do this analysis is to measure human level performance on data with that tag so by brainstorming different tags you can segment your data into different categories and then use questions like these to try to decide what to prioritize working on let's dive more deeply into an example of doing this in the next video\", metadata={'source': 'quEHyoA94rw', 'title': '#14 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 6]', 'description': 'Unknown', 'view_count': 4840, 'thumbnail_url': 'https://i.ytimg.com/vi/quEHyoA94rw/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVihBMA8=&rs=AOn4CLA_qVxn2Ikv9_XPQSD4CMcAPeXkAg', 'publish_date': '2022-04-20 00:00:00', 'length': 508, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"in the last video you learned about brainstorming and tagging your data with different attributes let's see how you can use this to prioritize where to focus your attention here's the example we had previously with four tags and the accuracy of the algorithm human level performance and what's the gap between the current accuracy and human level performance rather than deciding to work on car noise because the gap to hlp is biggest one other useful factor to look at is what's the percentage of data with that tag let's say that sixty percent of your data is clean speech four percent is dated with car noise 30 has people noise and six percent is low bandwidth audio this tells us that if we could take clean speech and raise our accuracy from 94 to 95 on all the clean speech then multiplying 1 with 60 this tells us that if we could improve our performance on clear speech to human level performance our overall speech system would be 0.6 percent more accurate because we would do 1 better on 60 of the data so this will raise average accuracy by 0.6 percent on car noise if we can improve the performance by four percent on four percent of the data multiplying that out that gives us a 0.16 percent improvement and multiplying these out as well we get 0.6 percent and well this is essentially zero percent because we can't make that any better and so whereas previously we had said there's a lot of room for improvement in car noise in this slightly richer analysis we see that because people noise accounts for such a large fraction of the data it may be more worthwhile to work on either people noise or maybe on clean speech because there's actually larger potential for improvements in both of those than for speech with car noise so to summarize when prioritizing what to work on you might decide on the most important categories to work on based on how much room for improvement there is such as compared to human level performance or according to some baseline comparison how frequently does that carry appear you can also take into account how easy it is to improve accuracy in that category for example if you have some ideas for how to improve the accuracy of speech with car noise maybe your data augmentation that might cause you to prioritize that category more highly than some other category where you just don't have as many ideas for how to improve the system and then finally how important it is to improve performance on that category for example you may decide that improving performance with car noise is especially important because when you're driving you have a stronger desire to do search especially search on maps and find addresses without needing to use your hands if your hands are supposed to be holding the steering wheel there is no mathematical formula that will tell you what to work on but by looking at these factors i hope you'll be able to make more fruitful decisions once you've decided that you want to work on one category of data say data with car noise once you've decided that there's a category or maybe a few categories where you want to improve the album's performance one fruitful approach is to consider adding data or improving the quality of that data for that one or maybe a small handful of categories so for example if you want to improve performance on speech with car noise you might go out and collect more data with car noise or if you have a way of using data augmentation to get more data from that category that would be another way to improve your album's performance one topic that we'll discuss next week is how to improve label accuracy or data quality you learn more about this when we talk about the data phase of the machine learning project life cycle in machine learning we always would like to have more data but going out to collect more data generically can be very time consuming and expensive by carrying out an analysis like this when you are then going through this iterative process of improving your learning algorithm you can be much more focused in exactly what types of data you collect because if you decide to collect more data with car noise or maybe people noise you can be much more specific in going out to collect more of just that data or using data augmentation without wasting time trying to collect more data from a low bandwidth cell phone connection and this focus on improving your data on the tags that you have determined are most fruitful for you to work on that can help you be much more efficient in how you improve your learning algorithms performance i found this type of error analysis procedure very useful for many of my projects and i hope it will help you too in building production ready machine learning systems next one of the most common challenges we run into is skewed data sets let's go on to the next video to go through some techniques for managing skewed data sets\", metadata={'source': 'BdZ6bjcixhk', 'title': '#15 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 7]', 'description': 'Unknown', 'view_count': 4273, 'thumbnail_url': 'https://i.ytimg.com/vi/BdZ6bjcixhk/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGEggTShlMA8=&rs=AOn4CLCtsUYStl02gGIVla8ukpDT_uDw4Q', 'publish_date': '2022-04-20 00:00:00', 'length': 351, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"data sets where the ratio of positive to negative examples is very far from 50 50 are called skewed data sets let's look at some special techniques for handling them let me start with a manufacturing example if a manufacturing company makes smartphones hopefully the vast majority of them are not defective so if 99.7 have no defect and are labeled y equals zero and only a small fraction is labeled y equals one then print zero which is not a very impressive learning algorithm will achieve 99.7 accuracy or medical diagnosis which was the example we went through in an earlier video if 99 of patients don't have a disease then an algorithm that predicts no one ever has a disease will have 99 accuracy or speech recognition if you're building a system for wake word detection sometimes also called trigger word detection these are systems that listen and see if you say a special word like alexa or ok google or hey siri most of the time that special wake word or trigger word is not being spoken by anyone at that moment in time so when i had built wake word detection systems the data sets were actually quite skewed one of the datasets i use had 96.7 negative examples and 3.3 positive examples when you have a very skewed data set like this raw accuracy is not that useful a metric to look at because prints zero can get very high accuracy instead it's more useful to build something called the confusion matrix a confusion matrix is a matrix where one axis is labeled with the actual label so it's the ground truth label y equals zero or y equals one and whose other axis is labeled with the prediction so was your learning algorithms prediction y equals zero or y equals one so if you're building a confusion matrix you throw in with each of these four cells the total number of examples say the number of examples in your dev set in your development set that fell into each of these four buckets let's say that 905 examples in your development set had a ground truth label of y equals zero and your algorithm got it right then you might write 905 there these examples are called true negatives because they were actually negative and your algorithm predicted it was negative next let's throw in the true positives which are the examples where the actual ground truth label is one and the prediction is one maybe there are 68 of them true positives the false negatives are the examples where your algorithm thought it was negative but it was wrong the actual label is positive so these are false negatives some of the 18 of that and lastly false positives are the ones where your algorithm thought it was positive but that turned out to be false so 9 false positives the precision of the learning algorithm if i sum up over the columns 905 plus 9 is 940 and 18 68 is 86. so this is indeed a pretty skewed data set where out of a thousand examples there were 914 negative examples in just 86 positive examples so 8.6 positive 91.4 percent negative the precision of your learning algorithm is defined as follows it asks of all the examples that the average thought were positive examples what fraction did it get right so precision as is defined as true positives divided by true positives plus false positives in other words it looks at this row so of all the examples that your algorithm thought had a label of 1 which is 68 plus 9 of them 68 of them were actually right so the position is 68 over 68 plus 9 which is a 88.3 in contrast the recall asks of all the examples that were actually positive what fraction did your algorithm get right so recall is defined as true positives divided by true positives plus false negatives which in this case is 68 over 68 plus 18 which is 79.1 and the metrics of precision and recall are more useful than raw accuracy when it comes to evaluating the performance of learning algorithms on very skewed data sets let's see what happens if your learning algorithm outputs zero all the time it turns out it won't do very well on recall taking this example of where we had 914 negative examples and 86 positive examples if the algorithm outputs 0 all the time this is what the confusion matrix would look like 914 times it outputs zero with a ground truth of zero and 86 times it output zero with a ground truth of one so precision is true positives divided by true positives plus false positives which in this case turns out to be zero over zero plus zero which is not defined and unless your algebra actually output no positive labels at all you get some of the number that hopefully isn't zero over zero but more importantly if you look at recall which is true positives over true positives plus false negatives this turns out to be zero over zero plus 86 which is zero percent and so the print zero algorithm achieves zero percent recall which gives you an easy way to flag that this is not detecting any useful positive examples and the learning algorithm with some precision evens the high value precision is not that useful usually if this recall is so low so the standard metrics when i look at when comparing different models on skewed data sets are precision and recall where looking at these numbers helps you figure out and of all the examples that are truly positive examples what fraction did the algorithm manage to catch sometimes you have one model with a better recall and a different model with a better precision so how do you compare two different models there's a common way of combining precision and recall using this formula which is called the f1 score one intuition behind the f1 score is that you want an algorithm to do well on both precision and recall and if it does worse on either precision or recall that's pretty bad and so f1 is a way of combining precision and recall that emphasizes whichever of p or r positional recall is worse in mathematics this is technically called a harmonic mean between precision and recall which is like taking an average but placing more emphasis on whichever is the lower number so if you compute the f1 score of these two models it turns out it to be 83.4 using the formula below here and model 2 has a very bad recall so its f1 score is actually quite low as well and this lets us tell maybe more clearly that model 1 appears to be a superior model than model 2. for your application you may have a different weighting between precision and recall and so f1 isn't the only way to combine precision and recall it's just one metric that's commonly used for many applications let me step through one more example where precision and recall is useful so far we've talked about the binary classification problem with skewed datasets it turns out to also frequently be useful for multi-class classification problems if you're detecting defects in smartphones you may want to detect scratches on them or dents or pit marks this is what it looks like if someone took a screwdriver and poked a cell phone or discoloration of the cell phone's lcd screen or other material maybe all four of these defects are actually quite rare but you might want to develop an algorithm that can detect all four of them one way to evaluate how your album is doing on all four of these defects each of which can be quite rare would be to look at precision and recall of each of these four types of defects individually in this example the learning algorithm has 82.1 precision on finding scratches and 99.2 recall you find in manufacturing that many factories will want high recall because you really don't want to let the phone go out that is defective but if an algorithm has slightly lower precision that's okay because through a human re-examining the phone they will hopefully figure out that the phone is actually okay so many factories will emphasize high recall and by combining precision recall using f1 as follows this gives you a single number evaluation metric for how well your lram is doing on the four different types of defects and can also help you benchmark to human level performance and also prioritize what to work on next so instead of accuracy on scratches dense pit marks and discolorations using f1 score can help you to prioritize the most fruitful type of defect to try to work on and the reason we use f1 is because maybe all four defects are very rare and so accuracy would be very high even if the algorithm was missing a lot of these defects so i hope that these tools will help you both evaluate your algorithm as well as prioritize what to work on both in problems with skewed data sets and for problems with multiple rare classes now to wrap up this section on error analysis there's one final concept i hope to go over with you which is performance auditing i found for many projects this is a key step to make sure that your learning algorithm is working well enough before you push it out to a production deployment let's take a look at performance auditing\", metadata={'source': 'BlxnbyvHTyI', 'title': '#16 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 8]', 'description': 'Unknown', 'view_count': 4307, 'thumbnail_url': 'https://i.ytimg.com/vi/BlxnbyvHTyI/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVihAMA8=&rs=AOn4CLAOF5kbg43FfuI_80CzXRwg6F45EQ', 'publish_date': '2022-04-20 00:00:00', 'length': 734, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"even when your learning algorithm is doing well on accuracy or f1 score or some appropriate metric is often worth one last performance audit before you push it to production and this can sometimes save you from significant post-deployment problems let's take a look you've seen this diagram before after you've gone around this loop multiple times to develop a good learning algorithm it's worthwhile auditing his performance one last time here's a framework for how you can double check your system for accuracy for fairness buyers and for other possible problems step one is brainstorm the different ways the system might go wrong for example does the algorithm perform sufficiently well on different subsets of the data such as individuals of a certain ethnicity or individuals of different genders or does the algorithm make certain errors such as false positives or false negatives which you might worry about in skewed datasets or how does it perform on certain rare and important classes so the types of issues we talked about in the key challenges video earlier this week any of them that concern you you might include them in this list of brainstormed ways that the system might go wrong for all the ways that you're worried about the system going wrong you might then establish metrics to assess the performance of your algorithm against these issues one very common design pattern you see is that you often be evaluating performance on slices of the data so rather than evaluating performance on your entire def set you may be taking out all of the individuals of a certain ethnicity or all the individuals of a certain gender or all of the examples where there is a scratch defect on the smartphone but to take a subset of the data also call the slice of the data to analyze performance on those slices in order to check against these things that may be problems after establishing appropriate metrics ml ops tools can also help trigger an automatic evaluation for each model to order this performance for instance tensorflow has a package for tensorflow model analysis or tfma that computes detailed metrics on new machine learning models on different slices of data you learn more about this tool in the next course and as part of this process i would also advise you to get buy-in from the business or the product owner that these are the most appropriate set of problems to worry about and a reasonable set of metrics to assess against these possible problems and if you do find a problem then it is great that you discover this problem before pushing your system to production and you can then go back to update the system to address it before deploying a system that may cause problems downstream let's walk through this framework with an example i'm going to use speech recognition again if you built a speech recognition system you might then brainstorm the ways the system might go wrong so one thing i've looked at before for systems i worked on was accuracy on different genders and different ethnicities for example a speech system that does poorly on certain genders may be problematic or also ethnicities one type of analysis i've done before is to carry out analysis of our accuracy depending on the perceived accent of the speaker because we want to understand if the speech system's performance was a huge function of the accent of the speaker or you might worry about the accuracy on different devices because different devices may have different microphones and so if you do much worse on one brand of cell phone so that if there is a problem you can proactively fix it or finally this might not be an example you would have thought of but prevalence of root mis transcriptions here's one example of something that actually happens to some of deep learning.ai's causes one of our instructors lawrence moroney was talking about gans generative adversarial networks but because the transcription system was mistranscribing gans because this unfortunately is not a common word in english language and so the subtitles had a lot of references to gun and gang which were mistranscriptions of what the instructor actually said which is gang so it made it look like there's a lot of gun violence in that deep learning.ai course and we actually had to go in to fix it because we didn't want that much gun gang violence in the subtitles it turns out more generally that mistranscribing someone's speech into a rude word or a swear word that's perceived much more negatively than a more neutral mistranscription and so i build speech systems as well where we pay special attention to avoiding mistranscriptions that resulted in the speech system thinking someone said a swear word when maybe they didn't actually say that swear word based on this list of brainstorm ways that a speech system might go wrong you can then establish metrics to assess performance against these issues on the appropriate slices of data for example you can measure the mean accuracy of the speech system for different genders and for different accents represented in the data set and also check for accuracy on different devices and check for offensive or root words in the output i find that the ways a system might go wrong turns out to be very problem dependent different industries different tasks will have very different standards and in fact today all standards in ai for what to consider an unacceptable level of bias or what is fair and what is not fair those standards are still continuing to evolve in ai and in many specific industries so i would advise you to do a search for your industry to see what is acceptable and to keep current with standards of fairness and all of our growing awareness for how to make our systems more fair and less biased one last tip i find that rather than just one person trying to brainstorm what could go wrong for high stakes applications if you can have a team or sometimes even external advisors help you brainstorm things that you want to watch out for that can reduce the risk of you or your team being caught later by something that you hadn't thought of i know that even standards are still evolving from what we consider fair and sufficiently unbiased in many industries but this is one of the topics i think it'd be good for us to get ahead of and to proactively try to identify measure against and solve problems rather than deploy a system to be surprised much later by some unexpected consequences so that's it for performance auditing with this i hope you have higher confidence in your learning algorithm when you go out to push it to production\", metadata={'source': 'o4je1lSpyaw', 'title': '#17 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 9]', 'description': 'Unknown', 'view_count': 3959, 'thumbnail_url': 'https://i.ytimg.com/vi/o4je1lSpyaw/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgXihEMA8=&rs=AOn4CLAocqZNIlObtACmW4kAhL-qSMhP-A', 'publish_date': '2022-04-20 00:00:00', 'length': 477, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"let's say that error analysis has caused you to decide to focus on improving your learning algorithm's performance on data with a certain category attack say speech with car noise in the background let's take a look at how you can take a data centric approach to improving your learning algorithm's performance you've heard me speak before about model centric versus data centric ai development here's a little more detail on what i mean with a model centric view of ai development you would take the data you have and then try to work really hard to develop a model that does as well as possible on the data because a lot of academic research in ai was driven by researchers downloading a benchmark data set and trying to do well on that benchmark most academic research on ai is model centric because the benchmark data set is a fixed quantity so in this view model centric development you would hold the data fix and iteratively improve so in this model centric view you would hold the data fix and iteratively improve the code or the model there's still an important role to play in trying to come up with better models but there's a different view of ai developments which i think is more useful for many applications which is to shift a bit from a model sentry toward a data centric view in this view we think of the quality of the data as paramount and you can use tools such as error analysis or data augmentation to systematically improve the data quality and for many applications i find that if your data is good enough there are multiple models that will do just fine so in this view you can instead hold the code fix and iteratively improve the data there's a role for model centric development and there's a role for data centric development if you've been used to model-centric thinking for most of your experience with machine learning i would urge you to consider taking a data centric view as well where when you're trying to improve your learning album's performance try asking how can you make your data set even better one of the most important ways to improve the quality of a data set is data augmentation so let's go on to the next video where we'll start to take a look at data augmentation\", metadata={'source': 'k3UYUmp3Bi4', 'title': '#18 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 10]', 'description': 'Unknown', 'view_count': 3373, 'thumbnail_url': 'https://i.ytimg.com/vi/k3UYUmp3Bi4/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgXihDMA8=&rs=AOn4CLBv5UiQsUTXGCyOgMBq0bVutYddyA', 'publish_date': '2022-04-20 00:00:00', 'length': 160, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"there's a picture a conceptual picture that i found useful for thinking about data augmentation and how this can help the performance of a learning algorithm let me share this picture of you since i think you find it useful too when trying to decide whether to use data augmentation take speech recognition there could be many different types of noise in speech input such as call noise play noise train noise machine noise or cafe noise or library noise which isn't that loud or food court noise maybe these types of noises are more similar to each other because they're all mechanical types of noise and these types of noise may be a little bit more similar to each other with mainly people talking and interacting with each other so let me share with you a picture that i keep in mind when i'm planning out my activities on getting more data through data augmentation or through actual data collection of any of these types of data in this diagram the vertical axis represents performance say accuracy and on the horizontal axis and this is a conceptual kind of a thought experiment type of axis i'm going to represent the space of possible inputs so for example there's speech with call noise and play noise and train noise sound a bit like colonoids so they're quite similar and machine noise is a little bit further away by machine noise i'm picturing the sounds of a washing machine or a very loud air conditioner say then you may have speech with cafe noise library noise or food court noise and those are maybe more similar to each other than to these types of mechanical noise your system will have different levels of performance on these different types of inputs let's say the performance is this for data play noise that with car noise train noise machine noise and it does worse on data with library noise cafe noise food court noise and so i think of there as being a curve or maybe think of this like a one-dimensional piece of rubber band or like a rubber sheet that shows how accurate your speech system is as a function of the type of input it gets a human will have some other level of performance on these different types of data so maybe a human is a bit better with play noise bit better on car noise and so on and maybe they are much better than your algorithm on library noise caffeine noise and food chord noise so the human level performance is represented via some other curve and let me just label this as the current model's performance in blue so this gap represents an opportunity for improvement now what happens if you use data augmentation or maybe not data augmentation but go out to a bunch of actual cafes to collect a lot more data with caffeine noise in the background what you would do is you would take this point imagine grabbing a hold of this blue rubber band or this rubber sheet and pulling it upwards like so that's what you're doing if you collect or somehow get more data with caffeine noise and add that to your training set you're pulling up the performance of the algorithm on inputs with caffeine noise and what that will tend to do is pull up this rubber sheet in the adjacent region as well so if performance on cafe noise goes up probably performance on the nearby points will go up too and performance on far away points may or may not go up as much it turns out that for unstructured data problems pulling up one piece of this rubber sheet is unlikely to cause a different piece of the rubber sheet to dip down really far below instead pulling up one point causes nearby points to be pulled up quite a lot and far away points may be pulled up a little bit or if you're lucky maybe more than a little bit but when i'm planning how to improve my learning album's performance and where i hope to get it to and getting more data in those places to interestingly pull up with those pieces or those parts of the rubber sheet to get them closer to human level performance and when you pull up part of the rubber sheet the location of the biggest gap may shift to somewhere else and error analysis will tell you what is the location of this new biggest gap that may then be worth your effort to collect more data on and therefore to try to pull up one piece at a time and this turns out to be a pretty efficient way to decide where on the blue rubber sheet to pull up next to try to get performance closer to say human level performance i hold this analogy of a rubber band or a rubber sheet and repeatedly pulling up a point on this driver sheet will help you predict the effects of collecting more data that's associated with a specific category or a specific tag how do you get more of this data let's take a look at how you can perform data augmentation and some best practices doing so in the next video\", metadata={'source': 'uot5sbPz1NQ', 'title': '#19 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 11]', 'description': 'Unknown', 'view_count': 3416, 'thumbnail_url': 'https://i.ytimg.com/vi/uot5sbPz1NQ/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgXihDMA8=&rs=AOn4CLD1UWOjk9WFYj658He3kH_JFY8zxA', 'publish_date': '2022-04-20 00:00:00', 'length': 359, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"data augmentation can be a very efficient way to get more data especially for unstructured data problems such as images audio maybe text but when carrying out data augmentation there are a lot of choices you have to make what are the parameters how do you design the data augmentation setup let's dive into this to look at some best practices take speech recognition given an audio clip like this ai is the new electricity if you take background cafe noise it sounds like this [Music] and add these two audio clips together literally take the two waveforms and sum them up then you can create a synthetic example that sounds like this ai is the new electricity so it sounds like someone's saying ai is a new electricity in a noisy cafe this is one form of data augmentation that lets you efficiently create a lot of data that sounds like data collected in the cafe or if you take the same audio ai as the new electricity and add it to background music then it sounds like someone's saying it with maybe the radio on in the background ai is the new electricity now when carrying out data augmentation there are few decisions you need to make what types of background noise should you use and how loud should the background noise be relative to the speech let's take a look at some ways of making these decisions systematically the goal of data augmentation is to create examples that your learning algorithm can learn from as a framework for doing that i encourage you to think of how you can create realistic examples that the algorithm does poorly on because if the algorithm already does well on those examples then there's less for it to learn from but you want the examples to still be ones that a human or maybe some of the baseline can do well on because otherwise one way to generate examples that the algorithm does poorly on would be to just create examples that are so noisy that no one can hear what anyone said but that's not helpful you want examples that are hard enough to challenge the algorithm but not so hard that they're impossible for any human or any algorithm to ever do well on and that's why when i am generating new examples using data augmentation i try to generate examples that meets both of these criteria now one way that some people do data augmentation is to generate an augmented data set and then train the learning algorithm and see if the algorithm does better on the data set and then fiddle around with the parameters for data augmentation and train the learning algorithm again and so on this turns out to be quite inefficient because every time you change your data augmentation parameters you need to train your neural network or train your learning algorithm all over and this can take a long time instead i found that using these principles allows you to sanity check that your new data generated using data augmentation is useful without actually having to spend maybe hours or sometimes days of training a learning algorithm on that data to verify that it will result in the performance improvement so specifically here's a checklist you might go through when you are generating new data one does it sound realistic you want your audio to actually sound like realistic audio of the sort that you want your algorithm to perform on two is the x to y mapping clear in other words can humans still recognize what was said this is to verify point two here and three is the algorithm currently doing poorly on this new data and that helps you verify points one if you can generate data that means all of these criteria then that will give you a higher chance that when you put this data into your training set and retrain the algorithm that that will result in you successfully pulling up part of this rubber sheet let's look at one more example using images this time let's say that you have a very small set of images of smartphones with scratches here's how you may be able to use data augmentation you can take the image and flip it horizontally this results in a pretty realistic image the phone buttons are now on the other side but this could be a useful example to add to your training set or you could implement contrast changes uh i've actually brightened up the image here so the scratch is a little bit more visible or you could try darkening the image but in this example the image is now so dark that even i as a person can't really tell if there's a scratch there or not and so whereas these two examples on top would pass the checklist we had earlier that the human can still detect the scratch well this example is too dark it would fail that checklist and so i would try to choose a data augmentation scheme that generates more examples that look like the ones on top and few of the ones that look like the ones here at the bottom and in fact going off the principle that we want images that look realistic that humans can do well on and hopefully the album does poorly on you can also use more subscripted techniques such as take a picture of the phone with no scratches and use photoshop in order to artificially draw a scratch and this technique literally using photoshop can also be an effective way to generate more examples because this example with a scratch here you may or may not be able to see it depending on the video compression and image contrast where you're watching this video but with a scratch here this looks like a pretty realistic scratch this is actually generated a photoshop and i as a person can recognize the scratch and so if the learning algorithm isn't detecting this right now this would be a great example to add i've also used more advanced techniques like gans generative adversarial networks to synthesize scratches like these automatically although i've found that techniques like that can also be overkill meaning that the simpler techniques are much faster to implement that work just fine without the complexity of building again to synthesize scratches you may have heard of the term model iteration which refers to iteratively training a model using our analysis and then trying to decide how to improve the model taking a data centric approach to ai development sometimes it's useful to instead use a data iteration loop where you repeatedly take the data and the model train your learning algorithm do error analysis and as you go through this loop focus on how to add data or improve the quality of the data and for many practical applications taking this data iteration loop approach with a robust hyper parameter search that's important too but taking a data iteration loop approach results in faster improvement to your learning album's performance depending on your problem so when you're working on an unstructured data problem data augmentation if you can create new data that seems realistic that humans can do quite well on but the album struggles on that can be an efficient way to improve your learning algorithm's performance and so if you found through error analysis that your learning algorithm does poorly on speech with cafe noise data augmentation to generate more data with caffeine noise could be an efficient way to improve your learning album's performance now when you add data to your system question i've often often been asked is can adding data hurt your learning album's performance usually for unstructured data performance the answer is no with some caveats but let's dive more deeply into this in the next video\", metadata={'source': 'foCIxwn7VpI', 'title': '#20 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 12]', 'description': 'Unknown', 'view_count': 3530, 'thumbnail_url': 'https://i.ytimg.com/vi/foCIxwn7VpI/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgXChDMA8=&rs=AOn4CLArFSNWIje9nsGXKbxTQq8k7G1rlw', 'publish_date': '2022-04-20 00:00:00', 'length': 527, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"for a lot of machine learning problems the training sets and depth and test set distribution start up being reasonably similar but if you're using data augmentation you're adding to specific parts of the training set such as adding lots of data with cafe noise so now your training set may come from a very different distribution than the deaf set and the test set is this going to hurt your learning algorithms performance usually the answer is no with some caveats when you're working on unstructured data problems but let's take a deeper look at what that really means if you are working on an unstructured data problem and if your model is large such as a neural network that is quite large and has large capacity and thus low bias and if the mapping from x to y is clear and by that i mean given only the input x humans can make accurate predictions then it turns out adding accurately labeled data rarely hurts accuracy this is an important observation because adding data through data augmentation or collecting more of one type of data can really change your input data distribution the probability of x let's say at the start of your problem 20 of your data had cafe noise but using augmentation you added a lot of caffeine noise so now this is 50 of your data is dated with caffeine noise in the background it turns out that so long as your model is sufficiently large then it won't stop it from doing a good job on the caffe noise data as well as doing a good job on non-caffe noise data in contrast if your model was small then changing your input data distribution this way may cause it to spend too much of its resources modeling caffeine noise settings and this could hurt his performance on non-caffeine noise data but if your model is large enough then this isn't really an issue the second problem that could arise is if the mapping from x to y is not clear meaning given x the true label of y is very ambiguous this doesn't really happen much in speech recognition but let me illustrate this with an example from computer vision this is very rare so it's not something i would worry about for most practical problems but let's see why this is important one of the systems i had worked on many years ago google street view images to read host numbers in order to more accurately geolocate buildings and hoses in google maps so one of the things that system did was take as input pictures like this and figure out what is this digit so clearly this is a one and this is a alphabet i you don't see a lot of eyes in street view images but there are some buildings you know you may see a sign that says navigate to house number 42 i but house numbers really rarely have an alphabet i in it now if you find that your algorithm has very high accuracy on recognizing once but low accuracy on recognizing eyes one thing you might do is add a lot more examples of eyes into your training set and the problem and this is a rare problem is there are some images that are truly ambiguous is this a one or is this an eye and if you were to add a lot of new eyes to your training set especially ambiguous examples like this then that may skew the data set to have a lot more eyes and hurt performance because we know that there are a lot more ones than eyes on house numbers if the learning algorithm sees a picture like this it would be safer to guess that this is a one rather than that this is an i but if data augmentation skews the data set in the direction of having a lot more eyes rather than a lot of ones then it may cause the algorithm to guess poorly on an ambiguous example like this so this is one rare example where adding more data could hurt performance and this example of one versus i is one that contradicts the second bullet because for some images the mapping from x to y is not clear in particular given only an image like this on the right even a human can't really tell what this is just to be clear the example that we just went through together is a pretty rare almost corner case and it's quite unusual for data augmentation or adding more data to hurt the performance of your learning algorithm so long as your model is big enough maybe your neural network is big enough to learn from a diverse set of data sources but i hope that understanding this rare case where it could hypothetically hurt gives you more comfort with using data augmentation or collecting more data to improve the performance of your algorithm even if it causes your training set distribution to become different from your def set and test set distribution so far our discussion has focused on unstructured data problems how about structured data problems it turns out there's a different set of techniques that's useful for structured data let's take a look at that in the next video\", metadata={'source': 'O9ZrPXPLmWg', 'title': '#21 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 13]', 'description': 'Unknown', 'view_count': 3570, 'thumbnail_url': 'https://i.ytimg.com/vi/O9ZrPXPLmWg/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgXChCMA8=&rs=AOn4CLBZUshmQ7mkZ3Mi3HDezBDFkRSxLQ', 'publish_date': '2022-04-20 00:00:00', 'length': 376, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"for many structured data problems it turns out that creating brand new training examples is difficult but there's something else you could do which is to take existing training examples and figure out if there are additional useful features you can add to it let's take a look at an example let me use an example of restaurant recommendations where if you're running an app that has to recommend restaurants to users that may be interested in checking out certain restaurants one way to do this would be to have a set of features for each user or for each person and a set of features for each restaurant that then get fed in to some learning algorithm say a neural network and then your network whose job it is to predict whether or not this is a good recommendation whether to recommend this restaurant to that person in this particular example which is a real example error analysis showed that the system was unfortunately frequently recommending to vegetarians restaurants that only had meat options there were users that were pretty clearly vegetarian based on what they had ordered before and the system was still sending to them maybe a hot new restaurant that they recommended because it's a hot new restaurant but it didn't have good vegetarian options so this wasn't a good experience for anyone and there was a strong desire to change this now i didn't know how to synthesize new examples of uses or new examples of restaurants because this application had a fixed pool of uses and there were only so many restaurants so rather than trying to use data augmentation to create brand new people or restaurants to feed the training set i thought it was more fruitful to see if there were features to add to either the person inputs or to the restaurant inputs specifically one feature you can consider adding is a feature that indicates whether this person appears to be vegetarian and this doesn't need to be a binary value feature zero one it could be soft features such as the percentage of food ordered that was vegetarian or some other measure of how likely they seem to be vegetarian and a feature to add on the restaurant side would be does this restaurant have vegetarian options or good vegetarian options based on the menu for structured data problems usually you have a fixed set of users or a fixed set of restaurants or fixed set of products making it hard to use data augmentation or collect new data from new users that you don't have yet on restaurants that may or may not exist instead adding features can be a more fruitful way to improve the performance of the algorithm to fix problems like this one identified through error analysis additional features like these can be hand coded or they could in turn be generated by some learning algorithm such as having a learning algorithm try to read the menu and classify meals as vegetarian or not or having people code this manually could also work depending on your application some other food delivery examples we found that there were some users that would only ever order a tea and coffee and some users they would only ever order a pizza so if the product team wants to improve the experience of these users a machine learning team might ask what are the additional features we can add to detect who are the people that only order tea or coffee or who are the people that only ever order pizza and enrich the user features so as to help the learning algorithm make better recommendations for restaurants that these users may be interested in over the last several years there's been a trend in product recommendations of a shift from collaborative filtering approaches to what content-based filtering approaches collaborative filtering approaches is loosely an approach that looks at the user tries to figure out who's similar to that user and then recommends things to you that people like you also liked in contrast a content based filtering approach will tend to look at you as a person and look at the description of the restaurant or look at the menu of the restaurants and look at other information about the restaurant to see if that restaurant is a good match for you or not the advantage of content based filtering is that even if there's a new restaurant or a new product that hardly anyone else has liked by actually looking at the description of the restaurant rather than just looking at who else likes the restaurants you can more quickly make good recommendations this is sometimes also called the code start problem of how do you recommend a brand new product that almost no one else has purchased or liked or disliked so far and one of the ways to do that is to make sure that you capture good features for the things that you might want to recommend unlike collaborative filtering which requires a bunch of people to look at the product and decide if they like it or not before it can decide whether a new user should be recommended the same product so data iteration for structured data problems may look like this you saw that with some model train the model and then carry out error analysis error analysis can be harder on structured data problems if there is no good baseline such as human level performance to compare to and human level performance is hard for structured data because it's really difficult for people to recommend good restaurants even to each other but i found that error analysis can discover ideas for improvement so can user feedback and so can benchmarking to competitors but through these methods if you can identify a academy or a certain type of tag associated with your data that you want to drive improvement then you may be able to go back to select some features to add such as features to figure out who's vegetarian and what restaurants have good vegetarian options that would help you to improve your model and because the specific application may have only a finite list of uses and restaurants the users and restaurants you have maybe all the data you have which is why adding features to the examples you have may be a more fruitful approach compared to trying to come up with new users or new restaurants and of course i think features are a form of data too which is why this form of data iteration where error analysis helps you decide how to modify the features that can be an efficient way as well of improving your learning algorithm's performance i know that many years ago before the rise of deep learning part of the hope for deep learning was that you don't have to hand design features anymore i think that has for the most part come true for unstructured data problems so i use the hand design features for images i just don't do that anymore let the learning album figure it out but even with the rise of modern deep learning if your data set size isn't massive there is still designing of features driven by error analysis that can be useful for many applications today the larger data set the more likely it is that a pure end-to-end deep learning algorithm can work but for anyone other than the largest tech companies and sometimes even them for some applications designing features especially for structured data problems can still be a very important driver of performance improvements maybe just don't do that for unstructured data nearly as much because learning algorithms are very good and learning features automatically for images audio and for attacks maybe but for structured data it's okay to go in and work on the features\", metadata={'source': 'DTd7TyY7a-0', 'title': '#22 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 14]', 'description': 'Unknown', 'view_count': 3318, 'thumbnail_url': 'https://i.ytimg.com/vi/DTd7TyY7a-0/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgVyg9MA8=&rs=AOn4CLDZS1Q29bPl7h9Wo00G07c0HXazHA', 'publish_date': '2022-04-20 00:00:00', 'length': 524, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"as you're working to iteratively improve your algorithm one thing that'll help you be a bit more efficient is to make sure that you have robust experiment tracking let's take a look at some best practices when you're running dozens or hundreds or maybe even more experiments it's easy to forget what experiments you have already run having a system for tracking your experiments can help you be more efficient in making the decisions on the data or the model or hyper parameters to systematically improve your algorithm's performance when you're tracking the experiments you've run meaning the models you've trained here are some things i would urge you to track one is to keep track of what album you're using and what version of code um keeping a record of this will make it much easier for you to go back and replicate an experiment you had run maybe two weeks ago and whose details you may not fully remember anymore second keep track of the data set you use third hyperparameters and fourth save the results somewhere this should include at least the high level metrics such as accuracy or f1 score or the relevant metrics but if possible it'd be useful to just save a copy of the trained model so how can you track these things here are some tracking tools you might consider a lot of individuals and sometimes even teams will start off with text files so when i'm running experiment by myself i might use a text file to just make a note with a few lines of text per experiment to note down what i was doing this does not scale well but it may be okay for small experiments a lot of teams then migrate from text files to spreadsheets especially shared spreadsheets if you're working on a team where different columns of a spreadsheet can keep track of the different things you want to track for the different experiments you're running and spreadsheets actually scale quite a bit further especially shared spreadsheets that multiple members of a team may be able to look at but beyond a certain point some teams will also consider migrating to a more formal experiment tracking system the space of experiment tracking systems is still evolving rapidly and so there's a growing set of tools out there but some examples include waste and biases comets ml flow sagemaker studio landing ai ram ceo also has his own experiment tracking to focusing on computer vision and manufacturing applications when i'm trying to use a tracking tool whether a text file or a spreadsheet or some larger system here are some of the things i look at first is does it give me all the information needed to replicate the results and when in terms of rep in terms of replicability one thing to watch out for is if your learning algorithm pulls data off the internet because data of the internet can change that can decrease replicability unless you're careful in how your system is implemented second tools that help you quickly understand the experimental results of a specific training run ideally with useful summary metrics and maybe even a bit of a in-depth analysis can help you more quickly look at your most recent experiments or even look at older experiments and remember what had happened finally some other features to consider resource monitoring how much cpu or gpu memory resources did they use or tools to help you visualize the trained model or even tools to help you with a more in-depth error analysis i found all of these to sometimes be useful features of experiment tracking frameworks rather than worrying too much about exactly which experiment tracking framework to use though the number one thing i hope you take away from this video is do try to have some system even if it's just a text file or just a spreadsheet for keeping track of your experiments and include as much information as is convenient to include because later on if you're trying to look back remember how you had generated a certain model having that information would be really useful for helping you to replicate your own result\", metadata={'source': 'A2bnWAIpLIo', 'title': '#23 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 15]', 'description': 'Unknown', 'view_count': 2862, 'thumbnail_url': 'https://i.ytimg.com/vi/A2bnWAIpLIo/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGEYgTihyMA8=&rs=AOn4CLBU1B8wMlV4vitFPVpHPnfb914PLA', 'publish_date': '2022-04-20 00:00:00', 'length': 283, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"you've learned about taking a data-centric approach to ai development i'd like to leave you with a thought on shifting from big data to good data here's what i mean a lot of modern ai had grown up in large consumer internet companies with maybe a billion users and thus companies like that have a lot of data on their users if you have big data like that by all means it could help the performance if you have room tremendously but both for software consumer internet but equally importantly for many other industries there just isn't a billion data points and i think it may be even more important for those applications to focus not just on big data but on good data i found that if you're able to ensure consistently high quality data in all phases of the machine learning project life cycle that is key to making sure that you have a high performance and reliable machine learning deployment what do i mean by good data i think good data covers the important cases so you should have good coverage of different input x and if you find out that you don't have enough data with speech with caffeine noise data augmentation can help you get more data get more diverse inputs x to give you that coverage so we spent quite a bit of time talking about this in this week's material good data is also defined consistently with definition of labels why that's unambiguous we haven't talked about this yet but we'll go into much greater depth on this next week good data also has timely feedback from production data we actually talked about this last week when we were covering the deployment section in terms of having monitoring systems to track concept drift and data drift and finally you do need a reasonable size data set so to summarize during the machine learning project life cycle we've talked about during the deployment phase last week how to make sure you have timely feedback this week as we talked about modeling we also included in our discussion how to make sure you have hopefully good coverage of important cases next week when we dive into data definition we'll spend much more time to talk about how to make sure your data is defined consistently and i hope that with the ideas conveyed last week this week and next week you'll be armed with the tools you need to give your learning algorithm good data through all phases of the machine learning project life cycle so that's it congratulations on getting to the end of this week's videos on modeling i look forward to diving more deeply with you into the data part of the full cycle of a machine learning project and next week we'll also have a short optional section on scoping machine learning projects i look forward to seeing you next week\", metadata={'source': 'qOEeK1SNF3k', 'title': '#24 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 16]', 'description': 'Unknown', 'view_count': 2736, 'thumbnail_url': 'https://i.ytimg.com/vi/qOEeK1SNF3k/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgWihJMA8=&rs=AOn4CLDssYizzJaag1cLBvt5RrhecBOlIg', 'publish_date': '2022-04-20 00:00:00', 'length': 211, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"you're now in the third and final week of this course just one more week and then you'll be done with this first course of the specialization in this week we'll dive into data how do you get data that sets up your training your modeling for success but first why is defining what data to use even hard let's look at an example i'm going to use the example of detecting iguanas one of my friends and cartoon fruit is really like iguanas so have a bunch of iguana pictures floating around let's say that you've gone into the forest and collected hundreds of pictures like these and you sent these pictures to labelers with the instructions please use bounding boxes to indicate the position of iguanas one labeler may label it like this and say one iguana to iguanis this label did a good job a second labor that is equally hardworking equally diligent may say look the iguana on the left has a tail that goes all the way to the right of this image so the second labor may say one iguana to iguanas good job labor hard to fault this labor either a third layer may say well i'm going to look through all hundreds of images and label them all and i'm going to use boundary boxes and so let me indicate the position you go honors and draw a bounding box like that three diligent hard-working laborers can come up with these three very different ways of labeling iguanas and maybe any of these is actually fine i would prefer the top two rather than third one but any of these labeling conventions could result in your learning algorithm learning a pretty good iguana detector but what is not fine is if one-third of your label is used the first and one-third the second and one-third the third labeling convention because then your labels are inconsistent and this is confusing to the learning algorithm while the iguana example was a fun one you see this type of effect in many practical computer vision problems as well let's use the phone defect detection example if you ask the labor to use bounding boxes to indicate significant defects say maybe one labor will look at and go oh well clearly the scratch is the most significant defect let me draw a bounty bounce on that a second labeler may look at this phone and say there are actually two significant defects there's a big scratch and then there's that small mark there it's called a pit mark kind of like if someone poked the phone with a sharp screwdriver i think the second layer probably did a better job but then a third laborer may look at this and say well here's a bounding box that shows you where the defects are between these three labels probably the one in the middle would work the best but this is a very typical example of inconsistent labeling that you will get back from a labeling process with even slightly ambiguous labeling instructions and if you can consistently label the data with one convention maybe the one in middle your learning algorithm will do better what we will do in this week is dive into best practices for the data stage of the full cycle of a machine learning project specifically we'll talk about how to define what is the data what should be x and what should be y and establish a baseline and doing that well will set you up to label and organize the data well which will give you a good data set for when you move into the modeling phase which you already saw last week many machine learning researchers and many machine learning engineers had started off downloading data off the internet to experiment with models so using data prepared by someone else nothing at all wrong with that and for many practical applications the way you prepare your data sets will have a huge impact on the success of your machine learning project in the next video we'll take a look at some more examples of how data can be ambiguous so that this will set us up later this week for some techniques for improving the quality of your data let's go on to the next video\", metadata={'source': '0aDhjrs8FMw', 'title': '#25 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 1]', 'description': 'Unknown', 'view_count': 2986, 'thumbnail_url': 'https://i.ytimg.com/vi/0aDhjrs8FMw/hqdefault.jpg?sqp=-oaymwExCJADEOABSFryq4qpAyMIARUAAIhCGAHwAQH4Af4JgALQBYoCDAgAEAEYQiBKKGUwDw==&rs=AOn4CLASlQF7TraSGGTeO8yqdr6b_plvVg', 'publish_date': '2022-04-20 00:00:00', 'length': 258, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"in the last video you saw how the right bounding boxes for an image can be ambiguous let's take a look at some more label ambiguity examples we briefly touched on speech recognition in the first week of this course here's another example given this audio clip sounds like someone was standing on a busy roadside asking for the nearest gas station and then a car drove past so did they say something right after that i don't know so one way to transcribe this would be um nearest gas station and in some places people spell um with two m's so that would be a different way to spell it and we could have used dot dot dots or ellipses instead of the comma as well which would be another ambiguity or given the audio had noise after the last words um did they say something off the nearest gas station i'm not sure actually so would you transcribe it like this instead so there are combinatorially many ways to transcribe this um with one m or two m's commodore ellipses whether to write unintelligible at the end of this being able to standardize on one convention will help your speech recognition algorithm let's also look at an example of structured data a common application in many large companies is user id merge that's when you have multiple data records that you think correspond to the same person and you want to merge these user data records together for example say you run a website that offers online listings of jobs so this may be one data record that you have from one of your registered users with the email first name last name and address now say your company acquires a second company that runs a mobile app that allows people to log in to chat and get advice from each other about their resumes it seems synergistic for your business if you run a listing of online jobs maybe you merge or acquire a second company that runs a mobile app that lets people chat about their resumes and from this mobile app you have a different database of users so given this data record and this one do you think these two are the same person one approach to the user id merge problem is to use a supervised learning algorithm that takes as input to user data records and tries to output either one or zero based on whether it thinks these two are actually the same physical human being if you have a way to get ground truth data records such as if a handful of users are willing to explicitly link the two accounts then that could be a good set of labeled examples to train an algorithm but if you don't have such a ground true set of data what many companies have done is ask human laborers sometimes a product management team to just manually look at some pairs of records that have been filtered to maybe similar names or similar zip codes and then to just use human judgment to determine if these two records appear to be the same person because whether these two records really is the same person is genuinely ambiguous they may and they may not be different people will label these records inconsistently and if there's a way to just get them to label the data a little more consistently you see some examples of how to do this later even when the ground truth is ambiguous then that can help the performance of your learning algorithm user id merging is a very common function in many companies let me just ask you to please do this only in ways that are respectful of the user's data and their privacy and only if you are using the data in a way consistent with what they have given you permission for you know user privacy is really important a few other examples from structured data if you are trying to use a learning algorithm to look at a user account like these and predict is it a bot or a spam account sometimes that can be ambiguous or if you look at a online purchase is this a fraudulent transaction so has someone stole an account and is using a stolen accounts to interact with your website or to make purchases sometimes that too is ambiguous or if you look at someone's interactions with your website and you want to know are they looking for a new job at this moment in time based on how someone behaves on a job board website or a resume chat app you can sometimes guess if they're looking for a job but it's hard to be sure so that's also a little bit ambiguous in the face of potentially very important and valuable prediction tiles like these the ground truth can be ambiguous and so if you ask people to take their best guess at the ground truth label for tasks like these giving labeling instructions that results in more consistent and less noisy and less random labels will improve the performance of your learning algorithm so when defining the data for your learning algorithm here are some here are some important questions first what is the input x for example if you're trying to detect defects on smartphones for the pictures you're taking is the lighting good enough is the camera contrast good enough is the camera resolution good enough so if you find that you have a bunch of pictures like these which is so dark it's hard even for a person to see what's going on the right thing to do may not be to take this input x and just label it it may be to go to the factory and politely request improving the lighting because it is only with this better image quality that the labeler can then more easily see scratches like this and label them so sometimes if your sensor or your imaging solution or your audio recording solution is not good enough the best thing you could do is recognize that if even a person can't look at the input and tell what's going on then improving the quality of your sensor or improving the quality of the input x that can be an important first step to ensuring your learning algorithm kind of reasonable performance and for structured data problems defining whether the features to include can have a huge impact on your learning algorithm's performance for example for user id merge if you have a way of getting the user's location even a rough gps location if you have permission from the user to use that can be a very useful cue for deciding whether two user accounts actually belong to the same person and of course please do this type of thing only if you have permission from the user to use their data this way in addition to defining the input x you also have to figure out what should be the target label y and as you've seen from the preceding examples one key question is how can we ensure labelers give consistent labels in the last video in this video you saw a variety of problems with the labels being ambiguous or in some cases the input x not being sufficiently informative such as if the image is too dark let's take these data issues and put them into a more systematic framework that will allow us to devise solutions in a more systematic way let's go on to the next video to take a look\", metadata={'source': 'mzv1mkJRA10', 'title': '#26 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3 Lesson 2]', 'description': 'Unknown', 'view_count': 2855, 'thumbnail_url': 'https://i.ytimg.com/vi/mzv1mkJRA10/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVyhCMA8=&rs=AOn4CLDZuAAc0G20CAmRfo6_AKoLxwZWCw', 'publish_date': '2022-04-20 00:00:00', 'length': 550, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"i'd like to share with you a useful framework for thinking about different major types of machine learning projects it turns out that the best practices for organizing data for one type can be quite different than the best practices for a totally different type let's take a look at one of these major types of machine learning projects let's fill in this two by two grid one axis will be whether your machine learning problem uses unstructured data or structured data i found that the best practices for these are very different mainly because humans are great at processing unstructured data like images and audio and text and not as good at processing structured data like database records the second axis is the size of your data set do you have a relatively small data set or do you have a very large data set there's no precise definition of what exactly is small and what is large but i'm going to use as a slightly arbitrary threshold whether you have over 10 000 examples or not and clearly this boundary is a little bit fuzzy and the transitions from small to big data sets is a gradual one but i found that best practices for if you have say a hundred or a thousand examples smaller data sets is pretty different than when you have a very large data set and the reason i chose the number 10 000 is that's roughly the size beyond which it becomes quite painful to examine every single example yourself you know if you have a thousand examples you could probably examine every example yourself but when you have a hundred thousand examples ten thousand hundred thousand million examples is very it becomes very time consuming for you as an individual or maybe a couple of machine learning engineers to manually look at every example so that affects the best practices as well let's look at some examples if you are training a manufacturing visual inspection from just 100 examples of scratch phones that's unstructured data because this is image data and it's a pretty small data set if you are trying to predict housing prices based on the size of the house and other features in the house from just 50 training examples then there's a structured data set with just real value features and a relatively small data set if you are carrying out speech recognition from 50 million training examples there's unstructured data but you have a lot of data or if you are trying to recommend products so online shopping recommendations and you have a million users in your database then there's a structured problem with relatively large amount of data for a lot of unstructured data problems people can help you to label data and data augmentation such as synthesizing new images or synthesizing the audio and there's some emerging techniques for synthesizing new text as well but data augmentation can help so for manufacturing visual inspection you can use data augmentation to maybe generate more pictures of smartphones or for speech recognition data augmentation can help you synthesize audio clips with different background noise in contrast for structured data problems it can be harder to obtain more data and also harder to use data augmentation if only 50 houses have been so recently in that geography well it's hard to synthesize new houses that don't exist or if you have a million users in your database well again it's hard to synthesize new users that don't really exist and it's also harder not impossible still worth trying but it may or may not be possible to get humans to label the data so i find that the best practices for unstructured versus structured data are quite different the second axis is the size your data set when you have a relatively small data set having clean labels is critical if you have a hundred training examples then if just one of the examples is mislabeled that's one percent of your data set and because the data set is small enough for you or a small team to go through it efficiently it may well be worth your while to go through that hundred examples and make sure that every one of those examples is labeled in a clean and consistent way meaning according to a consistent labeling standard in contrast if you have a million data points it can be harder maybe impossible for a small machine learning team to manually go through every example having clean labels is still very helpful don't get me wrong even when you have a lot of data clean labels is better than non-clean ones but because of the difficulty of having the machine learning engineering team go through every example the emphasis is on data processes in terms of how you collect and store the data the labeling instructions you may write for a large team of crowd source labelers and once you have executed some data process such as asked a large team of labelers to label a large set of audio clips it can also be much harder to go back and change your mind and get everything relabeled so let's summarize for unstructured data problems you may or may not have a huge collection of unlabeled examples x maybe in your factory you actually took many thousands of images of smartphones but you just haven't bothered to label all of them yet this is also common in the self-driving car industry where many self-driving car companies have collected tons of images of cars driving around but just have not yet gotten that data labeled for these unstructured data problems you can sometimes get more data by taking your unlabeled data x and asking humans to just label more of it this doesn't apply to every problem but for the problems where you do have tons of unlabeled data this can be very helpful and as we've already mentioned data augmentation can also be helpful for structured data problems it's usually harder to obtain more data because you only have so many users or only so many houses or so that you can collect data from and human labeling on average is also harder although there are some exceptions such as in the last video where you saw that we could try to ask people to label examples for the user id merge problem but in many cases where we ask humans to label structured data even when it's a completely fine idea completely worthwhile to ask people to try to label if two records are the same person there's more likely to be a little bit more ambiguity where even human labor sometimes finds it hard to be sure what is the correct label lastly let's look at small versus big data where i use the slightly arbitrary threshold of whether you have more or less than say 10 000 labor training examples for small data sets clean labels are critical and the data set may be small enough for you to manually look through the entire data set and fix any inconsistent labels further the labeling team is probably not that large it may be one or two or just a handful of people that created all the labels so if you discover an inconsistency in the labels say one person label iguana is one way and a different person labeled iguanas a different way you can just get the two or three labels together and have them talk to each other and hash out and agree on one labeling convention for the very large data sets the emphasis has to be on data process and if you have 100 labelers or even more it's just harder to get 100 people into a room to all talk to each other and hashtag the process and so you might have to rely on a smaller team to establish a consistent label definition and then share that definition with all say 100 or more labelers and ask them to all implement the same process i want to leave you with one last thought which is that i found this categorization of problems into unstructured versus structures small versus big data i found this to be helpful for predicting not just whether data processes generalized from one to another problem but also whether other machine learning ideas generalize from one to another so one tip if you are working on a problem from one of these four quadrants then on average advice from someone that has worked on problems in the same quadrants will probably be more useful than advice from someone that's worked in a different quadrant i found also in hiring machine learning engineers someone that's worked in the same quadrant as the problem i'm trying to solve will usually be able to adapt more quickly to working on other problems in that quadrant because the instincts and decisions are more similar within one quadrant than if you shift to a totally different quadrant in this chart i've sometimes heard people give advice like oh if you're building a computer vision system always get at least a thousand labeled examples and i think people that give advice like that are well meaning and i appreciate that they're trying to give good advice but i found that advice to not really be useful um for all problems machine learning is very diverse and it's hard to find one-size-fits-all advice like that i've seen computer vision problems built with 100 examples or 100 examples per class a speed system is built with 100 million examples and so if you are looking for advice uh on the machine learning project try to find someone that's worked in the same quadrant as the problem you're trying to solve now we talked about one formulation of different types of machine learning problems there's one aspect i would like to dive into with you in the next video which is how for small data problems having clean data is especially important let's take a look at the next video of why this is true\", metadata={'source': 's5qFpEPNXEY', 'title': '#27 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 3]', 'description': 'Unknown', 'view_count': 2840, 'thumbnail_url': 'https://i.ytimg.com/vi/s5qFpEPNXEY/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgXShFMA8=&rs=AOn4CLCMBcA2NRYVltcTERe3pDn1bKPC-g', 'publish_date': '2022-04-20 00:00:00', 'length': 677, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"in problems of a small data set having clean and consistent labels is especially important let's start with an example one of the things i used to do is use machine learning to fly helicopters one things you might want to do is take as input the voltage applied to the motor or to the helicopter rotor and predict what is the speed of the rotor you can have this type of problem not just flying helicopters but for other control problems when you're controlling the speed of a motor so let's say you have a data set that looks like this where you have five examples so a pretty small data set because this data set that is the output y is pretty noisy it's difficult to know what is the function you should use to map voltage to the rotor speed in rpm maybe it should be a straight line something like that or maybe something like that or maybe it should go up and then be flat like that or maybe it should be a curve like that really hard to tell when you have a small data set five examples and noisy labels is difficult to fit a function confidently now if you have a ton of data this data set is equally noisy as the one on the left but you just have a lot more data then the learning algorithm can average over the noisy data sets and you can now fit a function you know pretty confidently looks like curve should be something like that a lot of ai had recently grown up in large consumer internet companies which may have 100 million users or a billion users and does very large data sets and so i think some of the practices for how to deal with small data sets have not been emphasized as much as would be needed to tackle problems where you don't have a hundred million examples but only a thousand or even fewer so to me the interesting case is one of you still have a small data set five examples same as the example on the left but you now have clean and consistent labels in this case you can pretty confidently fit a function through your data and with only five examples you can build a pretty good model for predicting for predicting speed as a function of the input voltage i've trained computer vision systems with just 30 images and had it worked just fine and the key is usually to make sure that the labels are clean and consistent let's take a look at another example of phone defect inspection the task is to take as input pictures like these and to decide whether there is a defect or not on the phone now if labeling instructions are initially unclear then labelers will label images inconsistently it may be that when there's a giant scratch you know sufficiently large one that everyone will agree as a defect and if there's a tiny little thing that inspectors will ignore it but there's this region of ambiguity where different inspectors will label different scratches with a length between point two and point four in slightly inconsistent ways so one solution to this would be to say why don't we try to get a lot more pictures of phones and scratches and then see what the inspectors do and then maybe eventually we can train a neural network they can figure out from the image what is and what is in the scratch on average maybe that approach could work but it'd be a lot of work and require collecting a lot of images i found that it can be more fruitful to ask the inspectors to sit down and just try to reach agreement on what is the size of scratch that would cause them to label a stretch with a bounding box versus the side is too small and not worth bothering labeling so in this example if the labelers can agree that the point of transition from where little ding becomes a defect is a length of 0.3 then the way they label the images becomes much more consistent and it becomes much easier for learning algorithm to take as input images like this and consistently decide whether something is a scratch or a defect just to be clear in this example the input to the learning algorithm is images like that on the left not the stretch length like that on the right but the point is if you can get inspectors to agree what is a scratch and what is in the scratch and to define the toss as putting bounding boxes around defects they're over 0.3 millimeters in length then that will cause your images to be labeled more consistently and allow your learning algorithm to achieve higher accuracy even when your data set isn't that big so you've seen a couple examples now of how label consistency helps a learning algorithm i want to wrap up this video with one more thought which is that big data problems can have small data challenges too specifically problems with a large data set but where there's a long tail of rare events in the input will have small data challenges too for example the launch web search engine companies all have very large data sets of web search queries but many web queries are actually very rare and so the amount of click stream data for the rare queries is actually small take self-driving cars self-driving car companies tend to have very large data sets collected from driving hundreds of thousands or millions of hours or more but there are rare occurrences that are critical to get right to make sure a self-driving car is safe such as that very rare occurrence of a young child running across the highway or that very rare occurrence of a truck popped across a highway so even if a self-driving car has a very large data set the number of examples it may have of these rare events is actually very small and so ensuring label consistency in terms of how these rare events are detected and labeled is still very helpful for improving self-driving cars or product recommender systems if you have a catalog of hundreds of thousands or millions or more items or product recommendation systems if you have an online catalog of anywhere from thousands to hundreds of thousands to sometimes even millions of catalogs to sometimes even millions of items then you will have a lot of products where the number sold of that item is quite small and so the amount of data you have of users interacting with the items in the long tail is actually small and if there's a way which is not easy but there's a way to make sure that data is clean and consistent then that too will help your learning algorithm in terms of how i recommend so it doesn't recommend items in the long tail where the amount of data per item will tend to be low so when you have a small data set label consistency is critical even when you have a big data set label consistency can be very important it's just that i found it easier on average to get to label consistency on smaller datasets than on very large ones in the next video we'll look at some concrete ideas and best practices for improving your datasets label consistency let's go on to the next video\", metadata={'source': 'f5sN3xAEAWQ', 'title': '#28 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 4]', 'description': 'Unknown', 'view_count': 2711, 'thumbnail_url': 'https://i.ytimg.com/vi/f5sN3xAEAWQ/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGEggTihlMA8=&rs=AOn4CLBldAVh9-dimD71XdZncgqrZ4Lojw', 'publish_date': '2022-04-20 00:00:00', 'length': 497, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"let's take a look at some ways to improve the consistency of your labels here's a general process you can use if you are worried about labels being inconsistent find a few examples and have multiple labelers label the same example in some cases you can also have the same labeler label an example wait a while until they've hopefully forgotten or technical term is wash out but have them take a break and then come back and re-label it and see if they're even consistent with themselves when you find that these disagreements have the people responsible for labeling this could be the machine learning engineer it could be the subject matter expert such as the manufacturing expert that's responsible for labeling what is a scratch and what is in scratch and or the dedicated labelers discuss together what they think should be a more consistent definition of a label why and try to have them reach an agreement and ideally also document and write down that agreement and this definition of why can then become an updated set of labeling instructions that they can go back to label new data or to relabel old data during this discussion in some cases the labels will come back and say they don't think the input x has enough information if that's the case consider changing the input x so for example when we saw the pictures of phones they were so dark that we couldn't even tell what was going on that was a sign that we should consider increasing the illumination the lighting with which the pictures were taken but of course i know this isn't always possible but sometimes this can be a big hole and then all this is an iterative process so after improving x or after improving the label instructions you would ask the team to label more data and if you think there are still disagreements then repeat the whole process of having multiple labelers label the same example measure disagreement and so on let's look at some examples one common outcome of this type of exercise is to standardize the definition of labels so between these ways of labeling the audio clip you heard on the earlier video perhaps the labels will standardize on this as the convention or maybe they'll pick a different one and that could be okay too but at least this makes the data more consistent another common decision that i've seen come out of a process like this is merging classes so if in your labeling guidelines you ask labelers to label deep scratches on the surface of the phone as well as shallow scratches on the surface of the phone but if the definition between what constitutes a deep scratch versus a shallow scratch barely visible here i know it's unclear then you end up with labels very inconsistently labeling things as deep versus shallow scratches sometimes the factory does really need to distinguish between deep versus shallow scratches sometimes factory need to do this to figure out what was the cause of the defect but sometimes i found that you don't really need to distinguish between these two classes and you can instead merge the two classes into a single clause say the scratch class and this gets rid of all of the inconsistencies with different labels labeling the same thing deep versus shallow so merging classes isn't always applicable but when it is it simplifies the task for the learning algorithm one other technique i've used is to create a new class or create a new label to capture uncertainty so for example let's say you ask labelers to label phones as defective or not based on the length of the scratch so here's a sequence of smartphones with larger and larger scratches so not sure if you can see these on your display but let me just make them a little bit more visible here and i know that all of these are really large scratches if this is a real phone you're buying so this is just for illustrative purposes and maybe everyone agrees that the giant scratches the defect tiny scratch is not a defect but they don't agree on what's in between if it was possible to get them to agree then that would be one way to reduce label ambiguity but if that turns out to be difficult then here's another option which is to create a new class where you now have three labels you can say it's clearly not a defect or clearly a defect or just acknowledge that some examples are ambiguous and put them in a new borderline clause and if it becomes easier to come up with consistent instructions for this three-class problem because maybe some examples are genuinely borderline then that could potentially improve labeling consistency let me use speech illustration to illustrate this further given this audio clip nearest grocery i really can't tell what they said nearest grocery and if you were to force everyone to transcribe it some labelers will transcribe nearly go some will say maybe they'll say nearest grocery and it's very difficult to get to consistency because the audio clip is genuinely ambiguous to improve labeling consistency it may be better to create a new tag the unintelligible tag and just ask everyone to label this as nearest nearest unintelligible nearest grocery and this can result in more consistent labels than you were to ask everyone to guess what they heard when it really is unintelligible let me wrap up with some suggestions for working with small versus big data sets to improve label consistency and we've just been talking about unstructured data or problems where we can count on people to label the data for small data sets there's usually a small number of labelers and so when you find an inconsistency you can ask the labelers to sit down and discuss a specific image or specific audio clip and try to drive toward agreement for big data sets it will be more common to try to get to consistent definition with a small group and then send the labeling instructions to a larger group of labelers one other technique that is commonly used but i think overuse in my opinion is that you can have multiple labelers label every example and then let them vote and voting is sometimes called consensus labeling in order to increase accuracy i find that this type of voting mechanism technique it can work but it's probably overused in machine learning today where what i've seen a lot of teams do is have inconsistent labeling instructions and then try to have a lot of labels and then voting to try to make it more consistent but before resorting to this which i do use but more of a last resort i would usually first try to get to more consistent label definitions to try to make the individual labeler's choices less noisy in the first place rather than take a lot of noisy data and then try to use voting to reduce the noise i hope that the tools you just learned for improving label consistency will help you to get better data for your machine learning tools one of the gaps i see in the machine learning world today is that there's still a lack of tools and ml also machine learning ops tools for helping teams to carry out this type of process more consistently and repeatedly so it's not you know us trying to figure this out in a jupiter notebook but instead to have tools help us to detect when labels are consistent and to help facilitate the process in improving the quality of the data so this is something i look forward to hopefully our community working on and developing in terms of improving label quality one of the questions that often comes up is what is human level performance on a task i find human level performance be important and sometimes misused concept let's take a deeper look at this in the next video\", metadata={'source': 'a-oCxdzFapE', 'title': '#29 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 5]', 'description': 'Unknown', 'view_count': 2464, 'thumbnail_url': 'https://i.ytimg.com/vi/a-oCxdzFapE/hqdefault.jpg?sqp=-oaymwExCJADEOABSFryq4qpAyMIARUAAIhCGAHwAQH4Af4JgALQBYoCDAgAEAEYRSBLKGUwDw==&rs=AOn4CLCEhc2Z01CiZrw15lDpnTCR1-D7ug', 'publish_date': '2022-04-20 00:00:00', 'length': 549, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"some machine learning tasks are trying to predict an inherently ambiguous output and human level performance can establish a useful baseline of performance as a reference but human level performance is also sometimes misused let's take a look one of the most important uses of measuring human level performance or hrp is to estimate bayes error or irreducible error especially on unstructured data toss in order to help with error analysis and prioritization and just establish what might be possible take a visual inspection task this may have happened to you before but i have gotten requests from business owners saying hey andrew can you please build a system that's 99 accurate or maybe 99.9 accurate so one way to establish what might be possible would be to take a data set and look at the ground truth data say you have six examples where the ground truth label is these and then to ask a human inspector to label the same data blinded to the ground truth label of course and see what they come up with and if they come up with these you would say this inspector agreed to the ground truth on four other six examples and disagreed on two out of six and so human level performance is you know 66.7 and so this would let you go back to the business owner and say look even your inspector is only 66.7 accuracy how can you expect me to get 99 accuracy so hrp is useful for establishing a baseline in terms of what might be possible there's one question that is often not asked which is what exactly is this ground truth label because rather than just measuring how well we can do compared to some ground truth label which was probably written by some other human are we really measuring what is possible or are we just measuring how well two different people happen to agree with each other when the ground truth label is itself determined by a person there's a very different approach to thinking about human level performance which i want to share with you in this and the next video beyond this purpose of estimating bayes error and establishing what's possible using that to help with error analysis and prioritization here are some other uses of human level performance in academia hlp is often used as a respectable benchmark and so when you establish that people are only 92 accurate or some of the number on a speech recognition data set and if you can beat human level performance then that establishes then that helps you to quote proof that your learning algorithm is doing something hard and helps get the paper published i'm not saying this is a great use of hlp but in academia showing you can beat hlp maybe for the first time has been a tried and true formula for establishing the academic significance of a piece of work and helps with getting something published we discussed briefly on the last slide what to do if a business or product owner asks for 99 accuracy and if you think that's unrealistic then measuring hlp may help you to establish a more reasonable target there's one other use of hlp that you might hear about that i'll be cautious about which is i've seen many projects with a machine learning team wants to use hlp or beating hlp to prove that the machine learning system is superior to the humans doing the job and as tempting as it is to go to someone and says look i've proved that my machine learning system is more accurate than humans inspecting the phones or the radiologists reading x-rays or something and now that i've mathematically proved the superiority of my learning outro you have to use it right i know the logic of that is tempting but as a practical matter this approach rarely works and you also saw last week that businesses need systems that do more than just doing well on average tested accuracy so if you ever find yourself in this situation i would urge you to just use this type of logic with caution or maybe even more preferably just don't use these arguments i've usually found other arguments than this to be more effective at working with a business to see if they should adopt a machine learning system the problem with beating human level performance as proof of machine learning superiority is multifold beyond the fact that most applications require more than just high average tested accuracy one of the problems with this metric is that it sometimes gives a learning algorithm an unfair advantage when labeling instructions are inconsistent let me show you what i mean if you have inconsistent labeling instructions so that when an audio clip says nearest gas station let's say 70 percent of laborers use this labeling convention and 30 percent of labelers use this labeling convention neither one is a superior transcript to the other both seem completely fine but just by luck of the draw 70 percent of laborers choose the first one 30 choose the second one so if the ground truth is established by a labeler maybe just a label with a slightly bigger title but really by one labeler then the chance that two random labelers will agree will be 0.7 squared plus 0.3 squared which is 0.58 so we had two labels use the first convention there's a point seven square chars of that or if both of your random labels use the second convention there's a point three squared charge of that then the two of them will agree so the chance of two labels are green is 0.58 and in the usual way of measuring human level performance you will conclude that human level performance is 0.58 but what you're really measuring is the chance of two random labelers agreeing this is where a machine learning algorithm has an unfair advantage i think either of these labeling conventions is completely fine but the learning algorithm is a little bit better at gathering statistics of how often ellipses versus commas are used in such a context then the learning algorithm may be able to always use the first labeling convention because it knows that statistically it has a 70 chance of getting it right if it uses ellipses or dot dot so a learning algorithm will agree with humans 70 percent of the time just by choosing the first laden convention but this 12 improvement in performance whereas human level performance is 58 and your learning algorithm is 12 better is 0.70 this 12 better performance is not actually important for anything between these two equally good slightly arbitrary choices the learning algorithm just consistently picks the first one so it gains what seems like a 12 advantage on this type of on this type of query but it's not actually outperforming any human in any way that a user would care about and one side effect of this is that if your speech recognition task has multiple types of audio for some there's this dot dot or ellipses versus common ambiguity and the learning algorithm does 12 percent better on this if your learning algorithm makes some more significant errors on other types of input audio then when is performance where it actually does worse could be average out by queries like these where kind of fake looks like is doing better and this will therefore mask or hide the fact that your learning algorithm is actually creating worse transcripts than humans actually are and what this means is that a machine learning system can look like it's doing better than hlp but actually be producing worse transcripts than people because it's just doing better on this type of problem which is not important to do better on while potentially actually doing worse on some other types of input audio given these problems of human level performance what are we supposed to do measuring human level performance is useful for establishing a baseline using that to drive air analysis and prioritization but using it to benchmark machines and humans sometimes runs into problematic cases like this i found that when my goal is to build a useful application not publish a paper you publish a paper let's prove we can outperform people that helps publish paper but found that when my goal is to build a useful application rather than trying to beat human level performance i found it is often useful to instead try to raise human level performance because we raise human level performance by improving label consistency and that ultimately results in better learning outcome performance as well let's take a deeper look at this in the next video\", metadata={'source': 'eW546hpa744', 'title': '#30 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 6]', 'description': 'Unknown', 'view_count': 2495, 'thumbnail_url': 'https://i.ytimg.com/vi/eW546hpa744/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVihAMA8=&rs=AOn4CLDVWH1jGxXYbt2YHJX0Ghu_0QVidw', 'publish_date': '2022-04-20 00:00:00', 'length': 628, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"i think the use of hlp and machine learning had taken off partly because it helped people get papers published to show they can beat hlp there's also been a bit misused in settings where the goal is to build a valuable application not just to publish a paper when the ground truth is externally defined then there are fewer problems with hlp when the ground tree really is some real ground truth for example i've done a lot of work on medical imaging uh working on you know ai for diagnosing from x-rays or things like these and given an x-ray image if you want to predict the diagnosis if the diagnosis is defined according to say a biopsy so a biological or medical test then hlp helps you measure how well does a doctor versus a learning algorithm predict the outcome of a biopsy or a biological medical test i find that to be really useful but when the ground truth is defined by a human maybe even a doctor labeling an x-ray image then hlp is just measuring how well can one doctor predict another doctor's label versus how well can one learning algorithm predict another doctor's label and that too is useful but it's different than if you're measuring how well you versus a doctor are predicting some ground truth outcome from a medical biopsy so to summarize when the ground truth label is externally defined such as the medical biopsy then hrp gives an estimate for base error and irreducible error in terms of predicting the outcome of that medical test the biopsy but there are also a lot of problems where the ground truth is just another human label the visual inspection example we had from the previous video showed this where the inspector had 66.7 accuracy rather than just aspiring to beat the human inspector it may be more useful to see why the ground truth which is just some other inspector compared to this inspector don't agree for example if we look at the length of the different scratches that they label say on these six examples these were the lengths of the scratches and if we speak of the inspectors and have them agree that 0.3 mm is the threshold above which a stretch becomes a defect then what we would do is then what we realize is that for the first example both labeled it one totally appropriately for the second example the ground truth here is one but is less than 0.3 so we really should change this to 0 then 0.5 gets 1 1 0.200.1 and this example has a stretch of 0.1 but really this should have been a zero if we go through this exercise of getting the ground truth labor and this inspector to agree then we actually just raise human level performance from 66.7 percent to 100 at least as measured on these six examples so but notice what we've done by raising hlp to 100 we've made it pretty much impossible for a learning algorithm to beat hlp so that seems terrible you can't tell the business owner anymore you beat hlp and does they must use your system but the benefit of this is you now have much cleaner more consistent data and that ultimately will allow your learning algorithm to do better so when you go is to come up with a learning algorithm that actually generates accurate predictions rather than just prove for some reason that you can beat hlp i find this approach of working to raise hlp to be more useful to summarize when the ground truth label y comes from a human hlp being quite a bit less than 100 may just indicate that the labeling instructions or labeling convention is ambiguous on the last slide you saw an example of this in visual inspection you also see this in speech recognition where the um comma versus um ellipsis dot dot that type of ambiguous labeling convention will also cause hlp to be less than 100 improving labor consistency will raise human level performance and this makes it harder unfortunately for your learning algorithm to beat hlp but the more consistent labels will raise your machine learning algorithm performance which is ultimately likely to benefit the actual application so far we've been discussing hrp on unstructured data but some of these issues apply to structured data as well you already know that structured data problems are less likely to involve human labors and thus hlp is less frequently used but there are exceptions you saw previously the user id merging example where you might have a human label where the two records belong to the same person or i've worked on projects where we will look at network traffic into a computer to try to figure out if the computer was hacked and we asked human i.t experts to provide labels for us sometimes it's hard to know if a transaction is fraudulent and you just ask a human to label that or is this account a spam account or a bot generated account or from gps what is the mode of transportation is this person on foot or on a bike or in the car or on the bus it turns out buses stop at bus stops and so you can actually kind of tell if someone's in the bus or in the car based on their gps trace and for problems like these it would be quite reasonable to ask a human to label the data at least on the first pass for a learning algorithm to make such predictions as these and so when the ground truth label you're trying to predict comes from one human the same questions of what does hlp mean it is a useful baseline to figure out what is possible but sometimes when measuring hlp you realize that low hlp stems from inconsistent labels and working to improve hlp by coming up with a more consistent labeling standard will both raise hlp and give you cleaner data with which to improve your learning algorithms performance here's what i hope you take away from this video first hlp is important for problems where human level performance can provide a useful reference i do measure it and use it as a reference for what might be possible and to drive error analysis and prioritization having said that when you're measuring hlp if you find the hlp is much less than 100 also ask yourself if some of the gap between hlp and complete consistency is due to inconsistent labeling instructions because if that turns out to be the case then improving labeling consistency will raise hlp and also give cleaner data for your learning algorithm which will ultimately result in better machine learning algorithm performance here's what i hope you take away from this video hlp is useful and important for many applications for problems where i think how well humans perform is a useful reference i do measure hrp and i use that to get a sense of what might be possible and also use hlp to drive error analysis and prioritization having said that if in the process of measuring hlp you find that hlp is much less than perfect performance much lower than 100 this is also worth asking yourself if that gap between hlp and 100 accuracy may be due to inconsistent labeling instructions because if that's the case then improving labeling consistency will both raise hlp but more importantly help you get cleaner and more consistent labels which will improve your learning algorithm's performance\", metadata={'source': 'Ny970B12IQk', 'title': '#31 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 7]', 'description': 'Unknown', 'view_count': 2499, 'thumbnail_url': 'https://i.ytimg.com/vi/Ny970B12IQk/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGEMgRyhlMA8=&rs=AOn4CLDXyvd5QisZmcx-Yb0Y8eFiMJvC6A', 'publish_date': '2022-04-20 00:00:00', 'length': 542, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"you've learned about how to define what should be the data what should be the definition of why what should be the definition of the input x but how do you actually go about obtaining data for your task let's take a look at some best practices one key question i would urge you to think about is how long how much time should you spend obtaining data you know that machine learning is a highly iterative process where you need to pick a model hyper parameters have a data set then train you can carry out our analysis and go around this loop multiple times to get to a good model let's say for the sake of arguments that training your model for the first time takes a couple days maybe much shorter or maybe longer and let's say just for the sake of arguments that carrying out error analysis for your project for the first time may take a couple days if this is the case i would urge you not to spend 30 days collecting data because that will delay by a whole month you're getting into this iteration instead i urge you to get in this iteration loop as quickly as possible so training a model and error analysis might take just a couple days i would urge you to ask yourself what if you were to give yourself only two days to collect data would that help get you into this loop much more quickly maybe two days is too short but i've seen far too many teams take too long to collect their initial data set before they train the initial model whereas i've rarely come across a team where i said hey you really should have spent more time collecting data and after you've trained your initial model care and analysis there's plenty of time to go back and collect more data i found for a lot of projects i've led when i go to the team and say hey everyone we're gonna spend at most seven days collecting data so what can we do i found that posing the question that way often leads to much more creative ways ways that still 100 respect user privacy and follow regulatory considerations of any but much more creative scrappy ways to get a lot of data quickly and that allows you to enter this iteration loop much more quickly and lets the project make faster progress one exception to this guideline is if you have worked on this problem before and if from experience you know you need at least a certain training set size then it might be okay to invest more effort up front to collect that much data so because i've worked on speech recognition i have a good sense of how much data i'll need to do certain things and i know it's just not worth trying to train certain models if i have less than certain number of hours of data but a lot of the time if you're working on a brand new problem and if you're not sure and it's often hard to tell even from the literature but if you're not sure just how much data is needed then it's much better to quickly collect a small amount of data trade the model and then use error analysis to tell you if it's worth your while to go out to collect more data in terms of getting the data you need one other step i often carry out is to take inventory of possible data sources let's continue to use speech recognition as an example if you were to brainstorm a list of data sources this this is maybe what you might come up with maybe you already own 100 hours of transcribed speech data and because you already own it the cost of that is zero or you may be able to use a crowdsourcing platform and pay people to read text so you provide them a piece of text and ask them to read it out loud and this creates text data where you already have the transcript because we're reading a piece of text that you have or you may decide to take audio that you have that hasn't been labeled yet and to pay for it to be transcribed it turns out this is more expensive on a per hour basis than paying people to read text but this results in audio that sounds more natural because people aren't reading so for a hundred hours of data it may cost six thousand dollars to get high quality transcripts or you may find some commercial organizations that could sell you data through an exercise like this you can brainstorm what are the different types of data you might use as well as their associated costs one column that's missing from this that i find very important is the time cost so how long will it take you to execute the project to get these different types of data for the own data you could get that instantaneously for crowd source reading you may need to implement a bunch of software find the right crowd sourcing platform carry out software integration so you might estimate that that's two weeks of engineering work paying for data to be labeled is simpler but still is work to organize and manage whereas purchasing data maybe there's a purchase order process that may be much quicker i find that some teams won't go through an inventory process like this and would just pick a random idea and maybe decide to use crowdsourcing and reading to collect data but if you can sit down write all the different data sources and think through the trade-offs including cost and time then that can help you to make often better decisions about what sources of data to use and so if you are especially pressed with time based on this analysis you may decide to use the data video and maybe purchase some data and use that over the middle two options in order to get going more quickly in addition to the amount of data you can acquire and the financial cost and the time cost other important factors does application dependence will include data quality where you may decide for example that paying for labels actually gives more natural audio than having people sound like they're reading as well as really importantly privacy and regulatory constraints if you decide to get data labeled here are some options you might think through as well the three most common ways to get data labeled are in-house where you have your own team labeled data versus outsource where you might find some company that labels data and have them do it for you versus crowdsource where you might use a crowdsourcing platform to have a large group collectively label the data the difference between outsourced versus crowdsource is that depending on what type of data you have there may be specialized companies that could help you get the label quite efficiently some of the trade-offs between these options having machine learning engineers label data is often expensive but i find that to get a project going quickly having machine learning engineers do this just for a few days is usually fine and in fact this can help build the machine learning engineer's intuition about the data when i'm working on a new project i often don't mind spending a few hours or maybe a day or two labeling data myself if that helps me to build my intuition about the project but beyond a certain point you may not want to spend all your time as a machine learning engineer labeling data and you might want to shift to more scalable labeling processes depending on your application there may be also different groups or subgroups of individuals that are going to be more qualified to provide the labels why if you're working on speech recognition then maybe almost any reasonably fluent speaker can listen to audio and transcribe it so speech recognition because of the number of people that speak a certain language has a very large pool of potential laborers or hopefully they will be careful and diligent for more specialized applications like factory inspection or medical image diagnosis a typical person off the street probably can't look at a medical x-ray image and diagnose from it or look at a smartphone and determine what is and what isn't a defect so most specialized tasks like these usually require an sme or subject matter expert in order to provide accurate labels and then finally there are some applications where it's very difficult to get anyone to give good labels take product recommendations there are probably product recommendation systems that are giving better recommendations to you than even your best friends or maybe your significant other and for this you may just have to rely on purchase data by the user as the label rather than get humans to label this when you're working on an application figuring out which of these categories of applications you're working on and identifying the right type of person or persons to help you label will be an important step to making sure your labels are high quality one last tip let's say you have a thousand examples and you've decided you need a bigger data set how much bigger should you make your data set one tip i've given a lot of teams is don't increase your data by more than 10x at the time so if you have a thousand examples and you've changed your model on a thousand examples maybe it's worth investing to try to increase your data set to 3000 examples or maybe at most 10 000 examples but i would first do a 10x or less than 10x increase first train another model carry out error analysis and only then figure out if it's worth increasing it substantially beyond that because once you increase your data set size by 10x so many things change is really difficult i've found it's really hard to predict what will happen when your data set size increases even beyond that it's also fine to increase your data set size 10 or 50 or just your 2x at the time so this is only an upper bound for how much you might invest to increase your data set size and this guideline hopefully will help teams avoid over-investing in tons of data only to realize that collecting quite damaged data wasn't the most useful thing they could have done i hope the tips in this video will help you to be more efficient in how you go about collecting your data now when you collect your data one of the things you might run into is the need to build a data pipeline where your data doesn't come all at once but there are multiple pre-processing steps that your data has to go through let's go on to the next video to take a look at some best practices for building data pipelines\", metadata={'source': 'qt9tXjtlQt4', 'title': '#32 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 8]', 'description': 'Unknown', 'view_count': 2478, 'thumbnail_url': 'https://i.ytimg.com/vi/qt9tXjtlQt4/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVyhAMA8=&rs=AOn4CLAZ15fMH17NqAT32-PzpH69uGTrKw', 'publish_date': '2022-04-20 00:00:00', 'length': 747, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"data pipelines sometimes also called data cascades refers to when your data has multiple steps of processing before getting to the final output there's some best practices relevant for managing such data pipelines let's start to an example let's say that given some user information you would like to predict if a given user is looking for a job because if they're looking for a job at this moment in time you may want to surface job ads or other pieces of particularly useful information to them so given raw data such as the data on top there's often some sort of pre-processing or data cleaning before the data is fed to learning algorithm that then tries to predict why are they looking for a job and the data cleaning may include things like spam cleanup such as removing the spam accounts and maybe also user id merge which we talked about in an earlier video for the sake of this example let's say that spam cleanup and user id merge are done with just scripting so explicit sequences of instructions that tells your code when is an account to be considered spammy and when should two user ids be merged of course these systems could be built using machine learning algorithms as well which makes them even a little bit more complex to manage now when you have scripts for the data cleaning one of the issues you run into is replicability when you take these systems into production deployment let's say during the development of the system you have input data fed through pre-processing scripts and the pre-processed data is fed to machine learning algorithm and after some amount of work your learning algorithm does well on the test set during the development phase you may have seen that pre-processing scripts can be quite messy it may be you hacking something up processing data mailing a file to a different member of your team having them have a few incantations in python or some scripting language to process the data and then having them mail the process data back to you when you take this system to production you then have new data which has to be fed through a similar set of scripts because this data is going to be fed to the same machine learning algorithm and your machine learning algorithm on this data is what will run in your product so the key question is if your pre-processing was done with a bunch of scripts spread out on a bunch of different people's computers and laptops how do you replicate the strips to make sure that the input distribution to your machine learning algorithm was the same for the developed data and the production data i find that the amount of effort that you should invest to make sure that the pre-processing scripts are highly replicable can depend a little bit on the phase of the project i know that it may be fashionable to say that everything you do should be 100 replicable and i'll probably get some criticism for not hewing to that line but i find that a lot of projects do go through a proof of concept of poc phase and then a production phase where during the proof of concept phase the primary goal is just to decide if the application is workable and worth building and deploying my advice to most teams is during the proof of concept phase focus on getting the prototype to work and it's okay if some of the data pre-processing is manual if the project succeeds you need to replicate all this pre-processing later so my advice would be take extensive notes write extensive comments to increase the odds that you can replicate all this pre-processing later but this is also not the time to get bogged down in tons of process just to ensure replicability when the focus is really to just decide if the application is workable and is worth taking to the next phase once you've decided that this project is worth taking to production then you know it's going to be really important to really replicate any pre-processing scripts so in this phase that's when i would use more sophisticated tools to make sure the entire data pipeline is replicable and this is when tools which can be a little bit more heavyweight but tools like tensorflow transform apache beam airflow and so on become very valuable and in fact you learn more about tensorflow transform later into specialization as well in this video you learned about data pipelines and when to invest in their replicability it turns out many applications have significantly more complex data pipelines than what we saw in this video and for those settings you also have to think about what metadata you want and perhaps also keep track and take care of data provenance and lineage let's go on to the next video to look at these topics\", metadata={'source': 'gz-44N3MMOA', 'title': '#33 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 9]', 'description': 'Unknown', 'view_count': 2346, 'thumbnail_url': 'https://i.ytimg.com/vi/gz-44N3MMOA/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgXyhGMA8=&rs=AOn4CLBKBxiNTOpFUFNOtiwMavgq6tB5tA', 'publish_date': '2022-04-20 00:00:00', 'length': 346, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"for some applications having and tracking metadata data provenance and data lineage can be a big help what do these words even mean let's look at an example here's a more complex example of a data pipeline building on our previous example of using user records to predict if someone is looking for a job at a given moment in time let's say you start off with a spam data set this may include a list of known spam accounts as well as features such as a list of blacklisted ip addresses that spammers are known to use you might also implement a learning algorithm so piece of machine learning code and train your learning algorithm on the spam data set thus giving you an anti-spam model so these arrows indicate flow of information or flow of computation where training your ml code on the spam data set gives you your anti-spam model you then take your user data and apply the anti-spam model to it to get the dspam user data we're following our usual convention that things with a purple rectangle around it represent pieces of code now taking your dspam user data next you might want to carry out user id merge to do that you might start off with some id merge data so this would be labeled data telling you some pairs of accounts that actually correspond to the same person have a machine learning album implementation train the model on that and this gives you a learned id merge model that tells you when to combine two accounts into a single user id you take your id merge model apply it to the dspam user data this gives you your cleaned up user data then finally based on the clean user data hopefully some of this labels with whether someone's looking for a job you would then have another machine learning model trained on it to give you a model to predict if a given user is looking for a job or not and this is then used to make predictions on other users or maybe across your whole database of users so this level of complexity of a data pipeline is not atypical in large commercial systems and i've seen data pipelines or data cascades that are even far more complicated than this one of the challenges of working with data pipelines like this is what if after running this system for months you discover that oops the ip address blacklist you're using has some mistakes in it in particular what if you discover that there were some ip addresses that were incorrectly blacklisted maybe because the provider from whom you had purchased the blacklisted ip addresses found out that there were some ip addresses that multiple users use right such as if multiple users on a corporate campus or university campus share an ip address for security reasons but the organization creating the blacklist ipi just thought it was spammy because so many people shared an ip address this has happened before so the question is having built up this big complex system if you were to update your spam data set won't that change your spam model and therefore that and therefore that and therefore that and therefore that and how do you go back and fix this problem especially if each of these systems was developed by a different engineer and you have files spread across the laptops of your machine learning engineering development team so to make sure your system is maintainable especially when a piece of data upstream ends up needing to be changed it can be very helpful to keep track of data provenance as well as lineage data provenance refers to where the data came from so who did you purchase the spam ip address from and lineage refers to the sequence of steps needed to get to the end of the pipeline at the very least having a extensive documentation could help you reconstruct data provenance and lineage but to build robust maintainable systems not in the proof of concept stage but in the production stage there are more sophisticated tools to help you keep track of what happened so you can change part of the system and hopefully replicate the rest of the data pipeline without too much unnecessary complexity to be honest the tools for keeping track of data provenance and lineage are still immature in today's machine learning world i find that extensive documentation can help and some formal tools like tensorflow transform can also help but solving this type of problem is still not something that we are great at as a community yet to make life easier both for managing data pipelines as well as for error analysis and driving machine learning development there's one tip i want to share which is to make extensive use of metadata so metadata is data about data for example in manufacturing visual inspection the data would be the pictures of phones and the labels but if you have metadata that tells you at what time was this picture of a phone taken what factory was this picture from what's the line number what were the camera settings such as camera exposure time and camera aperture what's the number of the phone you're inspecting what is the id of the inspector that provided this label these are examples of data about your data set x and y and this type of metadata can turn out to be really useful because if you discover during machine learning development that for some strange reason line number 17 in factory 2 [Music] generates images that produce a lot more errors for some reason then this allows you to go back to see what was funny about line 17 and factory two but if you had not stored the factory and line number of metadata in the first place then it would have been really difficult to discover this during error analysis so i found many times when i happened to maybe get lucky and store the right metadata only to discover a month later that that metadata helped generate a key insight that helped the project move forward so my tip is if you have a framework for storing metadata that will definitely make life easier but even if you don't just like you rarely regret commenting your code i think you will rarely regret storing metadata that could then turn out to be useful later and just like if you don't comment your code in a timely way it's much harder to go back to commenting later in the same way if you don't store the metadata in a timely way it can be much harder to go back to recapture and organize that data one more example for speech recognition if you have audio recorded from different brands of smartphones let's say that in advance or if you have different labelers labeling your speech or if you use a voice activity detection model then let's keep track of what was the version number of the voice activity detection model that you use and all of these means that in case for some reason one version of the vad voice activity detection system results in much larger errors this significantly increases the odds of your discovering that and be able to use that to improve your learning over and performance so to summarize metadata can be very useful for error analysis and spotting unexpected effects or tags or categories of data that have some unusually poor performance or something else to suggest how to improve your system and of course maybe not surprisingly this type of metadata is also very useful for keeping track of where the data came from of data provenance the takeaway from this video is that for large complex machine learning systems that you might need to maintain keeping track of data provenance and lineage can make your life much easier and as part of building out these systems consider keeping track of metadata which can help you with tracking data provenance but also error analysis before we wrap up this section there's just one more tip i hope to share with you which is the importance of balanced train death test splits let's go on to the next video\", metadata={'source': 'hbqxEJisBHo', 'title': '#34 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 10]', 'description': 'Unknown', 'view_count': 2310, 'thumbnail_url': 'https://i.ytimg.com/vi/hbqxEJisBHo/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVyhAMA8=&rs=AOn4CLCJpo607K9yg245bw2Kl1ounjm_Vw', 'publish_date': '2022-04-20 00:00:00', 'length': 596, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"many of us are used to taking a data set and randomly splitting it into train depth and tests it turns out when your data set is small having balance trained dev and test sets can significantly improve your machine learning development process let's take a look let's use our manufacturing visual inspection example say your training set has a hundred images so pretty small data sets and with 30 positive examples so 30 defective phones and 70 non-defective if you were to use a train depth test split of sixty percent of the data in the training set twenty percent in the depth or holdout validation set and 20 in the test set say then if you were to use a random split just by chance it's not inconceivable that you may end up with 21 positive examples in train two in-depth and seven in test this would be quite likely just by random chance and this means the training set is 35 percent positive not that far from 30 positive in the overall data set but your depth set is 10 positive and your test set is 35 positive so 2 out of 20 is 10 7 out of 20 is 35 and this makes your death sets quite non-representative because in your death set you have only two or ten percent positive examples rather than 30 positive examples but when your data set is small then all of your 20 def set examples is just a higher chance of this slightly less representative split so what we would really want is for the training set to have exactly 18 positive examples def sets have exactly six positive examples and the test set to have exactly six positive examples and this would be thirty percent thirty percent thirty percent and if you could get this type of split this would be called a balance split where each of your train dev and tests has exactly 30 positive examples and this makes your data set more representative of the true data distribution there's no need to worry about this effect when you have a large data set if you have a very large data set a random split will very likely be representative meaning that the percentage of positive examples will be quite close to your overall data set but when you have a small data set with just 20 def set examples and 20 test set examples then explicitly making sure you have a balanced split can make your death set and test set more reliable measures of your learning algorithms performance this is one of those little techniques that turns out to make a big difference to your performance when you're working on a small data problem but that you don't really need to worry about if you have a very large data set so when you have a smaller data set i hope you consider using a balanced train dev test splits as well in terms of how you set up your data sets so when you're working on a smaller data problem i hope that using a balanced chain depth test split will help you with your learning algorithm and so that's it congratulations on getting to this point in this course you've finished the data section of videos and in the last two weeks you also learned about modeling and deployment there's just one last optional section that you can watch if you want on scoping i hope you come with me to watch the optional scoping videos as well we'll talk about how to select a project to work on but either way congrats on finishing all the required videos of this course i hope you've learned a lot and that these ideas will be useful for all your machine learning projects\", metadata={'source': 'mFD5hUZubTI', 'title': '#35 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 1, Lesson 11]', 'description': 'Unknown', 'view_count': 2239, 'thumbnail_url': 'https://i.ytimg.com/vi/mFD5hUZubTI/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgXChEMA8=&rs=AOn4CLDy6jMjGpvSN9CQnwXzAUFhUqnEBQ', 'publish_date': '2022-04-20 00:00:00', 'length': 277, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"picking the right project to work on is one of the most rare and valuable skills in ai today in the next few videos i'd like to share with you some best practices for scoping picking what project to work on and also planning out the scope of the project i remember when i was younger i tended to just jump into the first project that i got excited about and you know sometimes i was lucky and it worked out okay now that i've had a little bit more experience i find that if you by yourself or your team is going to spend a lot of time weeks or months or even longer working on a project it's well worth your while to think through a few options and try to select the most promising products to work on before putting so much effort into it so that let's dive into scoping let's use the example of an e-commerce retailer looking to increase sales if you were to sit down and brainstorm what an ecom company could do you might come up with many ideas such as maybe a better product recommendation system or better search so people can find what they're looking for or you may find that the catalog data is missing fields or is incomplete and this affects search or recommendations results so you might start the project to improve the quality of the catalog data or you may help them with inventory management such as deciding how many shirts to buy and where to ship the shirts or what price optimization with a quick brainstorming session you may be able to come up with dozens of ideas for how to help this ecommerce retailer the questions that we'd like to answer in the scoping process are what project or projects should we work on what are the metrics for success and what are the resources such as data time people needed to execute this project what i've seen in a lot of businesses is that of all the ideas you could work on some are going to be much more valuable than others maybe two times or five times or ten times more valuable than a different idea and being able to pick the most valuable project will significantly increase the impact of your work machine learning is a general purpose too there are a lot of things we can do with machine learning how do we take valuable projects to work on let's dive more deeply into the scoping process in the next video\", metadata={'source': 'UEMMOdFbT94', 'title': '#36 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 12]', 'description': 'Unknown', 'view_count': 2426, 'thumbnail_url': 'https://i.ytimg.com/vi/UEMMOdFbT94/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVChCMA8=&rs=AOn4CLBHFOq_Q0F6qVNjWTnaYDfJ7c4o-A', 'publish_date': '2022-04-20 00:00:00', 'length': 153, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"i'd like to share with you a process for scoping projects that hope will be valuable for how you decide what to work on when i'm speaking with a company for the first time about their ai projects this is the process that i use as well let's dive in when brainstorming projects work on the first thing i do is usually get together with a business or product owner often not an ai person but someone that understands a business or an application and to brainstorm with them what are their business or application problems and at this stage i'm trying to identify a business problem not an ai problem so if i'm speaking with an econ retail business like the example from the previous video i might ask what are the top few things top three things you wish were working better and maybe they'll share business problems like they'd like to increase conversions number of people that go to the website and convert to a sale or reduce inventory so you don't need as much stuff sitting around in the warehouse or increase margin increase the profit per item sold at this point in the process i'm not trying to identify an ai problem in fact i'll often tell my partners i don't want to hear about your ai problems i want to hear about your business problems and then it's my job to work with you to see if there is an ai solution and sometimes there isn't and that's fine too feel free to use the exact same words as well when brainstorming projects with your non-ai partners if you want having identified a few business problems like the three examples on the right only then do i see or start to brainstorm if there are possible ai solutions not all problems can be solved by ai and that's okay but hopefully we'll come up with some ideas for using machine learning algorithms to address some of the business problems i find that it's helpful for this process to separate out the identification of the problem from the identification of the solution as engineers we are pretty good at coming up with solutions but having a clear articulation of what is the problem first often helps us come up with better solutions this type of separation between problem and solution is something you might hear about in the writings on design thinking as well after brainstorming a variety of different solutions i would then assess the feasibility and the value of these different solutions sometimes you hear me use the word diligence to refer to this phrase diligence is a term that actually comes from the legal field but it basically means double checking if an ai solution really is technically feasible and valuable or double checking something that you're hoping is true really is true after validating technical feasibility and the value or roi return on investments of your giving project if it still looks promising right if it still looks promising we then flesh out the milestones for the project and finally budget for resources let's take a deeper look at this process of identifying problems and solutions and we'll use these three examples from e-comm so the first one increase conversion if a business wants to increase conversions you may have different ideas for doing that for example you may want to improve the quality of the website's search results so people find more relevant products when they search or you might decide to try to offer up better product recommendations based on their purchase history it is quite common that one problem may lead to multiple ideas for solutions and you may be able to brainstorm other ideas as well such as maybe a redesign of how products are displayed on a page or you may find interesting ways to surface the most relevant product reviews to help users understand the product and thus hopefully purchase it so there could be many ways to increase conversions take the next problem from the previous slide of reducing inventory maybe you will you could imagine a demand prediction project to better estimate how many people buy something from you so you don't purchase too many or too few and have more accurate inventory in your warehouses or you may decide to come up with a marketing campaign to drive sales for specifically the products that you bought too many of so as to steer more purchases of stuff sitting in your warehouse and that could also reduce inventory and there could be many other ideas for solutions or for the problem of increasing margin you may come up with some ways to use machine learning to optimize what to sell what is worth selling and what is not worth selling in econ retail sometimes this is called merchandising just deciding what to sell or you can recommend bundles where if someone buys a camera maybe you can recommend to them a protective camera case and these bundles can also increase margin the problem identification is a step of thinking through what are the things you want to achieve and solution identification is a process of thinking through how to achieve those objectives one thing i still see too many teams do today is jump into the first project that they're excited about in my experience if you have deep domain knowledge about an application or industry maybe the first thing your gut gets excited about could be okay but even then i find it worthwhile to first engage in diversion thinking where you brainstorm a lot of possibilities to be followed by convergent thinking where you then narrow it down to one or a small handful of the most promising projects to focus on one thing i hope you might avoid is working really hard on the project and creating a certain amount of monetary or social value if for the same amount of work there's a different project that could have created 10 times more you know monetary or social or other positive types of value and i think this type of scoping process will help you to do that\", metadata={'source': '43CZ0HjIC7U', 'title': '#37 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 13]', 'description': 'Unknown', 'view_count': 2864, 'thumbnail_url': 'https://i.ytimg.com/vi/43CZ0HjIC7U/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgWShFMA8=&rs=AOn4CLA_ithcmA7ehGH1jVQkgpgisG8eMw', 'publish_date': '2022-04-20 00:00:00', 'length': 415, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"in the last video you heard about the step of assessing a project for technical feasibility and for value let's take a deeper look at how you can carry out this diligent step to figure out if a project really is feasible and also how valuable it really is let's start with feasibility is this project idea technically feasible before you've started on the machine learning project how do you know if this thing can even be built one way to get a quick sense of feasibility is to use an external benchmark such as the research literature or other forms of publications or if a different company or even a competitor has managed to build a certain type of online search system before or recommendation system or inventory management but if there's some external benchmark that might help give you a sense that this project may be technically feasible because someone else has managed to do something similar either to complement this type of external benchmark or in the absence of this type of external benchmark here are some other ways to assess feasibility and i'm going to build a two by two matrix that looks at different cases depending on whether your problem has unstructured data like speech images or structured data like transaction records and on the other axis i'm going to put new versus existing whereby new i mean you're trying to build a system to do a toss for the first time such as if you've never done demand forecasting before and you're thinking of building one whereas existing refers to if you already have some existing system maybe a machine learning one maybe not that is carry out this toss and you're thinking of scoping out an improvement to an existing system right so new means you are delivering a brand new capability and existing means you're scoping out the project to improve on an existing capability in the upper left hand quadrant to see if a project is technically feasible i find human level performance hrp to be very useful and give you an initial sense of whether a project is doable so when evaluating hrp i would give a human the same data as would be fed to a learning algorithm and just ask you know can a human given the same data perform the task such as can a human given a picture of a scratch smartphone perform the task of detecting scratches reliably and if a human can do it then that significantly increases the hope that you can also get a learning algorithm to do it for existing projects i would use hlp as a reference as well where if you have a visual defect inspection system and you're hoping to improve it to a certain level of performance if humans can achieve the level you're hoping to get it to then that might give you more hope that it is technically feasible whereas if you're hoping to increase performance well beyond human level performance then that suggested project might be harder or may not be possible in addition to hlp i often also use the history of the project as a predictor for future progress and we'll say more about both hlp and history of project in the next few slides but the previous rate of progress on the project can be a reasonable predictor for the future rate of progress on the project you'll see more of this later in this video moving over to the right column if you're working on a brand new project with structured data the question i would ask is are predictive features available do you have reason to think that the data you have the inputs x are strongly predictive or sufficiently predictive of the target output y in this box on the lower right for a structured data problem if you're trying to improve an existing system one thing that will help a lot is if you can identify new predictive features so are there features that you aren't yet using but you can identify that could really help predict why and also by looking at the history of the project so on this slide you heard about three concepts human level performance the question of whether predictive features are available and also the history of a project let's take a deeper look at these three concepts and let's start with using hlp on unstructured data images so i use hlp to benchmark what might be doable for unstructured data because people are very good on unstructured data tasks and so the key criteria for assessing project feasibility is can a human given the exact same data as would be given to learning algorithm perform the task let's look at an example let's say you're building a self-driving car and you want an algorithm to classify whether traffic light is currently red yellow or green i would i would take pictures from your self-driving car and ask a person to look at an image like this and see if a person looking only at the image can tell which lamp is illuminated and in this example it's pretty clear green but if you find that you also have pictures like this then well i can't tell which lamp is illuminated in this example and this is why it's important for this hlp benchmark to make sure the human is given only the same data as your learning algorithm it turns out maybe a human sitting in the car and seeing the traffic light with their own eye could have told you which lamp was illuminated in this example on the right but that's because the human eye has superior contrast to most digital cameras but a useful test is not whether the human eye can recognize which light which lamp is illuminated the useful test is if the person was sitting back in the office and they can only see the image from the camera can they still do the task and that gives you a better read on feasibility and specifically it helps you make a better guess and whether a learning algorithm which will only have access to this image can also accurately detect which lamp in the traffic light is illuminated making sure that a human sees only the same data as the learning iron will see is really important i've seen a lot of projects where for a long time a team was working on a computer vision system say and they thought they could do it because a human physically inspecting the cell phone or something could detect the defect but it took a long time to realize that even a human looking only at the image couldn't figure out what was going on then you can figure out much earlier that with the current camera setup it just wasn't feasible and the more efficient thing to do would have been to invest early on in a better camera or a better lighting setup or something rather than keep working on a machine learning algorithm on a problem that i think just wasn't doable with the imaging setup available at the time next for structured data problems one of the key criteria to assess for technical feasibility is do we have input features x that seem to be predictive whenever we're trying to predict why let's look at a few examples in our ecom example if you have features that show what are the past purchases of a user and you like to predict future purchases that seems plausible to me because most people's previous purchases are predictive of future purchases so if you have past purchase data you do have features that seem predictive of future purchases and this project might be worth a try or if you work with a physical store given data on weather if you want to predict shopping mall foot traffic so how many people will go to the mall well we know that when it rains a lot fewer people leave their house so weather is predictive of foot traffic and shopping malls and so i would say you do have predictive features whoever try let's look at some more examples given dna of an individual let's try to predict if this individual will have heart disease this one i don't know the mapping from your dna to whether or not you get heart disease is a very noisy mapping in biology this is referred to the genotype and phenotype but the mapping from genotype to phenotype or your genetics to your health condition is a very noisy mapping so i would have mixed feelings about this project because it turns out your genetic sequence is only slightly maybe mildly predictive of whether you get heart disease so with a question so i'm going gonna put a question mark there or given social media chatter can you predict demand for a clothing style this is another iffy one i think you may be able to predict demand for clothing style right now but given social media chatter can you predict what will be the hot fashionable trend six months from now that actually seems very difficult so one of the ways i've seen ai projects go poorly is if there's an idea like let's use social media to figure out what people are chatting about in fashion and they will manufacture the clothing and sell it in six months and sometimes the data just is not that predictive and you end up with a learning algorithm that does barely better than random guessing and that's why looking at whether you have features that you believe are predictive is an important step of diligence for assessing technical feasibility of a project one last example that that may be even clearer which is given a history of a particular stock or a particular shares price let's try to predict the future price of that stock all the evidence i've seen is that this is not doable unless you get some other clever set of features looking at the single shares historical price to predict the future price of that stock is exceedingly difficult and i would say if those are the only features you have those features are not predictive of the future price of that stock based on the evidence i've seen and so even leaving aside the question of how much predicting share prices or trading creates any social value i have some questions about that sometimes i think this project is also just not technically feasible finally on this diagram one last criteria i mentioned a couple times is the history of a project let's take a look at that when i've worked on a machine learning application for many months i found that the rate of previous improvement can be maybe a surprisingly good predictor for the rate of future improvement here's a simple model you could use let's take speech recognition as an example and let's say that this is human level performance and i'm going to use human level performance as our estimate for bayes era or the irreducible level of error that we hope to get to let's say that when you started the project you know say in the first quarter or q1 or some year the system had 10 error rate and over time in subsequent quarters the error you know went down like so so q2 q3 q4 and so on it turns out that it's not a terrible model to estimate this curve so if you want to estimate how well the team could do in the future one simple model i've used is to estimate the rate of progress as for every fixed period of time say every quarter the team will reduce the error rate by some percentage relative to human level performance so in this case it looks like this gap between the current level of performance and human level performance is shrinking by maybe 30 every quarter which is why you get this curve that is exponentially decaying towards hlp and by estimating this rate of progress you may project into the future that hopefully in future quarters you continue to reduce the error by 30 percent relative to hlp and this will give you a sense of what might be reasonable for the future rate of progress on this project and thus this gives you a sense of what may be feasible for an existing project for which you already have this type of history and can try to extrapolate into the future in this video you saw how to use human level performance the question of whether you have predictive features and the history of a project in order to assess technical feasibility next let's dive more deeply into assessing the value of a project we'll do that in the next video\", metadata={'source': 'opWrnW5v25w', 'title': '#38 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 14]', 'description': 'Unknown', 'view_count': 3429, 'thumbnail_url': 'https://i.ytimg.com/vi/opWrnW5v25w/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVShAMA8=&rs=AOn4CLD202LIMzxGRxgxJhFngHfj0579Hw', 'publish_date': '2022-04-20 00:00:00', 'length': 867, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"how do you estimate the value of machine learning project this is sometimes not easy to estimate but let me share with you a few best practices tick speech recognition let's say you're working on building a more accurate speech recognition system for the purpose of voice search to let people speak to the smartphone app to do web searches it turns out that in most businesses there will be some metrics that machine learning engineers are used to optimizing and some metrics that the owners of the product or the business will want to maximize and there's often a gap between these two building machine learning systems the objective that the learning algorithm may optimize might be something like word level accuracy so if a user says a certain number of words how many of the words do we get right so maybe the learning algorithm actually does great in the sense on log likelihood or some other criteria but many machine learning teams would be comfortable trying to get good word level accuracy but when using this in a business context one other key metric is query level accuracy which is how often do you get all the words in a query write and for some businesses word level accuracy is important but query level accuracy may be even more important and we've now taken one step away from the objective that the learning algorithm is almost directly optimizing even after you get the query right which is important for the user experience what users care even more about is the search result quality and the reason the business may want to ensure search result quality is that this gives users a better experience and just increases user engagement so they come back to the search engine more often and this is important but this is just one step towards actually driving the revenue of the business one gap i've often seen between machine learning teams and business teams is the engineering team will usually want to work on this whereas the business leader may want promises on that and in order for a project to move forward i usually try to have the technical and the business teams try to agree on metrics that both are comfortable with this often takes a little bit of compromise where the machine learning team might stretch a little bit further to the right and the business teams stretch a little bit further to the left and the further we go to the right the harder it is for a machine learning team to really give a guarantee and i wish more problems could be solved by grading the sense or by optimizing test set accuracy but that's just not the state of the world today a lot of practical problems require we do something more than just optimizing test and accuracy so having the technical team and the business teams both step a little bit outside their comfort zone is often important for reaching compromise to pick some set of metrics that the technical team feels like could stretch a bit to deliver on and that the business team can stretch a bit to feel comfortable will create sufficient value for the business one other practice i've found useful is that if you can do even very rough back of the envelope calculations to relate word level accuracy to some of the metrics on the right so if word level accuracy improves by one percent if you have any rough guess for will that improve query level accuracy maybe by 0.7 percent or 0.8 percent and how much will that improve search result quality and user engagement and maybe revenue if you're able to come up with even a very crude back of the envelope calculation sometimes these are also called fermi estimates you can read about this on wikipedia that can also be a way to help bridge the machine learning engineering metrics and the business metrics now it goes without saying that as part of estimating the value of a project i would encourage you to give thought to any ethical considerations as well such as is this project creating net positive societal value and if not i hope you won't do it or is this project reasonably fair and free from bias and have any ethical or values based concerns being openly aired and debated i find that issues of values and ethics is very domain dependent is very different in making loans versus healthcare versus recommending products online so i encourage you to look up any ethical frameworks that have been developed for your industry and your application and if you have any concerns raise it for debates within your team ultimately if you don't think the project you're working on will help other people or will help humanity move forward i hope you keep searching for other more meaningful projects to jump into in my work i have faced difficult choices where i really wasn't sure if a particular project was something i should work on because i really didn't know if it would make people net net better off and i found that having a team debate and discuss it openly often helps us get to a better answer and feel more comfortable with whatever decision we make and i have killed multiple projects on ethical considerations when i felt the project was economically sound but i didn't think it would help people and i just told the team i don't want to do it and i won't do it so i hope this gives you a framework for evaluating the value of a project and on the ethics and value piece i think all of us collectively should only work on projects that create net positive social value that help other people that move humanity forward i personally kill projects just on that basis there are multiple projects that i felt the economic value was completely sound the economic case was completely fine but i looked at the project and i said i don't think this actually helps people and i've killed projects just on that basis and told my teams let's find something else to work on because i'm not going to do that so i hope that you also be able to focus your efforts just on projects that help people and that help move humanity forward\", metadata={'source': 'CEBwVqRdKWc', 'title': '#39 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 15]', 'description': 'Unknown', 'view_count': 3170, 'thumbnail_url': 'https://i.ytimg.com/vi/CEBwVqRdKWc/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgXihGMA8=&rs=AOn4CLCDEeeWvtZuj-r0hTx0O4nAfw5x2w', 'publish_date': '2022-04-20 00:00:00', 'length': 445, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"say you've identified the problem found a worthy solution finished diligence for technical feasibility and value and you think this is worth doing let's take a look at the last steps of the scoping process of milestones and resourcing determining milestones and resourcing involves writing out the key specifications for your project this will include machine learning metrics such as accuracy or precision recall for some applications this may also include fairness types of metrics the specification will often also include software metrics regarding the software system such as latency throughput queries per second and so on given the computational resources available and if possible you might also write out estimates of the business metrics you hope to move for the project you're scoping such as how much incremental revenue if you have a way of estimating that in addition writing out the resources needed how much data from which teams personnel any help you need from cross-functional teams what software integrations data labeling support or other support you need from other teams and finally the timeline [Music] on which you hope to achieve certain milestones or deliverables now if you're looking at a machine learning project and you find that you're having a very hard time writing on some of these key specifications then you might also consider carrying out a benchmarking exercise to compare it to other similar projects that others may have worked on before or building a proof of concept first in order to get a better sense of what accuracy precision or latency throughput or other metrics might be feasible and only after you've done that plc proof of concept to then use that information to more confidently scope out the milestones and resources needed for a larger scale execution of the project you have in mind so that's it congratulations on making it to the end of this section on scoping i hope that these ideas will help you to pick valuable and meaningful projects to work on and thank you also for sticking with me from deployment through modeling through training all the way back to scoping and i hope this framework of the full cycle of machine learning project will also be useful for all the projects i hope you will build and deploy\", metadata={'source': '9p7WWapTrpA', 'title': '#40 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 16]', 'description': 'Unknown', 'view_count': 4621, 'thumbnail_url': 'https://i.ytimg.com/vi/9p7WWapTrpA/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVihBMA8=&rs=AOn4CLCLlzY9Gv22eYV77m6hHBLmBtxWHA', 'publish_date': '2022-04-20 00:00:00', 'length': 155, 'author': 'DeepLearningAI'})]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# embedding_api_url = f\"https://api-inference.huggingface.co/pipeline/feature-extraction/sentence-transformers/all-MiniLM-L6-v2\""
      ],
      "metadata": {
        "id": "nbNGyas1tKXd"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def get_embeddings(texts):\n",
        "#     response = requests.post(embedding_api_url, headers=headers, json={\"inputs\": texts, \"options\":{\"wait_for_model\":True}})\n",
        "#     return response.json()"
      ],
      "metadata": {
        "id": "iyQ0xXym-xvT"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# emb = get_embeddings(\"Hello\")"
      ],
      "metadata": {
        "id": "7lpna50E-25g"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# len(emb)"
      ],
      "metadata": {
        "id": "qhww-W8d_DWK"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter"
      ],
      "metadata": {
        "id": "u4fnLXLiAEhU"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(docs[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4Shr5IHArbY",
        "outputId": "7d8a4bd4-c10e-438d-e9a1-cef18d834a15"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "langchain.schema.document.Document"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# text = [doc[0].page_content for doc in docs]\n",
        "# text = \"\\n\".join(text)\n",
        "# text_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=150,\n",
        "#                                             #    separators=[\"\\n\\n\", \"\\n\", \"\\. \"]\n",
        "#                                                )\n",
        "# splits = text_splitter.split_text(text)"
      ],
      "metadata": {
        "id": "zTenij7o_FKk"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=150,\n",
        "                                            #    separators=[\"\\n\\n\", \"\\n\", \"\\. \"]\n",
        "                                               )\n",
        "splits = text_splitter.split_documents(docs)"
      ],
      "metadata": {
        "id": "6SdWHDJbCYxQ"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(splits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RaSmqxZOAHHR",
        "outputId": "1c9eb13c-7576-4c41-c370-130fe4d2df0f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "206"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "splits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ologf-94BGjF",
        "outputId": "f270479e-8cf9-48cc-aef3-7eeba368d936"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content=\"hi and welcome to machine learning engineering for production a lot of learners have asked me hey andrew i've learned to train a machine learning model now what do i do machine learning models are great but unless you know how to put them into production it's hard to get them to create the maximum amount of possible value or for those of you that may be looking for position in machine learning many interviewers will ask have you ever deployed a machine learning algorithm in this full course specialization the first course taught by me the second third and fourth courses taught by robert crowe who's an expert at this from google we hope to share with you the practical hands-on skills and techniques you need to not just build a machine learning model but also to put them into production and so by the end of this first course and by the end of this specialization i hope you have a good sense of the entire life cycle of machine learning project from training model to put into production and really how to manage the entire machine learning project let's jump in let's start with an example let's say you're using computer vision to inspect phones coming off the manufacturing line to see if there are defects on them so this film shown on the left doesn't have any scratches on it but if there was a scratch or crack or something a computer vision algorithm would hopefully be able to find this type of scratch or defect and maybe put the bounding box around it as part of quality control\", metadata={'source': 'NgWujOrCZFo', 'title': '#1 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 1, Lesson 1]', 'description': 'Unknown', 'view_count': 64901, 'thumbnail_url': 'https://i.ytimg.com/vi/NgWujOrCZFo/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVihBMA8=&rs=AOn4CLD0OTUfsVbchzFkcRWBQAoDN7d2Vw', 'publish_date': '2022-04-20 00:00:00', 'length': 583, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"vision algorithm would hopefully be able to find this type of scratch or defect and maybe put the bounding box around it as part of quality control if you get a data set of scratch phones you can train a computer vision algorithm maybe in your network to detect these types of defects but what do you now need to do in order to put this into production deployment this would be an example of how you could deploy a system like this you might have an edge device by edge device i mean a device that is living inside the factory that is manufacturing these smartphones and that edge device would have a piece of inspection software whose job it is to take a picture of the phone see if there's a scratch and then make a decision on whether this phone is acceptable or not this is actually commonly done in factories this is called automated visual defect inspection what the inspection software does is it will control camera that will take a picture of the smartphone as it rolls off the manufacturing line and it then has to make an api call to pass this picture to a prediction server and the job of the prediction server is to accept these api calls you know receive an image make a decision as to whether or not this phone is effective and return this prediction and then the inspection software can make the appropriate control decision whether to let the stone move on in the manufacturing line or whether to shove it to a side because you know was defective and not acceptable so after you\", metadata={'source': 'NgWujOrCZFo', 'title': '#1 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 1, Lesson 1]', 'description': 'Unknown', 'view_count': 64901, 'thumbnail_url': 'https://i.ytimg.com/vi/NgWujOrCZFo/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVihBMA8=&rs=AOn4CLD0OTUfsVbchzFkcRWBQAoDN7d2Vw', 'publish_date': '2022-04-20 00:00:00', 'length': 583, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"to let the stone move on in the manufacturing line or whether to shove it to a side because you know was defective and not acceptable so after you have trained a learning algorithm maybe trained in your network to take as input x pictures of phones and map them to why predictions about whether the phone is defective or not you still have to take this machine learning model puts it in a prediction server set up api interfaces and really write all of the rest of the software in order to deploy this learning algorithm into production this prediction server is sometimes in the cloud and sometimes the prediction server is actually at the edge as well in fact in manufacturing we use edge deployments a lot because you can't have your factory go down every time your internet access goes down but cloud deployments with prediction server is a server in the cloud is also used for many applications let's say you write all the software what could possibly go wrong it turns out that just because you've trained a learning algorithm that does well on your test set which is to be celebrated it's great when you do well when you hold a test set unfortunately reaching that milestone doesn't mean you're done there can still be quite a lot of work and challenges ahead to get a valuable production deployment running for example let's say your training set has images that look like this there's a good phone on the left the one in the middle has a big scratch across it and you've trained your\", metadata={'source': 'NgWujOrCZFo', 'title': '#1 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 1, Lesson 1]', 'description': 'Unknown', 'view_count': 64901, 'thumbnail_url': 'https://i.ytimg.com/vi/NgWujOrCZFo/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVihBMA8=&rs=AOn4CLD0OTUfsVbchzFkcRWBQAoDN7d2Vw', 'publish_date': '2022-04-20 00:00:00', 'length': 583, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"set has images that look like this there's a good phone on the left the one in the middle has a big scratch across it and you've trained your learning algorithm to recognize that phones like this on the left are okay meaning that no defects and maybe draw bounding boxes around scratches or other defects it finds in phones when you deploy it in the factory you may find that the real-life production deployment gives you back images like this much darker ones because the lighting factory because the lighting conditions in the factory have changed for some reason compared to the time when the training set was collected this problem is sometimes called concept drift or data drift you learn more about these terms later in this week but this is one example of the many practical problems that we as machine learning engineers should step up to solve if we want to make sure that we don't just do well on the hold out test set but that our systems actually create value in a practical production deployment environment i've worked on quite a few projects where my machine learning team and i would successfully know a proof of concept and by that i mean we train a model in jupiter notebook and it will work great and we will celebrate that you know you should celebrate it when you have a learning algorithm work well in a jupiter notebook or in a development environment but it turns out that sometimes i'll see many projects where that success which is a great success to the practical\", metadata={'source': 'NgWujOrCZFo', 'title': '#1 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 1, Lesson 1]', 'description': 'Unknown', 'view_count': 64901, 'thumbnail_url': 'https://i.ytimg.com/vi/NgWujOrCZFo/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVihBMA8=&rs=AOn4CLD0OTUfsVbchzFkcRWBQAoDN7d2Vw', 'publish_date': '2022-04-20 00:00:00', 'length': 583, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"or in a development environment but it turns out that sometimes i'll see many projects where that success which is a great success to the practical deployment is still maybe another six months of work and this is just one of many of the practical things that a machine learning team has to watch out for and handle in order to actually deploy these systems some machine learning engineers will say is not a machine learning problem to access these problems you know the data set changes some machine engineers think well is that a machine learning problem my point of view is that our job is to make these things work um and so if the data set has changed is i think of it as my responsibility when i work on a project to step in and do what i can to adjust the data distribution as it is rather than as i wish it is so this specialization will teach you about a lot of these important practical things for building machine learning systems that work not just in the lab not just in the jupyter notebook but in a production deployment environment a second challenge of deploying machine learning models in production is that it takes a lot more than machine learning code over the last decade there's been a lot of attention on machine learning models so your neural network or other algorithm that learns a function mapping from some input to some output and there's been amazing progress in machine learning models but it turns out that if you look at a machine learning system in production if\", metadata={'source': 'NgWujOrCZFo', 'title': '#1 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 1, Lesson 1]', 'description': 'Unknown', 'view_count': 64901, 'thumbnail_url': 'https://i.ytimg.com/vi/NgWujOrCZFo/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVihBMA8=&rs=AOn4CLD0OTUfsVbchzFkcRWBQAoDN7d2Vw', 'publish_date': '2022-04-20 00:00:00', 'length': 583, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"output and there's been amazing progress in machine learning models but it turns out that if you look at a machine learning system in production if this little orange rectangle represents the machine learning code the machine learning model code then this is all the code you need for the entire machine learning project i feel like for many machine learning projects maybe only five to ten percent maybe even less of the code is machine learning code and and i think this is one of the reasons why when you have a proof of concept model working maybe in jupiter notebook it can still be a lot of work to go from that initial proof of concept to the production deployment so sometimes people refer to the poc or the proof of concept to production gap and a lot of that gap is sometimes just the sheer amount of work it is to also write all of this code out here beyond the initial machine learning model code so what is all this other stuff this is a diagram that i've adapted from a paper by d scully and others beyond the machine learning code there are also many components especially components for managing the data such as data collection data verification feature extraction and after you are serving it how to monitor the system well monitor the data comes back help you analyze it but there are often many other components that need to be built to enable a working production deployment so in this course you learn what are all of these other pieces of software needed for a valuable\", metadata={'source': 'NgWujOrCZFo', 'title': '#1 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 1, Lesson 1]', 'description': 'Unknown', 'view_count': 64901, 'thumbnail_url': 'https://i.ytimg.com/vi/NgWujOrCZFo/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVihBMA8=&rs=AOn4CLD0OTUfsVbchzFkcRWBQAoDN7d2Vw', 'publish_date': '2022-04-20 00:00:00', 'length': 583, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"be built to enable a working production deployment so in this course you learn what are all of these other pieces of software needed for a valuable production deployment but rather than looking at all of these complex pieces one of the most useful frameworks i found for organizing the workflow of a machine learning project is to systematically plan out the life cycle of a machine learning project let's go to the next video to dive in to what is the full life cycle of a machine learning project and i hope this framework will be very useful for all of your machine learning projects that you plan to deploy in the future let's go to the next video\", metadata={'source': 'NgWujOrCZFo', 'title': '#1 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 1, Lesson 1]', 'description': 'Unknown', 'view_count': 64901, 'thumbnail_url': 'https://i.ytimg.com/vi/NgWujOrCZFo/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVihBMA8=&rs=AOn4CLD0OTUfsVbchzFkcRWBQAoDN7d2Vw', 'publish_date': '2022-04-20 00:00:00', 'length': 583, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"when on building a machine learning system i found that thinking through the machine learning project life cycle is a effective way for me to plan out all the steps that i need to work on and when you are working machine learning system i think you find too that this framework allows you to plan out all the important things you need to do in order to get the system to work and also to minimize surprises so let's dive in these are the major steps of a machine learning project first is scoping in which you have to define the project just decide what to work on what exactly do you want to apply machine learning to and what is x and what is why after having chosen the project you then have to collect data or acquire the data you need for your algorithm this includes defining the data and establishing a baseline and then also labeling and organizing the data there's some best practices for this that are not intuitive that you learn more about later in this week after you have your data you then have to train the model during the model phase you have to select and train the model and also perform error analysis you might know that machine learning is often a highly iterative task so during the process of error analysis you may go back and update the model or you might also go back to the earlier phase and decide you need to collect more data as well as part of error analysis before taking the system to deployments i'll often also carry out a final check or maybe a final audit to\", metadata={'source': 'e69ZWbbsGng', 'title': '#2 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 1, Lesson 2]', 'description': 'Unknown', 'view_count': 17867, 'thumbnail_url': 'https://i.ytimg.com/vi/e69ZWbbsGng/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGEIgSyhlMA8=&rs=AOn4CLA8kWPqqdWaNG7RqHwYKsKN6DUZUA', 'publish_date': '2022-04-20 00:00:00', 'length': 235, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"more data as well as part of error analysis before taking the system to deployments i'll often also carry out a final check or maybe a final audit to make sure that the system's performance is good enough and that is sufficiently reliable for the application sometimes an engineer things that when you deploy a system you're done i now tell most people when you deploy a system for the first time you're maybe about halfway to the finish line because it's often only after you turn on live traffic that you then learn the second half of the important lessons needed in order to get the system to perform well to carry out the deployment step you have to deploy it in production write the software needed to put into production and then also monitor the system track the data that continues to come in and maintain the system for example if the data distribution changes you may need to update the model and so after the initial deployment maintenance will often mean going back to perform more error analysis and maybe retrain the model or it might mean taking the data you get back now that the system is deployed and is running on live data and feeding that back into your data set to then potentially update your data retrain the model and so on until you can put an updated model into deployment i found this framework useful for a very large variety of machine learning projects from computer vision to audio data to structured data to many other applications so feel free to take a screenshot\", metadata={'source': 'e69ZWbbsGng', 'title': '#2 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 1, Lesson 2]', 'description': 'Unknown', 'view_count': 17867, 'thumbnail_url': 'https://i.ytimg.com/vi/e69ZWbbsGng/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGEIgSyhlMA8=&rs=AOn4CLA8kWPqqdWaNG7RqHwYKsKN6DUZUA', 'publish_date': '2022-04-20 00:00:00', 'length': 235, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"of machine learning projects from computer vision to audio data to structured data to many other applications so feel free to take a screenshot of this image and use it with your friends or by yourself to plan out your machine learning projects as well thanks also to landing ai's dylan laird and daniel biberiata who are instrumental to developing this diagram in this video we quickly went through the machine learning project life cycle in order to deepen our understanding of this project life cycle it'll be useful to walk through a concrete example so in the next video let's step through what these different steps of machine learning project life cycle look like in the context of a speech recognition application let's go on to the next video\", metadata={'source': 'e69ZWbbsGng', 'title': '#2 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 1, Lesson 2]', 'description': 'Unknown', 'view_count': 17867, 'thumbnail_url': 'https://i.ytimg.com/vi/e69ZWbbsGng/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGEIgSyhlMA8=&rs=AOn4CLA8kWPqqdWaNG7RqHwYKsKN6DUZUA', 'publish_date': '2022-04-20 00:00:00', 'length': 235, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"one of the successes of deep learning has been speech recognition deep learning has made speech recognition much more accurate than you know maybe a decade ago and this is allowing many of us to use speech recognition in our smart speakers on our smartphones for voice search and in other contexts you may have heard occasionally about the research work that goes into building better speech models but what else is needed to actually build a valuable production deployment speech recognition system let's use the machine learning project life cycle to set through a speech recognition example so you can understand all the steps needed to actually build and deploy such a system i've worked on speech recognition systems in a commercial context before and so the first step of that was scoping have to first define the project and just make a decision to work on speech recognition say for voice search as part of defining the project i'd also encourage you to try to estimate or maybe at least guesstimate the key metrics this will be very problem dependent almost every application will have its own unique set of goals and metrics but in case of speech recognition some things i cared about were how accurate is the speech system was the latency how long does the system take to transcribe speech and what is the throughput how many queries per second could we handle and then if possible you might also try to estimate the resources needed so how much time how much compute how much budget as\", metadata={'source': 'YJsRD_hU4tc', 'title': '#3 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 1, Lesson 3]', 'description': 'Unknown', 'view_count': 15612, 'thumbnail_url': 'https://i.ytimg.com/vi/YJsRD_hU4tc/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgWyhEMA8=&rs=AOn4CLAQfNBgyjpOwU5T3OkoP8ckWEpJWQ', 'publish_date': '2022-04-20 00:00:00', 'length': 723, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"second could we handle and then if possible you might also try to estimate the resources needed so how much time how much compute how much budget as well as timeline how long would it take to carry out this project i'll have a lot more to say on scoping in week 3 of this course so we'll come back to this topic and describe this in greater detail as well the next step is the data stage where you have to define the data and establish a baseline and also label and organize the data what's hard about this one of the challenges of practical speech recognition systems is is the data label consistently here's an audio clip of a fairly typical recording you might get if you're working on speech recognition for voice search let me play this audio clip um today's weather and the question is given this audio clip that you just heard um today's weather would you want to transcribe it like that which if you have transcriptionists label the data this would be a perfectly reasonable transcription or would you want to transcribe it like that which is also a completely reasonable transcription or should the transcriptionist say well there's often a lot of noise in audio you know maybe there's a sound of a clunk if something fell down and you don't want to transcribe noise so maybe it's just noise and you should transcribe it like that it turns out that any of these three ways of transcribing the audio is just fine i would probably prefer either the first or the second not the third but what\", metadata={'source': 'YJsRD_hU4tc', 'title': '#3 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 1, Lesson 3]', 'description': 'Unknown', 'view_count': 15612, 'thumbnail_url': 'https://i.ytimg.com/vi/YJsRD_hU4tc/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgWyhEMA8=&rs=AOn4CLAQfNBgyjpOwU5T3OkoP8ckWEpJWQ', 'publish_date': '2022-04-20 00:00:00', 'length': 723, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"out that any of these three ways of transcribing the audio is just fine i would probably prefer either the first or the second not the third but what would hurt your learning algorithms performance is if one third of the transcription is used the first one third the second and one third the third way of transcribing because then your data is inconsistent and confusing for the learning algorithm because how is the learning algorithm supposed to guess which one of these conventions a specific transcriptionist happened to use for an audio clip so spotting correcting consistencies like that maybe just asking everyone to standardize on this first convention that can have a significant impact on your learning album's performance so we'll come back later in this course to dive into some best practices for how to spot inconsistencies and how to address them other examples of data definition questions for an audio clip like today's weather how much silence do you want before and after each clip after a speaker has stopped speaking do you want to include another 100 milliseconds of silence after that or 300 milliseconds or 500 milliseconds half a second or how do you perform volume normalization some speakers speak loudly some are less loud and then there's actually a tricky case of if you have a single audio clip with some really loud volume and some really soft volume all within the same audio clip so how do you perform volume normalization questions like all of these are data\", metadata={'source': 'YJsRD_hU4tc', 'title': '#3 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 1, Lesson 3]', 'description': 'Unknown', 'view_count': 15612, 'thumbnail_url': 'https://i.ytimg.com/vi/YJsRD_hU4tc/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgWyhEMA8=&rs=AOn4CLAQfNBgyjpOwU5T3OkoP8ckWEpJWQ', 'publish_date': '2022-04-20 00:00:00', 'length': 723, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"volume and some really soft volume all within the same audio clip so how do you perform volume normalization questions like all of these are data definition questions a lot of progress in machine learning that is a lot of machine learning research was driven by researchers working to improve performance on benchmark data sets in that model researchers might download the data set and just work on that fixed data set and this mindset has led to tremendous progress in machine learning so no complaints at all about this mindset but if you are working on a production system then you don't have to keep the data set fixed i often edit the training sets or even at the test set if that's what's needed in order to improve the data quality to get a production system to work better so what a practical ways to do this effectively not an ad hoc way but systematic frameworks for making sure you have high quality data you learn more about this later in this course and later in the specialization as well after you've collected your data set the next step is modeling in which you have to select and train the model and perform error analysis the three key inputs that go into training a machine learning model are the code that is the algorithm or the neural network model architecture that you might choose you also have to pick hyper parameters and then there's the data and running the codes with your hyperparameters on your data gives you the machine learning model the accelerated machine\", metadata={'source': 'YJsRD_hU4tc', 'title': '#3 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 1, Lesson 3]', 'description': 'Unknown', 'view_count': 15612, 'thumbnail_url': 'https://i.ytimg.com/vi/YJsRD_hU4tc/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgWyhEMA8=&rs=AOn4CLAQfNBgyjpOwU5T3OkoP8ckWEpJWQ', 'publish_date': '2022-04-20 00:00:00', 'length': 723, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"and then there's the data and running the codes with your hyperparameters on your data gives you the machine learning model the accelerated machine learning model for learning from say audio clips to text transcripts i've found that in a lot of research work or academic work you tend to hold the data fixed and vary the code and maybe vary the hyperparameters in order to try to get good performance in contrast i found that for a lot of product teams if your main goal is to just build and deploy a working valuable machine learning system i found that it can be even more effective to hold the code fixed and to instead focus on optimizing the data and maybe the hyper parameters in order to get a high performing model a machine learning system [Music] includes both code and data and also hyper parameters but they're maybe a bit easier to optimize than the code or data and i found that rather than taking a model centric view of trying to optimize the code to your fixed data set for many problems you can use an open source implementation of something that you download off github and instead just focus on optimizing the data so during modeling you have to select and train some model architecture maybe some neural network architecture error analysis can then tell you where your model still falls short and if you can use that error analysis to tell you how to systematically improve your data maybe improve the code too that's okay but often if air analysis can tell you how to\", metadata={'source': 'YJsRD_hU4tc', 'title': '#3 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 1, Lesson 3]', 'description': 'Unknown', 'view_count': 15612, 'thumbnail_url': 'https://i.ytimg.com/vi/YJsRD_hU4tc/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgWyhEMA8=&rs=AOn4CLAQfNBgyjpOwU5T3OkoP8ckWEpJWQ', 'publish_date': '2022-04-20 00:00:00', 'length': 723, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"analysis to tell you how to systematically improve your data maybe improve the code too that's okay but often if air analysis can tell you how to systematically improve the data that can be a very efficient way for you to get to a high accuracy model and part of the trick is you don't want to just feel like you need to collect more data all the time because we could always use more data but rather than just trying to collect more and more and more data which is helpful but can be expensive if error analysis can help you be more targeted in exactly what data to collect that can help you be much more efficient in building an accurate model finally when you have trained the model and when error analysis seems to suggest it's working well enough you're then ready to go into deployment check speech recognition this is how you might deploy a speech system you have a mobile phone this would be an edge device with software running locally on your phone that software taps into the microphone to record what someone is saying maybe for voice search and in a typical implementation of speech recognition you would use a vad module vad stands for voice activity detection and it's usually a relatively simple algorithm maybe a learning algorithm and the job of the vid allows the smartphone to select out just the audio that contains hopefully someone speaking so that you can send only that audio clip to your prediction server and in this case maybe the prediction server lives in the cloud\", metadata={'source': 'YJsRD_hU4tc', 'title': '#3 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 1, Lesson 3]', 'description': 'Unknown', 'view_count': 15612, 'thumbnail_url': 'https://i.ytimg.com/vi/YJsRD_hU4tc/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgWyhEMA8=&rs=AOn4CLAQfNBgyjpOwU5T3OkoP8ckWEpJWQ', 'publish_date': '2022-04-20 00:00:00', 'length': 723, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"someone speaking so that you can send only that audio clip to your prediction server and in this case maybe the prediction server lives in the cloud this would be a common deployment pattern the prediction server then returns both the transcript so the user so you can see what the system thinks you said and it also returns the search results if you're doing voice search and the transcript and search results are then displayed in the front end code running on your mobile phone so implementing this type of system would be the work needed to deploy a speech model in production even after it's running though you still have to monitor and maintain the system so here's something that happened to me once my team had built a speech recognition system and it was trained mainly on adult voices we pushed it to production ran into production and we found that over time more and more young individuals kind of teenagers you know sometimes even younger seem to be using our speech recognition system and the voices of very young individuals just sound different and so my speech systems performance started to degrade we just were not that good at recognizing speech as spoken by younger voices and so we had to go back and find a way you know collect more data other things in order to fix it so one of the key challenges when it comes to deployment is concept drift or data drift which is what happens when the data distribution changes such as there are more and more young voices being fed to the\", metadata={'source': 'YJsRD_hU4tc', 'title': '#3 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 1, Lesson 3]', 'description': 'Unknown', 'view_count': 15612, 'thumbnail_url': 'https://i.ytimg.com/vi/YJsRD_hU4tc/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgWyhEMA8=&rs=AOn4CLAQfNBgyjpOwU5T3OkoP8ckWEpJWQ', 'publish_date': '2022-04-20 00:00:00', 'length': 723, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content='is concept drift or data drift which is what happens when the data distribution changes such as there are more and more young voices being fed to the speech recognition system and knowing how to put in place appropriate monitors to spot such problems and then also how to fix them in a timely way is a key skill needed to make sure your production deployment creates a value you hope it will to recap in this video you saw the full life cycle of a machine learning project using speech recognition as the running example so from scoping to data to modeling to deployment next i want to briefly share with you the major concepts and sequencing you learn about in this course so come with me to the next video', metadata={'source': 'YJsRD_hU4tc', 'title': '#3 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 1, Lesson 3]', 'description': 'Unknown', 'view_count': 15612, 'thumbnail_url': 'https://i.ytimg.com/vi/YJsRD_hU4tc/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgWyhEMA8=&rs=AOn4CLAQfNBgyjpOwU5T3OkoP8ckWEpJWQ', 'publish_date': '2022-04-20 00:00:00', 'length': 723, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"you've seen the machine learning project lifecycle let's briefly go over what you learned in the rest of this course even though i presented the lifecycle going from left to right i found that for learning these materials it'll be more efficient for you to start at the end go and start from deployment and then work backwards to modeling data and then scoping so in the rest of this week starting with the next video you learn about the most important ideas in deployment next week in week 2 you learn about modeling you may have learned about how to train the machine learning model from other courses in this video i'll share some new ideas that you may not have heard before of how to systematically use a data centric approach to be more efficient in how you improve the performance of your model then in the third and final week of this course you learn about data how to define data and establish a baseline and how to label and organize your data in a way that is systematic not ad hoc not hacking around in the jupyter notebook in the hope that you stumble on the right insights but in a more systematic way that helps you be more efficient in defining the data that will help the modeling to help you get to deployment and then finally in week three we'll also have an optional section on scoping in which i hope to share with you some tips i've learned on how to define effective machine learning projects throughout this course you also learn about ml ops or machine learning operations\", metadata={'source': '1zhmudvZAs4', 'title': '#4 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 1, Lesson 4]', 'description': 'Unknown', 'view_count': 10354, 'thumbnail_url': 'https://i.ytimg.com/vi/1zhmudvZAs4/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgVSg_MA8=&rs=AOn4CLCjx3M4zOGG3DUM828U49cMKTa7eA', 'publish_date': '2022-04-20 00:00:00', 'length': 163, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"i've learned on how to define effective machine learning projects throughout this course you also learn about ml ops or machine learning operations which is an emerging discipline that comprises a set of tools and principles to support progress through the machine learning project life cycle but especially these three steps for example at landing ai where on co we used to do a lot of these steps manually which is okay but slow but after building an emma ops 2 called landing lens for computer vision applications all these steps became much quicker the key idea in ml ops is that systematic ways to think about scoping data modeling and deployment and also software tools to support the best practices so that's it in this course we're going to start at the end goal start from deployment and then work our way backwards as you already know being the deploy a system is one of the most important and valuable skills in machine learning today so let's go on to the next video where we'll dive deep into the most important lessons most important ideas needed to deploy machine learning systems i will see you in the next video\", metadata={'source': '1zhmudvZAs4', 'title': '#4 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 1, Lesson 4]', 'description': 'Unknown', 'view_count': 10354, 'thumbnail_url': 'https://i.ytimg.com/vi/1zhmudvZAs4/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgVSg_MA8=&rs=AOn4CLCjx3M4zOGG3DUM828U49cMKTa7eA', 'publish_date': '2022-04-20 00:00:00', 'length': 163, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"one of the most exciting moments of any machine learning project is when you get to deploy your model but what makes deployment hard i think there are two major categories of challenges in deploying a machine learning model first are the machine learning or the statistical issues and second are the software engine issues let's step through both of these so you can understand what you need to do to make sure that you have a successful deployment of your system one of the challenges of a lot of deployments is concept drift and data drift loosely this means what if your data changes after your system has already been deployed i had previously given an example from manufacturing where you might have trained a learning algorithm to detect scratches on smartphones under one set of lighting conditions and then maybe the lighting and the factory changes that's one example of the distribution of data changes let's walk through a second example using speech recognition i've trained a few speech recognition systems and when i built speech systems quite often i would have some purchase data so this would be some purchase or license data which includes both the input x the audio as well as the transcript y that the speech system is supposed to output and in addition to data that you might purchase from a vendor you might also have historical user data of user speaking to your application together with transcripts of that real user data and such user data of course should be collected with\", metadata={'source': 'UyEtTyeahus', 'title': '#5 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 1, Lesson 5]', 'description': 'Unknown', 'view_count': 11572, 'thumbnail_url': 'https://i.ytimg.com/vi/UyEtTyeahus/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGEogSihlMA8=&rs=AOn4CLC7sJtZTLBF7HIaUAQtjjaYBM3pfQ', 'publish_date': '2022-04-20 00:00:00', 'length': 862, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"user data of user speaking to your application together with transcripts of that real user data and such user data of course should be collected with very clear user opt-in permission and clear safeguards for user privacy after you've trained your speech recognition system on a data set like this you might then evaluate it on a test set but because speech data does change over time when i build speech recognition systems sometimes i will collect a def set or hold up validation set as well as test set comprising data from just the last few months so you can test it on fairly recent data to make sure your system works even on relatively recent data and then after you push the system to deployments the question is will the data change or after you've run it for a few weeks for a few months has the data changed yet again because of the data has changed such as the language changes or maybe people are using a brand new model of smartphone which has a different microphone so the audio sounds different then the performance of your speech recognition system can degrade and it's important for you to recognize how the data has changed and if you need to update your learning algorithm as a result when data changes sometimes it is a gradual change such as the english language which does change but changes very slowly with new vocabulary introduced at a relatively slow rate and sometimes data changes very suddenly where there's a sudden shock to a system for example when covet 19 the\", metadata={'source': 'UyEtTyeahus', 'title': '#5 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 1, Lesson 5]', 'description': 'Unknown', 'view_count': 11572, 'thumbnail_url': 'https://i.ytimg.com/vi/UyEtTyeahus/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGEogSihlMA8=&rs=AOn4CLC7sJtZTLBF7HIaUAQtjjaYBM3pfQ', 'publish_date': '2022-04-20 00:00:00', 'length': 862, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"introduced at a relatively slow rate and sometimes data changes very suddenly where there's a sudden shock to a system for example when covet 19 the pandemic hit a lot of credit card fraud systems started to not work because the purchase patents of individuals suddenly change many people that did relatively little online shopping suddenly started to use much more online shopping and so the way that people were using credit cards changed very suddenly and this actually tripped up a lot of anti-fraud systems and this very sudden shift to the data distribution meant that many machine learning teams were scrambling a little bit at the start of covid to collect new data and retrain systems in order to make them adapt to this very new data distribution sometimes the terminology of how to describe these data changes is not used completely consistently but sometimes the term data drift is used to describe if the input distribution x changes such as if a new politician or celebrity suddenly becomes well known and is mentioned much more than before and the term concept drift refers to if the desired mapping from x to y changes such as if before covert 19 perhaps for a given user a lot of surprising online purchases should have flagged that account for fraud but after the starter cover 19 maybe those same purchases would not have really been any calls for alarming in terms of flagging that the credit card may have been stolen or another example of concept drift let's say that x is the\", metadata={'source': 'UyEtTyeahus', 'title': '#5 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 1, Lesson 5]', 'description': 'Unknown', 'view_count': 11572, 'thumbnail_url': 'https://i.ytimg.com/vi/UyEtTyeahus/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGEogSihlMA8=&rs=AOn4CLC7sJtZTLBF7HIaUAQtjjaYBM3pfQ', 'publish_date': '2022-04-20 00:00:00', 'length': 862, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"any calls for alarming in terms of flagging that the credit card may have been stolen or another example of concept drift let's say that x is the size of a house and y is the price of a house because you're trying to estimate housing prices well if because of inflation or changes in the market houses maybe become more expensive over time then the same size hulls will end up with a higher price and so that would be concept drift maybe the size of houses haven't changed but the price of a given house changes whereas data drift would be if say people start building larger houses or start building smaller houses and thus the input distribution of the sizes and houses actually changes over time so when you deploy a machine learning system one of the most important tasks will often be to make sure you can detect and manage any changes including both concept drift which is when the definition of what is y given x changes as well as data drift which is if the distribution of x changes even if the mapping from x and y does not change in addition to managing these changes to the data a second set of issues that you will have to manage to deploy a system successfully are software engineering issues when you are implementing a prediction service whose job it is to take queries x and output prediction y you have a lot of design choices as to how to implement this piece of software here's a checklist of questions that might help you with making the appropriate decisions for managing the\", metadata={'source': 'UyEtTyeahus', 'title': '#5 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 1, Lesson 5]', 'description': 'Unknown', 'view_count': 11572, 'thumbnail_url': 'https://i.ytimg.com/vi/UyEtTyeahus/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGEogSihlMA8=&rs=AOn4CLC7sJtZTLBF7HIaUAQtjjaYBM3pfQ', 'publish_date': '2022-04-20 00:00:00', 'length': 862, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"to how to implement this piece of software here's a checklist of questions that might help you with making the appropriate decisions for managing the software engineering issues one decision you have to make for your application is do you need real-time predictions or are batch predictions okay for example if you are building a speech recognition system where the user speaks and you need to get a response back in half a second then clearly you need real-time predictions in contrast i have also built systems for hospitals that take patient records take electronic health records and run an overnight batch process to see if there's something associated with the patients that we can spot so in that type of system it was fine if we just ran it in a batch of patient records once per night and so whether you need to write real-time software they can respond within you know hundreds of milliseconds or whether you can write software that just does a lot of computation overnight that will affect how you implement your software and by the way later this week you also get to step through an optional programming exercise where you get to implement a real-time prediction service on your own computer you see that at the optional exercise at the end of this week so second question you need to ask is does your prediction service run in the cloud or does it run at the edge or maybe even in a web browser today there are many speech recognition systems that run in the cloud because having the\", metadata={'source': 'UyEtTyeahus', 'title': '#5 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 1, Lesson 5]', 'description': 'Unknown', 'view_count': 11572, 'thumbnail_url': 'https://i.ytimg.com/vi/UyEtTyeahus/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGEogSihlMA8=&rs=AOn4CLC7sJtZTLBF7HIaUAQtjjaYBM3pfQ', 'publish_date': '2022-04-20 00:00:00', 'length': 862, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"or does it run at the edge or maybe even in a web browser today there are many speech recognition systems that run in the cloud because having the compute resources of the cloud allows for more accurate speech recognition but there are also some speech systems for example a lot of speech systems within cars actually run at the edge and there are also some mobile speech recognition systems that work even if your internet even if your wi-fi is turned off so those would be examples of speech systems that run at the edge when i'm deploying visual inspection systems in factories i pretty much almost always run that at the edge as well because sometimes unavoidably the internet connection between the factory and you know the rest of the internet may go down and you just can't afford to shut down the factory whenever this internet connection goes down which which happens very rarely but maybe sometimes does happen and with the rise of modern web browsers there are better and better tools for deploying learning algorithms right there within a web browser as well when building a prediction service is also useful to take into account how much compute resources you have there have been quite a few times where i trained the neural network on a very powerful gpu only to realize that i couldn't afford an equally powerful set of gpus for deployment and wound up having to do something else to compress or reduce the model complexity so if you know how much cpu or gpu resources and maybe also\", metadata={'source': 'UyEtTyeahus', 'title': '#5 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 1, Lesson 5]', 'description': 'Unknown', 'view_count': 11572, 'thumbnail_url': 'https://i.ytimg.com/vi/UyEtTyeahus/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGEogSihlMA8=&rs=AOn4CLC7sJtZTLBF7HIaUAQtjjaYBM3pfQ', 'publish_date': '2022-04-20 00:00:00', 'length': 862, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"and wound up having to do something else to compress or reduce the model complexity so if you know how much cpu or gpu resources and maybe also how much memory resources you have for your prediction service then that could help you choose the right software architecture depending on your application especially if it's real-time application latency and throughput such as measure in terms of qps queries per second will be other software entering metrics you may need to hit in speech recognition it's not uncommon to want to get an answer back to the user within half a second or 500 milliseconds and of this 500 millisecond budget you may be able to allocate only say 300 milliseconds to your speech recognition and so that gives a latency requirement for your system and throughput refers to how many queries per second do you need to handle given your compute resources maybe given a certain number of cloud servers so for example if you're building a system that needs to handle a thousand queries per second it would be useful to make sure to spec out your system so that you have enough compute resources to hit the qps requirement next is logging when building your system it may be useful to log as much of the data as possible for analysis and review as well as to provide more data for retraining your learning algorithm in the future finally security and privacy i find that for different applications the required levels of security and privacy can be very different for example when i\", metadata={'source': 'UyEtTyeahus', 'title': '#5 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 1, Lesson 5]', 'description': 'Unknown', 'view_count': 11572, 'thumbnail_url': 'https://i.ytimg.com/vi/UyEtTyeahus/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGEogSihlMA8=&rs=AOn4CLC7sJtZTLBF7HIaUAQtjjaYBM3pfQ', 'publish_date': '2022-04-20 00:00:00', 'length': 862, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"security and privacy i find that for different applications the required levels of security and privacy can be very different for example when i was working on electronic health records patient records clearly the requirements for security and privacy were very high because patient records are very highly sensitive information and depending on your application you might want to design in the appropriate level of security and privacy based on how sensitive that data is and also sometimes based on regulatory requirements so if you save this checklist somewhere going through this when you're designing your software might help you to make the appropriate software engineering choices when implementing your prediction service so to summarize deploying a system requires two broad sets of tools there is writing the software to enable you to deploy the system in production and there is what you need to do to monitor the system performance and to continue to maintain it especially in the phase of concept drift as well as data drift one of the things you see when you're building machine learning systems is that the practices for the very first deployments will be quite different compared to when you are updating or maintaining a system that has already previously been deployed i know that there's some engineers that view deploying the machine learning model as getting to the finish line unfortunately i think the first deployment means you may be only about halfway there and the second\", metadata={'source': 'UyEtTyeahus', 'title': '#5 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 1, Lesson 5]', 'description': 'Unknown', 'view_count': 11572, 'thumbnail_url': 'https://i.ytimg.com/vi/UyEtTyeahus/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGEogSihlMA8=&rs=AOn4CLC7sJtZTLBF7HIaUAQtjjaYBM3pfQ', 'publish_date': '2022-04-20 00:00:00', 'length': 862, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"learning model as getting to the finish line unfortunately i think the first deployment means you may be only about halfway there and the second half of your work is just starting only after your first deployment because even after you've deployed there's a lot of work to feed the data back and maybe to update the model to keep on maintaining the model even in the phase of changes to the data one of the things we'll touch on in later videos is some of the differences between the first deployment such as if your product never had a speech recognition system but you've trained the speech recognition system and you're deploying it for the first time versus you already have had the learning algorithm running for some time and you want to maintain or update that implementation to summarize in this video you saw some of the machine learning or statistical related issues such as concept driven data drift as well as some of the software engineering related issues such as whether you need a batch or real-time prediction service and what are the compute and memory requirements you have to take into account now it turns out that when you're deploying a machine learning model there are a number of common design patterns the common deployment patterns that are used in many applications across many different industries in the next video you see what are some of the most common deployment patterns so that you can hopefully pick the right one for your application let's go on to the next\", metadata={'source': 'UyEtTyeahus', 'title': '#5 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 1, Lesson 5]', 'description': 'Unknown', 'view_count': 11572, 'thumbnail_url': 'https://i.ytimg.com/vi/UyEtTyeahus/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGEogSihlMA8=&rs=AOn4CLC7sJtZTLBF7HIaUAQtjjaYBM3pfQ', 'publish_date': '2022-04-20 00:00:00', 'length': 862, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"see what are some of the most common deployment patterns so that you can hopefully pick the right one for your application let's go on to the next video\", metadata={'source': 'UyEtTyeahus', 'title': '#5 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 1, Lesson 5]', 'description': 'Unknown', 'view_count': 11572, 'thumbnail_url': 'https://i.ytimg.com/vi/UyEtTyeahus/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGEogSihlMA8=&rs=AOn4CLC7sJtZTLBF7HIaUAQtjjaYBM3pfQ', 'publish_date': '2022-04-20 00:00:00', 'length': 862, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"when you've trained the learning algorithm the best way to deploy it is usually not to just turn it on and hope for the best because well what if something goes wrong when deploying systems there are a number of common use cases or types of use cases as well as different patterns for how you deploy depending on your use case let's go through that in this video in the last video i alluded to some of the differences between a first deployment versus a maintenance or an update deployment let's flesh this out into a little bit more detail one type of deployment is if you are offering a new product or capability that you had not previously offered for example if you're offering a speech recognition service that you had not offered before in this case a common design pattern is to start with a small amount of traffic and then gradually ramp it up a second common deployment use case is if there's something that's already being done by a person but we would now like to use a learning algorithm to either automate or assist with that task for example if you had people in a factory inspecting smartphones or scratches but now you would like to use a learning algorithm to either assist or automate that task the fact that people were previously doing this gives you a few more options for how you deploy and you see shadow mode deployment takes advantage of this and finally a third common deployment case is if you've already been doing this task with a previous implementation of a machine\", metadata={'source': 'ErNp43wcudY', 'title': '#6 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 1, Lesson 6]', 'description': 'Unknown', 'view_count': 9615, 'thumbnail_url': 'https://i.ytimg.com/vi/ErNp43wcudY/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgWShCMA8=&rs=AOn4CLDXpx65XXcQdGXgUMnu_TmwnkBCTQ', 'publish_date': '2022-04-20 00:00:00', 'length': 713, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"advantage of this and finally a third common deployment case is if you've already been doing this task with a previous implementation of a machine learning system but you now want to replace it with hopefully an even better one in these cases two recurring themes you see are that you often want a gradual ramp up with monitoring in other words rather than sending tons of traffic to a maybe not fully proven learning algorithm you may send it only a small amount of traffic and monitor it and then ramp up the percentage or amount of traffic and the second idea you see a few times is rollback meaning that if for some reason the album isn't working it's nice if you can revert back to the previous system if indeed there was an earlier system let's start with an example in visual inspection where perhaps you've had human inspectors inspect smartphones for defects for stretches and you would now like to automate some of this work with a learning algorithm when you have people initially doing a task one common deployment pattern is to use shadow mode deployment and what that means is that you will start by having a machine learning algorithm shadow the human inspector and run in parallel with the human inspector during this initial phase the learning algorithm's output is not used for any decision in the factory so whatever the learning algorithm says we're going to go over the human judgment for now so let's say for this smartphone the human says it's fine no defect the learning\", metadata={'source': 'ErNp43wcudY', 'title': '#6 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 1, Lesson 6]', 'description': 'Unknown', 'view_count': 9615, 'thumbnail_url': 'https://i.ytimg.com/vi/ErNp43wcudY/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgWShCMA8=&rs=AOn4CLDXpx65XXcQdGXgUMnu_TmwnkBCTQ', 'publish_date': '2022-04-20 00:00:00', 'length': 713, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"algorithm says we're going to go over the human judgment for now so let's say for this smartphone the human says it's fine no defect the learning algorithm says it's fine maybe for this example a big scratch down the middle person says it's not okay and the learning algorithm agrees and maybe for this example with a smaller scratch maybe the person says this is not okay but the learning algorithm makes a mistake and actually thinks this is okay the purpose of a shadow mode deployment is that it allows you to gather data of how the learning algorithm is performing and how that compares to the human judgments and by sampling the opus you can then verify if the learning algorithms predictions are accurate and therefore use that to decide whether or not to maybe allow the learning algorithms to make some real decisions in the future so when you already have some system that is making good decisions and that system can be human inspectors or even an older implementation of a learning algorithm using a shadow mode deployments can be a very effective way to let you verify the performance of a learning algorithm before letting it make any real decisions when you are ready to let a learning algorithm start making real decisions a common deployment pattern is to use a canary deployment so there's a phone album says is okay rejects that says okay rejects that rejects that and in the country deployments you would roll out to a small fraction maybe five percent maybe even less of traffic\", metadata={'source': 'ErNp43wcudY', 'title': '#6 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 1, Lesson 6]', 'description': 'Unknown', 'view_count': 9615, 'thumbnail_url': 'https://i.ytimg.com/vi/ErNp43wcudY/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgWShCMA8=&rs=AOn4CLDXpx65XXcQdGXgUMnu_TmwnkBCTQ', 'publish_date': '2022-04-20 00:00:00', 'length': 713, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"okay rejects that rejects that and in the country deployments you would roll out to a small fraction maybe five percent maybe even less of traffic initially and stop let the algorithm making real decisions but by running this on only a small percentage of the traffic hopefully if the album makes any mistakes it will affect only a small fraction of the traffic and this gives you more of an opportunity to monitor the system and ramp up the percentage of traffic it gets only gradually and only when you have greater confidence in this performance the phrase can redeployment is a reference to the english idiom or the english phrase can be in a coal mine which refers to how coal miners used to use canneries to spot if there's a gas leak but with academy deployment hopefully this allows you to spot problems early on before there are maybe overly large consequences to your factory or other context in which you're deploying you're learning algorithm another deployment pattern that is sometimes used is a blue green deployment let me explain with a picture say you have a system a camera software for collecting phone pictures in your factory these phone images are sent to a piece of software that takes these images and routes them into some visual inspection system in the terminology of a blue green deployments the old version of your software is called the blue version and the new version the learning algorithm you just implemented is called the green version in a blue green deployment\", metadata={'source': 'ErNp43wcudY', 'title': '#6 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 1, Lesson 6]', 'description': 'Unknown', 'view_count': 9615, 'thumbnail_url': 'https://i.ytimg.com/vi/ErNp43wcudY/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgWShCMA8=&rs=AOn4CLDXpx65XXcQdGXgUMnu_TmwnkBCTQ', 'publish_date': '2022-04-20 00:00:00', 'length': 713, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"is called the blue version and the new version the learning algorithm you just implemented is called the green version in a blue green deployment what you do is have the router send images to the old or the blue version and have that make decisions and then when you want to switch over to the new version what you would do is have the router stop sending images to the old one and suddenly switch over to the new version so the way a blue green deployment is implemented is you would have an old prediction service maybe running on some set of service you then spin up a new prediction service the green version and you would have the router suddenly switch the traffic over from the old one to the new one the advantage of a blue green deployment is that there's an easy way to enable rollback if something goes wrong you can just very quickly have the router go back reconfigure the router to send traffic back to the old or the blue version assuming that you kept your blue version of the prediction service running in a typical implementation of a blue green deployment people think of switching over the traffic 100 all at the same time but of course you can also use a more gradual version where you slowly send traffic over as you can imagine whether you use shadow mode canon remote blue green or some other deployment pattern quite a lot of software is needed to execute this emma ops tools can help with implementing these deployment patterns or you can implement it yourself one of the\", metadata={'source': 'ErNp43wcudY', 'title': '#6 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 1, Lesson 6]', 'description': 'Unknown', 'view_count': 9615, 'thumbnail_url': 'https://i.ytimg.com/vi/ErNp43wcudY/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgWShCMA8=&rs=AOn4CLDXpx65XXcQdGXgUMnu_TmwnkBCTQ', 'publish_date': '2022-04-20 00:00:00', 'length': 713, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"of software is needed to execute this emma ops tools can help with implementing these deployment patterns or you can implement it yourself one of the most useful frameworks i have found for thinking about how to deploy a system is to think about deployment not as a zero one is either deploy or not deploy but instead to design a system thinking about what is the appropriate degree of automation for example in visual inspection of smartphones one extreme would be if there's no automation so the human only system slightly more automated would be if your system is running in shadow mode so your learning albums are putting predictions but it's not actually used in the factory so that would be shadow mode a slightly greater degree of automation would be ai assistance in which given a picture like this of a smartphone you may have a human inspector make the decision but maybe an ai system can affect the user interface to highlight the regions where there's a scratch to help draw the person's attention to where it may be most useful for them to look the user interface or ui design is critical for human assistance but this could be a way to get a slightly greater degree of automation while still keeping the human in the loop an even greater degree of automation may be partial automation where given a smartphone if the learning algorithm is sure it's fine then that's his decision if it's sure it's defective then we just go with the ai already's decision but if the learning algorithm\", metadata={'source': 'ErNp43wcudY', 'title': '#6 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 1, Lesson 6]', 'description': 'Unknown', 'view_count': 9615, 'thumbnail_url': 'https://i.ytimg.com/vi/ErNp43wcudY/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgWShCMA8=&rs=AOn4CLDXpx65XXcQdGXgUMnu_TmwnkBCTQ', 'publish_date': '2022-04-20 00:00:00', 'length': 713, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"is sure it's fine then that's his decision if it's sure it's defective then we just go with the ai already's decision but if the learning algorithm is not sure in other words if the learning album's prediction is not a confident zero or one maybe only then do we send this to a human so this would be partial automation where if the learning algorithm is confident of its prediction we go of the learning algorithm but for the hopefully small subset of images where the album is not sure we send that to a human to get their judgment and the human judgment can also be very valuable data to feedback to further train and improve the algorithm i find that this partial automation is sometimes a very good design point for applications where the learning algorithm's performance isn't good enough for full automation and then of course beyond partial automation there is full automation where we might have the learning algorithm make every single decision so there is a spectrum of using only human decisions on the left all the way to using only the ai systems decisions on the right and many deployment applications will start from the left and gradually move to the right and you do not have to get all the way to full automation you could choose to stop using ai assistance or partial automation or you could choose to go to full automation depending on the performance of your system and the needs of the application on this spectrum [Music] both ai assistance and partial automation are\", metadata={'source': 'ErNp43wcudY', 'title': '#6 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 1, Lesson 6]', 'description': 'Unknown', 'view_count': 9615, 'thumbnail_url': 'https://i.ytimg.com/vi/ErNp43wcudY/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgWShCMA8=&rs=AOn4CLDXpx65XXcQdGXgUMnu_TmwnkBCTQ', 'publish_date': '2022-04-20 00:00:00', 'length': 713, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"depending on the performance of your system and the needs of the application on this spectrum [Music] both ai assistance and partial automation are examples of human in the loop deployments i find that for consumer internet applications such as if you run a web search engine or an online speech recognition system a lot of consumer software internet businesses have to use full automation because it's just not feasible to have someone on the back end doing some work every time someone does a web search or does a product search but outside consumer software internet for example inspecting things in factories there are actually many applications where the best design point may be a human in the loop deployments rather than a full automation deployment in this video you saw a few patterns of deployments such as a shadow one deployment academy deployment a blue green deployment and you also saw how you can pick the most appropriate degree of automation depending on your application which could be a human in the loop deployments or for automation as we went through these ideas you heard me mention a few times the importance of monitoring to help you spot problems if any so they can address them let's dive into the details of how to monitor the system in the next video\", metadata={'source': 'ErNp43wcudY', 'title': '#6 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 1, Lesson 6]', 'description': 'Unknown', 'view_count': 9615, 'thumbnail_url': 'https://i.ytimg.com/vi/ErNp43wcudY/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgWShCMA8=&rs=AOn4CLDXpx65XXcQdGXgUMnu_TmwnkBCTQ', 'publish_date': '2022-04-20 00:00:00', 'length': 713, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"how can you monitor a machine learning system to make sure that it is meeting your performance expectations in this video you learned about best practices for monitoring deployed machine learning systems the most common way to monitor a machine learning system is to use a dashboard to track how it is doing over time depending on your application your dashboards may monitor different metrics for example you may have one dashboard to monitor the server load or a different dashboard to monitor the fraction of non-null outputs so sometimes the speed recognition system outputs no and it thinks the user didn't say anything so if this changes dramatically over time it may be an indication that something is wrong or one common one i've seen for a lot of structured data taught is monitoring the fraction of missing input values if that changes it may mean that something has changed about your data so when you're trying to decide what to monitor my recommendation is that you sit down with your team and brainstorm all the things that could possibly go wrong and that you want to know about if something does go wrong and for all the things that could go wrong brainstorm a few statistics or a few metrics that will detect that problem for example if you're worried about user traffic spiking causing the service to become overloaded then server loads would be maybe one metric you could track and so on for the other examples here and when i'm designing my monitoring dashboards for the first\", metadata={'source': 'hq_XyP9y0xg', 'title': '#7 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 1, Lesson 7]', 'description': 'Unknown', 'view_count': 8091, 'thumbnail_url': 'https://i.ytimg.com/vi/hq_XyP9y0xg/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVSg_MA8=&rs=AOn4CLDhFYKPxWoK0h4-kR503svf0dwFuA', 'publish_date': '2022-04-20 00:00:00', 'length': 646, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"loads would be maybe one metric you could track and so on for the other examples here and when i'm designing my monitoring dashboards for the first time i think it's okay to start off with a lot of different metrics and monitor a relatively large set and then gradually remove the ones that you find over time not to be particularly useful here are some examples of metrics i've used or i've seen others use on a variety of projects first are the software metrics such as memory compute latency throughput server load things that help you monitor the health of your software implementation of the prediction service or of other pieces of software around your learning algorithm but these software metrics will help you make sure that your software is running well many email ops tools will come out of the box already tracking these software metrics in addition to the software metrics i would often choose other metrics that help monitor the statistical health or the performance of the learning algorithm broadly there are two types of metrics you might brainstorm around one is input metrics which a metric set measure has your input distribution x change for example if you are building a speech recognition system you might monitor the average input length in seconds of the length of the audio clip fed to your system you might monitor the average input volume and if these change for some reason that might be something you would want to take a look at just to make sure this hasn't hurt the\", metadata={'source': 'hq_XyP9y0xg', 'title': '#7 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 1, Lesson 7]', 'description': 'Unknown', 'view_count': 8091, 'thumbnail_url': 'https://i.ytimg.com/vi/hq_XyP9y0xg/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVSg_MA8=&rs=AOn4CLDhFYKPxWoK0h4-kR503svf0dwFuA', 'publish_date': '2022-04-20 00:00:00', 'length': 646, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"input volume and if these change for some reason that might be something you would want to take a look at just to make sure this hasn't hurt the performance of your algorithm i mentioned just now number or percentage of missing values is a very common metric when using structured data some of which may have missing values or for the manufacturing visual inspection example you might monitor average image brightness if you think that lighting conditions could change and you want to make sure you know if it does so you can brainstorm different metrics to see if your input distribution x might have changed a second set of metrics that help you understand if your learning algorithm is performing well are output metrics such as how often does your speech recognition system return no the empty string because it thinks the user didn't say anything or if you have built a speech recognition system for voice search for web search using voice you might decide to see how often does a user do two very quick searches in a row with substantially the same input that might be a sign that you misrecognize their query the first time around is an imperfect signal but you could try this metric and see if it helps or you could monitor the number of times the user first try to use the speech system and then switches over to typing that could be a sign that the user got frustrated or gave up on your speech system and could indicate degrading performance and of course for web search you would also\", metadata={'source': 'hq_XyP9y0xg', 'title': '#7 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 1, Lesson 7]', 'description': 'Unknown', 'view_count': 8091, 'thumbnail_url': 'https://i.ytimg.com/vi/hq_XyP9y0xg/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVSg_MA8=&rs=AOn4CLDhFYKPxWoK0h4-kR503svf0dwFuA', 'publish_date': '2022-04-20 00:00:00', 'length': 646, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"that the user got frustrated or gave up on your speech system and could indicate degrading performance and of course for web search you would also use maybe very course metrics like click-through rate or ctr just to make sure that the overall system is healthy so these output metrics can help you figure out if either your learning algorithm outputs y has changed in some way or if something that comes even after you're learning algorithms output such as a user switching over to typing has changed in some significant way because input and output metrics are application specific most demo ops tools will need to be configured specifically to track the input and output metrics for your application you may already know that machine learning modeling is a highly iterative process so is deployment take modeling you would come up with a machine learning model and some data train the model that's an experiment and then do error analysis and use the error analysis to go back to figure out how to improve the model or your data and is by iterating through this loop multiple times that you then hopefully get to a good model i encourage you to think of deployment as an iterative process as well when you get your first deployment up and running and put in place a set of monitoring dashboards that's only the start of this iterative process a running system allows you to get real user data or real traffic and it is by seeing how your learning algorithm performs on real data on real traffic\", metadata={'source': 'hq_XyP9y0xg', 'title': '#7 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 1, Lesson 7]', 'description': 'Unknown', 'view_count': 8091, 'thumbnail_url': 'https://i.ytimg.com/vi/hq_XyP9y0xg/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVSg_MA8=&rs=AOn4CLDhFYKPxWoK0h4-kR503svf0dwFuA', 'publish_date': '2022-04-20 00:00:00', 'length': 646, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"running system allows you to get real user data or real traffic and it is by seeing how your learning algorithm performs on real data on real traffic that that allows you to do performance analysis and this in turn helps you to update your deployment and to keep on monitoring your system in my experience it usually takes a few tries to converge to the right set of metrics to monitor sometimes i've deployed the machine learning system and it's not uncommon for you to deploy a machine learning system with an initial set of metrics only to run the system for a few weeks and then to realize that something could go wrong with it that you hadn't thought of before and then to pick a new metric to monitor or for you to have some metric that you monitor for a few weeks and then decide that this metric hardly ever changes and does isn't useful and to get rid of that metric in favor of focusing attention on something else after you've chosen a set of metrics to monitor common practice would be to set thresholds for alarms so you may decide based on this that if the server load ever goes above 0.91 [Music] that may trigger an alarm or a notification to let you know or let the team know to see if there's a problem and maybe spin up some more servers or if the fraction of non-now opus goes above or beyond certain thresholds that might trigger an alarm or if the not fraction of missing values goes above or below some set of thresholds maybe that should trigger an alarm and it is okay if\", metadata={'source': 'hq_XyP9y0xg', 'title': '#7 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 1, Lesson 7]', 'description': 'Unknown', 'view_count': 8091, 'thumbnail_url': 'https://i.ytimg.com/vi/hq_XyP9y0xg/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVSg_MA8=&rs=AOn4CLDhFYKPxWoK0h4-kR503svf0dwFuA', 'publish_date': '2022-04-20 00:00:00', 'length': 646, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"an alarm or if the not fraction of missing values goes above or below some set of thresholds maybe that should trigger an alarm and it is okay if you adapt the metrics and the thresholds over time to make sure that they are flagging to you the most relevant cases of concern if something goes wrong with your learning algorithm if it's a software issue such as server load is too high then that may require changing the software implementation or if it is a performance problem associated with the accuracy of the learning algorithm then you may need to update your model or if the issue associated with the accuracy of the learning algorithm then you may need to go back to fix that and that's why many machine learning models will need a little bit of maintenance or retraining over time just like almost all software needs some level of maintenance as well when a model needs to be updated you can either retrain it manually where an engineer maybe you will retrain the model perform error analysis on the new model and make sure it looks okay before you push that to deployment or you could also put in place a system where there is automatic retraining today manual retraining is far more common than automatic retraining for many applications developers are reluctant to let the learning algorithm be fully automatic in terms of deciding to recreate and push a new model to production but there is there are some applications especially in consumer software internet where automatic retraining\", metadata={'source': 'hq_XyP9y0xg', 'title': '#7 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 1, Lesson 7]', 'description': 'Unknown', 'view_count': 8091, 'thumbnail_url': 'https://i.ytimg.com/vi/hq_XyP9y0xg/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVSg_MA8=&rs=AOn4CLDhFYKPxWoK0h4-kR503svf0dwFuA', 'publish_date': '2022-04-20 00:00:00', 'length': 646, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"and push a new model to production but there is there are some applications especially in consumer software internet where automatic retraining does happen we'll talk more about retraining and how to vet or verify a model's performance before pushing a new model out to production in next week's videos but the key takeaways are that it is only by monitoring the system that you can spot if there may be a problem that may cause you to go back to perform a deeper error analysis or that may cause you to go back to get more data with which you can update your model so as to maintain or improve your system's performance you learn more about how to update models in the next two weeks materials as well in this video you learn how to monitor the performance of a machine learning system so that in case something needs to be maintained or fixed you can be alerted so they can take the appropriate action we've talked about how to monitor the performance of a single machine learning model one of the most useful concepts is for more complex systems where you don't have just one model but a more complex machine learning pipeline how do you monitor the performance of that you learn about that in the next video\", metadata={'source': 'hq_XyP9y0xg', 'title': '#7 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 1, Lesson 7]', 'description': 'Unknown', 'view_count': 8091, 'thumbnail_url': 'https://i.ytimg.com/vi/hq_XyP9y0xg/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVSg_MA8=&rs=AOn4CLDhFYKPxWoK0h4-kR503svf0dwFuA', 'publish_date': '2022-04-20 00:00:00', 'length': 646, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"many ai systems are not just a single machine learning model running a prediction service but instead involves a pipeline of multiple steps so what are machine learning pipelines and how do you build monitoring systems for that let's learn about that in this video let's continue with our speech recognition example you've seen how a speech recognition system may take as input audio and output a transcript the way that speech recognition is typically implemented on mobile apps is not like this but instead is a slightly more complex pipeline where the audio is fed to a module called a vad or a voice activity detection module whose job it is to see if anyone is speaking and only if the vad module the voice activity detection module thinks someone is speaking does it then bother to pass the audio on to a speech recognition system whose job it is to then generate the transcript and the reason we use a voice activity detection or vad module is because if say your speech recognition system runs in the cloud you don't want to stream more bandwidth than you have to to your cloud server and so the voice activity detection module looks at the long stream of audio on your cell phone and clips or shortens the audio to just the part where someone is talking and streams only that to the cloud server to perform the speech recognition so this is an example of a machine learning pipeline where there is one step usually done by a learning alarm as well to decide if someone is talking or not and\", metadata={'source': '79UqdjnPEZ0', 'title': '#8 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 1, Lesson 8]', 'description': 'Unknown', 'view_count': 7758, 'thumbnail_url': 'https://i.ytimg.com/vi/79UqdjnPEZ0/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgXShFMA8=&rs=AOn4CLAqXCTKfEKzDr-1CVkNX7ytvQQxUA', 'publish_date': '2022-04-20 00:00:00', 'length': 572, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"an example of a machine learning pipeline where there is one step usually done by a learning alarm as well to decide if someone is talking or not and then the second step also done by a learning algorithm to generate the text transcript when you have two learning algorithms one that's learned to detect someone's talking and one that's learned to transcribe speech when you have two such modules working together changes to the first module may affect the performance of the second module as well for example let's say that because of the way a new cell phone's microphone works the vad module ends up clipping the audio differently maybe it leaves more silence at the start or end or less silence than the sound or end and thus if the vad's output changes that will cause the speech recognition system's input to change and that could cause the greater performance of the speech recognition system let's look at an example involving user profiles maybe you have user data such as click stream data showing what users are clicking on and this can be used to build a user profile that tries to capture key attributes or key characteristics of a user for example i once built user profiles that would try to estimate many attributes of users including whether or not the user seemed to own a car because this would help us decide if it was worth trying to offer car insurance office to that user and so whether the user owns a car could be yes or no or unknown or maybe other finer gradations and\", metadata={'source': '79UqdjnPEZ0', 'title': '#8 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 1, Lesson 8]', 'description': 'Unknown', 'view_count': 7758, 'thumbnail_url': 'https://i.ytimg.com/vi/79UqdjnPEZ0/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgXShFMA8=&rs=AOn4CLAqXCTKfEKzDr-1CVkNX7ytvQQxUA', 'publish_date': '2022-04-20 00:00:00', 'length': 572, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content='to offer car insurance office to that user and so whether the user owns a car could be yes or no or unknown or maybe other finer gradations and these and the typical way that the user profile is built is with a learning algorithm to try to predict if this user owns a call this type of user profile which can have a very long list of predicted attributes can then be fed to recommend a system another learning algorithm that then takes its understanding of the user to try to generate product recommendations now if something about the click stream data changes maybe this input distribution changes then maybe over time if we lose our ability to figure out if a user owns a car then the percentage of the unknown tag here may go up and because the user profiles output changes the input to the recommended system now changes and this might affect the quality of the product recommendations when you have machine learning pipelines these cascading effects in the pipeline can be complex to keep track of but if the percentage of unknown labels does go up this could be something that you want to be alerted to so that you can update the recommended system if needed to make sure you continue to generate high quality product recommendations so when building these complex machine learning pipelines which can have machine learning based components or non-machine learning based components throughout the pipeline i find it useful to brainstorm metrics to monitor that can detect changes including', metadata={'source': '79UqdjnPEZ0', 'title': '#8 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 1, Lesson 8]', 'description': 'Unknown', 'view_count': 7758, 'thumbnail_url': 'https://i.ytimg.com/vi/79UqdjnPEZ0/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgXShFMA8=&rs=AOn4CLAqXCTKfEKzDr-1CVkNX7ytvQQxUA', 'publish_date': '2022-04-20 00:00:00', 'length': 572, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"or non-machine learning based components throughout the pipeline i find it useful to brainstorm metrics to monitor that can detect changes including concept drift or data drive or both and multiple stages of the pipeline so metrics to monitor include software metrics for perhaps each of the components in the pipeline or perhaps for the overall pipeline as a whole as well as input metrics and potentially output metrics for each of the components of the pipeline and by brainstorming metrics associated with individual components of the pipeline as well this could help you spot problems such as the voice activity detection system of putting longer or shorter audio clips over time or the user profile system suddenly having more unknown attributes for whether the user owns a car and thereby alerts you to changes in the data that may require you to take action to maintain the model but the principle that you saw in the last video of brainstorm all the things that could go wrong including things that could go wrong with individual components of the pipeline and design metrics to track those that principle still applies only now you're looking at multiple components in the pipeline finally how quickly does data change the rate at which data changes is very problem dependent for example let's see a build to face recognition system then the rate at which people's appearances changes usually isn't that fast you know people's hairstyles and clothing does change with fashion changes and\", metadata={'source': '79UqdjnPEZ0', 'title': '#8 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 1, Lesson 8]', 'description': 'Unknown', 'view_count': 7758, 'thumbnail_url': 'https://i.ytimg.com/vi/79UqdjnPEZ0/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgXShFMA8=&rs=AOn4CLAqXCTKfEKzDr-1CVkNX7ytvQQxUA', 'publish_date': '2022-04-20 00:00:00', 'length': 572, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"the rate at which people's appearances changes usually isn't that fast you know people's hairstyles and clothing does change with fashion changes and as cameras get better we've been getting higher and higher resolution pictures of people over time but for the most part people's appearances don't change that much but there are sometimes things that can change very quickly as well such as if a factory gets a new batch of material for how they make cell phones and so all the cell phones start to change in appearance so some applications will have data that changes over the time scale of months or even years and some applications with data that could suddenly change in a matter of minutes speaking in very broad generalities i find that on average user data generally changes relatively slowly if you run a consumer-facing business with a very large number of users then it is quite rare for millions of users to all suddenly change their behavior all at the same time and so user data if a large number of users will usually change relatively slowly there are a few exceptions of course covet 19 being one of them where a shock to society actually caused a lot of people's behavior that all change at the same time and if you look at web search traffic you will see trends maybe a holiday or a new movie and people start searching for something new they just became popular so there are exceptions but on average if you have a very large group of users there are only a few forces that can\", metadata={'source': '79UqdjnPEZ0', 'title': '#8 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 1, Lesson 8]', 'description': 'Unknown', 'view_count': 7758, 'thumbnail_url': 'https://i.ytimg.com/vi/79UqdjnPEZ0/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgXShFMA8=&rs=AOn4CLAqXCTKfEKzDr-1CVkNX7ytvQQxUA', 'publish_date': '2022-04-20 00:00:00', 'length': 572, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"new they just became popular so there are exceptions but on average if you have a very large group of users there are only a few forces that can simultaneously change the behavior of a lot of people all at the same time in contrast if you work on a b2b or business to business application i find that enterprise data or business data can shift quite quickly because the factory making cell phones may suddenly decide to use a new coating for their cell phones and suddenly the entire data set changes because the cell phones suddenly all look different but if you're providing a machine learning system to a company then sometimes if the ceo of that company decides to change the way that business operates all of that data can shift very quickly i know that these two bullets are me speaking in generalities and there are certainly exceptions to both of these but maybe this will give you a way of thinking about how quickly your data is likely to change or not change so that's it congratulations on making it to the end of this first week's videos i hope you also take a look at the practice quizzes which will let you practice all these concepts and make sure you deeply understand them and if you want you can also take a look at this week's optional programming exercise which lets you deploy a machine learning model on your own computer and i also look forward to seeing you in next week's videos where we'll dive together much more deeply into the modeling part of the full cycle of machine\", metadata={'source': '79UqdjnPEZ0', 'title': '#8 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 1, Lesson 8]', 'description': 'Unknown', 'view_count': 7758, 'thumbnail_url': 'https://i.ytimg.com/vi/79UqdjnPEZ0/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgXShFMA8=&rs=AOn4CLAqXCTKfEKzDr-1CVkNX7ytvQQxUA', 'publish_date': '2022-04-20 00:00:00', 'length': 572, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"also look forward to seeing you in next week's videos where we'll dive together much more deeply into the modeling part of the full cycle of machine learning project i look forward to seeing you next week\", metadata={'source': '79UqdjnPEZ0', 'title': '#8 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 1, Lesson 8]', 'description': 'Unknown', 'view_count': 7758, 'thumbnail_url': 'https://i.ytimg.com/vi/79UqdjnPEZ0/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgXShFMA8=&rs=AOn4CLAqXCTKfEKzDr-1CVkNX7ytvQQxUA', 'publish_date': '2022-04-20 00:00:00', 'length': 572, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"in this week you learned about some best practices for building a machine learning model that is worthy of a production deployment one of my friends adam coats joked that the way he listened to me give advice to machine learning teams he felt the way i gave advice was quite consistent from project to project so that he could almost replace me with an if then else sequence of statements and i found too when several senior machine learning engineers look at the project the advice they tend to give is also remarkably consistent what you learned in this week is what are some of the key challenges of trying to build a production ready machine learning model things like how do you handle skewed data sets or what if you do well in the test set but for some reason that still isn't good enough for your actual application and i hope that after this week's materials you'll be able to very efficiently know how to improve your machine learning model to solve the most important problems that then make it deployment ready let's dive in this week our focus will be on the modeling part of the full cycle of a machine learning project and you learn some suggestions for how to select and train the model and how to perform error analysis and use that to drive model improvements one of the themes you hear me refer to multiple times is model centric ai development versus data centric ai development the way that ai has grown up there's been a lot of emphasis on how to choose the right model such as\", metadata={'source': 'lHXd2hBnlJk', 'title': '#9 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 1]', 'description': 'Unknown', 'view_count': 5825, 'thumbnail_url': 'https://i.ytimg.com/vi/lHXd2hBnlJk/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgWyhCMA8=&rs=AOn4CLAFFQIYhlOu6kNiN2BZrc_RI1XamQ', 'publish_date': '2022-04-20 00:00:00', 'length': 161, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"development versus data centric ai development the way that ai has grown up there's been a lot of emphasis on how to choose the right model such as maybe how to choose the right neural network architecture i found that for practical projects it can be even more useful to take a more data centric approach where you focus not just on improving the neural network architecture but on making sure you are feeding your algorithm high quality data and that ultimately lets you be more efficient in getting your system to perform well but the way i engage in data centric ai development is not to just go and try to collect more and more and more data which can be very time consuming but to instead use tools to help me improve the data in the most efficient possible way you learn some ways for how to do that in this week so i'm excited to go through this week's materials review on training models but first let's look at some key challenges that many teams face when building machine learning models by understanding these key challenges you'd be better able to spot them ahead of time and address them more efficiently for your projects let's go on to the next video\", metadata={'source': 'lHXd2hBnlJk', 'title': '#9 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 1]', 'description': 'Unknown', 'view_count': 5825, 'thumbnail_url': 'https://i.ytimg.com/vi/lHXd2hBnlJk/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgWyhCMA8=&rs=AOn4CLAFFQIYhlOu6kNiN2BZrc_RI1XamQ', 'publish_date': '2022-04-20 00:00:00', 'length': 161, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"what is hard about training a machine learning model that does well let's look at some key challenges one framework that i hope you keep in mind when developing machine learning systems is that ai systems and machine learning systems comprise both code meaning the algorithm or the model as well as data there's been a lot of emphasis in the last several decades on how to improve the code in fact a lot of ai research had grown up by researchers downloading data sets and trying to find an algorithm or model that does well on the data set but for many applications you have the flexibility to change the data if you don't like the data and so there are many projects where the algorithm or model is basically a solve problem some model you download off github will do well enough and it'd be more efficient to spend a lot of your time improving the data because the data usually has to be much more customized to your problem this is a view that will carry throughout this week and next week's materials diving into more detail when building a machine learning system you may have an algorithm or a model this would be your code and some data and it's by training your algorithm on the data that you then have your machine learning model that can make predictions and of course hyper parameters are an additional input to this process it is important for many applications to make sure you have a well-tuned learning rate and regularization parameter and maybe a few other things the hyper\", metadata={'source': 'oBB47VrQucA', 'title': '#10 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 2]', 'description': 'Unknown', 'view_count': 5467, 'thumbnail_url': 'https://i.ytimg.com/vi/oBB47VrQucA/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVSg_MA8=&rs=AOn4CLArqsDgm2vaCSoI6RgV8v4SUm-f7Q', 'publish_date': '2022-04-20 00:00:00', 'length': 311, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"important for many applications to make sure you have a well-tuned learning rate and regularization parameter and maybe a few other things the hyper parameters are important but because the space of hyper parameters is usually relatively limited i'm going to spend more of our time focusing on the code and on the data so model development is a highly iterative process you usually start off with some model and hyper parameters and data train the model and then take the model to carrier error analysis and use that to help you decide how to improve the model or the hyper parameters or the data because machine learning is such an empirical process being able to go through this loop many times very quickly is key to improving performance but one of the things that will help you improve performance too is each time through the loop being able to make good choices about how to modify the data or how to modify the model or how to modify the hyper parameters after you've done this enough times and achieve a good model one last step that's often useful is to carry out a richer error analysis and have your system go through a final audit to make sure that it is working before you push it to a production deployment so why is model development hard when building a model i think there are three key milestones that most projects should aspire to accomplish first is you probably want to make sure you do well at least on the training set so if you're predicting housing prices as a function of\", metadata={'source': 'oBB47VrQucA', 'title': '#10 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 2]', 'description': 'Unknown', 'view_count': 5467, 'thumbnail_url': 'https://i.ytimg.com/vi/oBB47VrQucA/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVSg_MA8=&rs=AOn4CLArqsDgm2vaCSoI6RgV8v4SUm-f7Q', 'publish_date': '2022-04-20 00:00:00', 'length': 311, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"accomplish first is you probably want to make sure you do well at least on the training set so if you're predicting housing prices as a function of the size of a house are you at least able to fit a line that fits your training set quite well after you've done well on the training set you then have to ask if your algorithm does well on the development set or the holdout cross-validation set and then also the test set if your algorithm isn't even doing well on the training set then it's very unlikely to do well on the def set or the test set so i think of step one as something you have to do first as a milestone on your way towards achieving step two and then after you do well on the dev set or test set you also have to make sure that your learning algorithm does well according to the business metrics or according to the project skills over the last several decades a lot of machine learning development was driven by the goal of doing well on the dev set or test set unfortunately for many problems having a high tested accuracy is not sufficient for achieving the goals of the project and this has led to a lot of frustration and disagreements between the machine learning team which is very good at doing this and business teams which care more about the business metrics or some other goals of a project so you may be wondering hey andrew how is it possibly true that achieving low average tested error isn't good enough for a project there are a few common patterns that i've seen\", metadata={'source': 'oBB47VrQucA', 'title': '#10 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 2]', 'description': 'Unknown', 'view_count': 5467, 'thumbnail_url': 'https://i.ytimg.com/vi/oBB47VrQucA/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVSg_MA8=&rs=AOn4CLArqsDgm2vaCSoI6RgV8v4SUm-f7Q', 'publish_date': '2022-04-20 00:00:00', 'length': 311, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"andrew how is it possibly true that achieving low average tested error isn't good enough for a project there are a few common patterns that i've seen across many projects where you need something beyond low average test set era and people to spot these issues will help you be more efficient in addressing them let's dive more into this topic in the next video\", metadata={'source': 'oBB47VrQucA', 'title': '#10 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 2]', 'description': 'Unknown', 'view_count': 5467, 'thumbnail_url': 'https://i.ytimg.com/vi/oBB47VrQucA/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVSg_MA8=&rs=AOn4CLArqsDgm2vaCSoI6RgV8v4SUm-f7Q', 'publish_date': '2022-04-20 00:00:00', 'length': 311, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"the job of a machine learning engineer would be much simpler if the only thing we ever had to do was do well on the holdout test set as hard as it is to do well in the holdout test set unfortunately sometimes that isn't enough let's take a look at some of the other things we sometimes need to accomplish in order to make a project successful we've already talked about concept drift and data drift last week but here are some additional challenges we may have to address for a production machine learning project first a machine learning system may have low average test set error but if its performance on a set of disproportionately important examples isn't good enough then the machine learning system will still not be acceptable for production deployment let me use an example from web search there are a lot of web search queries like these apple pie recipes latest movies wireless data plan i want to learn about the diwali festival these types of queries are sometimes called informational or transactional queries where i want to learn about apple pies or maybe i want to buy a new wireless data plan and and you might be willing to forgive a web search engine that this doesn't give you the best apple pie recipe because there are a lot of good apple pie recipes on the internet so for informational and transactional queries a web search engine wants to return the most relevant results but users are willing to forgive maybe ranking the best result number two or number three there's a\", metadata={'source': 'fiDmWKh_WeQ', 'title': '#11 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 3]', 'description': 'Unknown', 'view_count': 9812, 'thumbnail_url': 'https://i.ytimg.com/vi/fiDmWKh_WeQ/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVyhEMA8=&rs=AOn4CLAwmKPa4TeP1AkNe5G9v2o-XfdUvQ', 'publish_date': '2022-04-20 00:00:00', 'length': 641, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"engine wants to return the most relevant results but users are willing to forgive maybe ranking the best result number two or number three there's a different type of web search query such as stanford or reddit or youtube these are called navigational queries where the user has a very clear intent very clear desire to go to stanford.edu or reddit.com or youtube.com when a user has a very clear navigational intent they will tend to be very unforgiving if a web search engine does anything other than return standard.edu as the number one ranked results and the search engine that doesn't give the right results will quickly lose the trust of his users so navigational queries in this context are a disproportionately important set of examples and if you have a learning algorithm that improves your average test and accuracy for web search but messes up just a small handful of navigational queries that may not be acceptable for deployment and the challenge of course is that average test set accuracy tends to weight all examples equally whereas in web search some queries are disproportionately important now one thing you could do is try to give these examples a higher weight that could work for some applications but in my experience just changing the ways of different examples doesn't always solve the entire problem closely related to this is the question of performance on key slices of the data set for example let's say you built a machine learning algorithm for loan approval to\", metadata={'source': 'fiDmWKh_WeQ', 'title': '#11 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 3]', 'description': 'Unknown', 'view_count': 9812, 'thumbnail_url': 'https://i.ytimg.com/vi/fiDmWKh_WeQ/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVyhEMA8=&rs=AOn4CLAwmKPa4TeP1AkNe5G9v2o-XfdUvQ', 'publish_date': '2022-04-20 00:00:00', 'length': 641, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"this is the question of performance on key slices of the data set for example let's say you built a machine learning algorithm for loan approval to decide who is likely to repay a loan and thus to recommend approving certain loans for approval for such a system you will probably want to make sure that your system does not unfairly discriminate against loan applicants according to the ethnicity gender maybe the location the language or other protected attributes many countries also have laws or regulations that mandate that financial systems and loan approval processes not discriminate on the basis of a certain set of attributes sometimes called protected attributes so even if a learning algorithm for loan approval achieves high average tested accuracy it would not be acceptable for production deployment if it exhibits an unacceptable level of bias or discrimination whereas the ai community has had a lot of discussion about fairness to individuals and rightly so because this is an important topic we have to address and do well on the issue of quote fairness or performance of key slices also occurs in other settings let's say you run an online shopping website so an e-commerce website where you aggregate and sell products from many different manufacturers and many different brands of retailers you might want to make sure that your system treats fairly all major user retailer and product categories for example even if a machine learning system has high average tested accuracy\", metadata={'source': 'fiDmWKh_WeQ', 'title': '#11 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 3]', 'description': 'Unknown', 'view_count': 9812, 'thumbnail_url': 'https://i.ytimg.com/vi/fiDmWKh_WeQ/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVyhEMA8=&rs=AOn4CLAwmKPa4TeP1AkNe5G9v2o-XfdUvQ', 'publish_date': '2022-04-20 00:00:00', 'length': 641, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content='system treats fairly all major user retailer and product categories for example even if a machine learning system has high average tested accuracy maybe it recommends better products on average if it gives really irrelevant recommendations to all users of one ethnicity that may be unacceptable or if it always pushes products from large retailers and ignores the smaller brands that could also be harmful to the business because you may then lose all the small retailers and it would also feel unfair to build a recommended system that only ever recommends products from the large brands that ignores the smaller businesses or if you had a product recommender that gave highly relevant recommendations but for some reason would never recommend electronics products then maybe the retailers that sell electronics would be quite reasonably upset and this may not be the right thing for the retailers on your platform or for the long term health of your business even if the average tested accuracy shows that by not recommending electronics products you are showing slightly more relevant results to use to your users for some reason one thing you learn later this week is how to carry out analysis on key slices of the data to make sure that you spot and address potential problems like these next is the issue of rare classes and specifically of skewed data distributions in medical diagnosis is not uncommon for many patients not to have a certain disease and so if you have a data set which is 99', metadata={'source': 'fiDmWKh_WeQ', 'title': '#11 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 3]', 'description': 'Unknown', 'view_count': 9812, 'thumbnail_url': 'https://i.ytimg.com/vi/fiDmWKh_WeQ/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVyhEMA8=&rs=AOn4CLAwmKPa4TeP1AkNe5G9v2o-XfdUvQ', 'publish_date': '2022-04-20 00:00:00', 'length': 641, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"data distributions in medical diagnosis is not uncommon for many patients not to have a certain disease and so if you have a data set which is 99 negative examples because 99 of the population doesn't have a certain disease but one percent positive then you can achieve very good tested accuracy by writing a program that just says print zero don't need a learning algorithm just write this one line of code and you have 99 accuracy on your data set but clearly print 0 is not a very useful algorithm for disease diagnosis by the way this actually did happen to me once where my team had trained a huge neural network found we had 99 average accuracy and we found it achieved it by printing zero all the time so we basically trained a giant neural network that did exactly the same thing as print zero and of course when we discovered this we then went back to fix the problem but so hopefully this won't happen to you closely related to the issue of skewed data distributions which is often a discussion of positive and negatives is accuracy on rare clauses i was working with my friend pranav rashberger and others on diagnosis from chess x-rays and we were diagnosing clauses and we were working on deep learning to spot different conditions there were some relatively common conditions these are technical medical terminology but for medical condition called effusion we had about ten thousand images and so we're achieving we were able to achieve a high level of performance whereas for a much\", metadata={'source': 'fiDmWKh_WeQ', 'title': '#11 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 3]', 'description': 'Unknown', 'view_count': 9812, 'thumbnail_url': 'https://i.ytimg.com/vi/fiDmWKh_WeQ/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVyhEMA8=&rs=AOn4CLAwmKPa4TeP1AkNe5G9v2o-XfdUvQ', 'publish_date': '2022-04-20 00:00:00', 'length': 641, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"called effusion we had about ten thousand images and so we're achieving we were able to achieve a high level of performance whereas for a much rarer condition hernia we had about 100 images and so performance was much worse and it turns out that from a medical standpoint it's not acceptable for a diagnosis system to ignore obvious cases of hernia if a patient shows up and an x-ray clearly shows they have hernia a learning algorithm that misses that diagnosis would be problematic but because this was a relatively rare class the overall average tested accuracy of the algorithm was not that bad and in fact diagram could have completely ignored all cases of hernia and it would have had only a modest impact on this average chest set accuracy because cases of hernia were rare and the algorithm could pretty much ignore it without hurting this average tested accuracy that much if average tested accuracy gives equal weight to every single example in the test set i have heard pretty much this exact same conversation too many times in too many companies and the conversation goes like this a machine learning engineer says i did well on the test set this works let's use it and a product owner or business owner says but this doesn't work for my application and the machine learning engineer replies but i did well on the test set my advice to you if you ever find yourself in this conversation is don't get defensive we as a community have built lots of tools for doing well on the test set\", metadata={'source': 'fiDmWKh_WeQ', 'title': '#11 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 3]', 'description': 'Unknown', 'view_count': 9812, 'thumbnail_url': 'https://i.ytimg.com/vi/fiDmWKh_WeQ/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVyhEMA8=&rs=AOn4CLAwmKPa4TeP1AkNe5G9v2o-XfdUvQ', 'publish_date': '2022-04-20 00:00:00', 'length': 641, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"you if you ever find yourself in this conversation is don't get defensive we as a community have built lots of tools for doing well on the test set and that's to be celebrated i think it's great but we often need to go beyond that because just doing well on the test set isn't enough for many production applications when i'm building a machine learning system i view it as my job not just to do well on the test set but to produce a machine learning system that solves the actual business or application need and i hope you take a similar view as well later this week we'll go through some techniques usually involving error analysis maybe error analysis on slices of the data that will allow you to spot some of these issues that require going beyond average tested accuracy and help you with tools to tackle these broader challenges as well\", metadata={'source': 'fiDmWKh_WeQ', 'title': '#11 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 3]', 'description': 'Unknown', 'view_count': 9812, 'thumbnail_url': 'https://i.ytimg.com/vi/fiDmWKh_WeQ/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVyhEMA8=&rs=AOn4CLAwmKPa4TeP1AkNe5G9v2o-XfdUvQ', 'publish_date': '2022-04-20 00:00:00', 'length': 641, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"when starting work on a machine learning project one of the most useful first step to take is to establish a baseline and it's usually only after you've established a baseline level of performance that you can then have tools to efficiently improve on that baseline level let's dive into some best practices for quickly establishing that baseline let me use the speech recognition example let's say you've established that there are four major categories of speech in your data clear speech which is when someone speaks without much background noise speech with colonoids in the background as if they were in a car when they use your speech recognition system speech with people noise in the background deliver their outdoors with other people talk in the background or speech on a low bandwidth connection kind of what it sounds like if you're using a cell phone with a very bad cell phone connection if your accuracy on these four categories of speeches 94 89 87 70 accuracy you might be tempted to say wow it does worse on low bandwidth audio so let's focus our attention on that but before leaping to that conclusion it'd be useful to establish a baseline level of performance on all four of these categories you can do that by asking some human transcriptionist to label your data and measuring their accuracy what is human level performance on these four calories of speech in this example we find that if we can improve our performance on clear speech up to human level performance looks like\", metadata={'source': 'O5mqR4EFBQk', 'title': '#12 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 4]', 'description': 'Unknown', 'view_count': 6390, 'thumbnail_url': 'https://i.ytimg.com/vi/O5mqR4EFBQk/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgXShHMA8=&rs=AOn4CLB0TpVHG0zrvfDE5o4IpzIuPnF17g', 'publish_date': '2022-04-20 00:00:00', 'length': 461, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"these four calories of speech in this example we find that if we can improve our performance on clear speech up to human level performance looks like there's a potential for a one percent improvement there if we can raise our performance up to human level performance on audio of colonoids in the background maybe four percent improvement two percent improvement and essentially zero percent improvement on low bandwidth audio and so whereas we had previously said without the human level performance we may have thought working on low bandwidth audio was most promising with this analysis we realized that maybe the low bandwidth audio is so global even people humans can't recognize what was said and it may not be that fruitful to work on that instead it may be more fruitful to focus our attention on improving speech recognition with car noise in the background so in this example using human level performance which i'll sometimes abbreviate to hlp human level performance gives you a point of comparison or baseline that helps you decide where to focus your efforts on car noise data rather than on low bandwidth data it turns out the best practices for establishing a baseline are quite different depending on whether you're working on unstructured or structured data unstructured data refers to data sets like images maybe pictures of cats or audio like our speech recognition example or natural language like text from restaurant reviews unstructured data tends to be data that humans are\", metadata={'source': 'O5mqR4EFBQk', 'title': '#12 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 4]', 'description': 'Unknown', 'view_count': 6390, 'thumbnail_url': 'https://i.ytimg.com/vi/O5mqR4EFBQk/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgXShHMA8=&rs=AOn4CLB0TpVHG0zrvfDE5o4IpzIuPnF17g', 'publish_date': '2022-04-20 00:00:00', 'length': 461, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"or audio like our speech recognition example or natural language like text from restaurant reviews unstructured data tends to be data that humans are very good at interpreting in fact humans evolve to be very good at understanding images and audio and maybe language as well and because humans are so good at unstructured data tasks measuring human level performance or hlp is often a good way to establish a baseline if you are working on unstructured data in contrast structured data are the giant databases or the giant excel spreadsheets you might have such as if you run an e-com website the data showing which user purchased what at what time and for what price that will be stored in a giant database and this type of data stored in a giant excel spreadsheet or some more robust database would be an example of structured data or your product and inventory data you know that would also be stored as structured data because humans are not as good at looking at data like this to make predictions we certainly didn't evolve to look at giant spreadsheets human level performance is usually a less useful baseline for structured data applications i find that machine learning developments best practice is quite different depending on whether you're working on an unstructured data or structured data problem keeping in mind this difference let's take a look at some ways to establish baselines for both of these types of problems we've already talked about human level performance as a baseline\", metadata={'source': 'O5mqR4EFBQk', 'title': '#12 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 4]', 'description': 'Unknown', 'view_count': 6390, 'thumbnail_url': 'https://i.ytimg.com/vi/O5mqR4EFBQk/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgXShHMA8=&rs=AOn4CLB0TpVHG0zrvfDE5o4IpzIuPnF17g', 'publish_date': '2022-04-20 00:00:00', 'length': 461, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"take a look at some ways to establish baselines for both of these types of problems we've already talked about human level performance as a baseline particularly for unstructured data problems another way to establish a baseline is to do a literature search for save the art or look at open source results to see what others report they are able to accomplish on this type of problem for example if you're building a speech recognition system and others report a certain level of accuracy on data that's similar to yours then that may give you a starting point using open source you may also consider coming out with a quick and dirty implementation not a cisco system but just a quick and dirty implementation that could start to give you a sense of what may be possible finally if you already have a machine learning system running for your application then the performance of your previous system performance of your older system can also help you establish a baseline that you can then aspire to improve on what a baseline system or a baseline level of performance does is it helps to indicate what might be possible in some cases such as if you're using human level performance especially on unstructured data problems this baseline can also give you a sense of what is the irreducible error or what is bayes error in other words what is the best that anyone could possibly hope for in terms of performance on this problem such as helping us realize that maybe the low bandwidth audio is so bad\", metadata={'source': 'O5mqR4EFBQk', 'title': '#12 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 4]', 'description': 'Unknown', 'view_count': 6390, 'thumbnail_url': 'https://i.ytimg.com/vi/O5mqR4EFBQk/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgXShHMA8=&rs=AOn4CLB0TpVHG0zrvfDE5o4IpzIuPnF17g', 'publish_date': '2022-04-20 00:00:00', 'length': 461, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"that anyone could possibly hope for in terms of performance on this problem such as helping us realize that maybe the low bandwidth audio is so bad that it's just not possible to have more than 70 accuracy as in our earlier example and by helping us to get a very rough sense of what might be possible it can help us be much more efficient in terms of prioritizing what to work on sometimes i've seen some business teams push a machine learning team to guarantee that their learning algorithm will be 80 accurate or 90 or 99 accurate before the machine learning team has even had a chance to establish a rough baseline this unfortunately puts the machine learning team in a very difficult position if you are in that position i would urge you to consider pushing back and asking for time to establish a rough baseline level of performance before giving a more firm prediction about how accurate the machine learning system can eventually get to be uh it helps you to make your case feel free to tell them that i asked you to do so and i think establishing that baseline first will help set you and your team up better for long-term success now that talks about the importance of baseline there are few additional tips i want to share with you about how to get started quickly on the machine learning project let's go on to the next video to take a look at some of these tips\", metadata={'source': 'O5mqR4EFBQk', 'title': '#12 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 4]', 'description': 'Unknown', 'view_count': 6390, 'thumbnail_url': 'https://i.ytimg.com/vi/O5mqR4EFBQk/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgXShHMA8=&rs=AOn4CLB0TpVHG0zrvfDE5o4IpzIuPnF17g', 'publish_date': '2022-04-20 00:00:00', 'length': 461, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"let me share with you a few tips for getting started on the machine learning project this video will be a little bit of a grab bag of different ideas but i hope nonetheless many of these ideas will be useful to you we've talked about how machine learning is an iterative process where you start with a model data hyper parameters create a model carry out error analysis and then use that to drive further improvements and after you've done this a few times gone around the loop enough times when you have a good enough model you might then carry out a final performance audit before taking it to production in order to get started on this first step of coming with a model here are some suggestions when i'm starting on the machine learning project i almost always start with a quick literature search to see what's possible so you can look at online courses look at blogs look at open source projects and my advice to you if your goal is to build a practical production system and not to do research is don't obsess about finding the latest greatest algorithm instead spend half a day maybe a small number of days reading blog posts and pick something reasonable that lets you get started quickly if you can find an open source implementation that can also help you establish a baseline more efficiently i find that for many practical applications a reasonable algorithm with good data will often do just fine and will in fact outperform a great algorithm with not so good data so don't obsess about\", metadata={'source': '8Covj8F-NNc', 'title': '#13 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 5]', 'description': 'Unknown', 'view_count': 5365, 'thumbnail_url': 'https://i.ytimg.com/vi/8Covj8F-NNc/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgWyhDMA8=&rs=AOn4CLApqhKPfzI_OtifKVnUCHZamvka8A', 'publish_date': '2022-04-20 00:00:00', 'length': 384, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"reasonable algorithm with good data will often do just fine and will in fact outperform a great algorithm with not so good data so don't obsess about taking the algorithm that was just published in some conference last week that is the most cutting-edge algorithm is that find something reasonable find a good open source implementation and use that to get going quickly because being able to get started on this first step of this loop can make you more efficient in iterating through more times and that will help you get to good performance more quickly second question of often asked is hey andrew do i need to take into account deployment constraints such as compute constraints when picking a model my answer is yes you should take deployment constraints such as compute constraints into accounts if the baseline is already established and you're relatively confident that this project will work and does your goal is to build and deploy a system but if you've not yet even established a baseline or if you're not yet sure if this project will work and be worthy of deployment then i would say no or maybe not necessarily and if you are in a stage of the project where your first goal is to just establish a baseline and determine what is possible and if this project is even worth pursuing for the long term then it might be okay to ignore deployment constraints and just find some open source implementation and try it out to see what might be possible even if that open source\", metadata={'source': '8Covj8F-NNc', 'title': '#13 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 5]', 'description': 'Unknown', 'view_count': 5365, 'thumbnail_url': 'https://i.ytimg.com/vi/8Covj8F-NNc/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgWyhDMA8=&rs=AOn4CLApqhKPfzI_OtifKVnUCHZamvka8A', 'publish_date': '2022-04-20 00:00:00', 'length': 384, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"to ignore deployment constraints and just find some open source implementation and try it out to see what might be possible even if that open source implementation is so computationally intensive that you know you will never be able to deploy that of course no harm taking deployment constraints into account as well at this phase of the project but it might also be okay if you don't and focus on more efficiently establishing the baseline first finally when trying out the learning algorithm for the first time before running it on all your data i would urge you to run a few quick sanity checks for your code and your algorithm for example i will usually try to over fit a very small training data set before spending hours or sometimes even overnight or days trading the album on the large data set maybe even try to make sure you can fit one training example especially if the output is a complex output for example i was once working on a speech recognition system where the goal was to input audio and have a learning algorithm output a transcript when i trained my algorithm on just one example one audio clip when i trained my speech recognition system on just one audio clip on the training set which is just one audio clip my system outputs this and output space space space space space space so clearly it wasn't working and because my speech system couldn't even accurately transcribe one training example there wasn't much point to spending hours and hours training on a giant training\", metadata={'source': '8Covj8F-NNc', 'title': '#13 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 5]', 'description': 'Unknown', 'view_count': 5365, 'thumbnail_url': 'https://i.ytimg.com/vi/8Covj8F-NNc/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgWyhDMA8=&rs=AOn4CLApqhKPfzI_OtifKVnUCHZamvka8A', 'publish_date': '2022-04-20 00:00:00', 'length': 384, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"system couldn't even accurately transcribe one training example there wasn't much point to spending hours and hours training on a giant training set or for image segmentation if your goal is to take as input pictures like this and segment out the cats in the image then before spending hours training your system on hundreds or thousands of images a worthy sanity check would be to feed it just one image and see if it can at least overfit that one training example before scaling up to a larger data set and the advantage of this is you may be able to train your algorithm on one or a small handful of examples in just minutes or maybe even seconds and this lets you find bugs much more quickly finally for image classification problems even if you have 10 000 images or 100 000 images or a million images in your training set it might be worthwhile to very quickly train your algorithm on a small subset of just 10 or maybe 100 images because you can do that quickly and if your algorithm can't even do well on a hundred images well then it's clearly not going to do well on ten thousand images so this would be another useful sanity check for your code now after you've trained a machine learning model after you've trained your first model one of the most important things is how do you carry out error analysis to help you decide how to improve the performance of your algorithm let's go on to the next video to dive into error analysis and performance auditing\", metadata={'source': '8Covj8F-NNc', 'title': '#13 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 5]', 'description': 'Unknown', 'view_count': 5365, 'thumbnail_url': 'https://i.ytimg.com/vi/8Covj8F-NNc/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgWyhDMA8=&rs=AOn4CLApqhKPfzI_OtifKVnUCHZamvka8A', 'publish_date': '2022-04-20 00:00:00', 'length': 384, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"the first time you train a learning algorithm you can almost guarantee that it won't work not the first time out so i think of the heart of the machine learning development process as error analysis which if you do it well can tell you what's the most efficient use of your time in terms of what you should do to improve your learning algorithm's performance let's start with an example let me walk through an error analysis example using speech recognition when i'm carrying out error analysis this is pretty much what i would do myself in a spreadsheet to get a handle on one of the errors of the speech system you might listen to maybe a hundred mislabeled examples from your death set from the development set so let's say the first example was labels with the ground truth label stir-fried lettuce recipe but your learning album's prediction was stir fry lettuce recipe if you have a couple of hypotheses for what are the major types of data in your data set maybe you think some of the data has car noise some of the data has people noise then you can build a spreadsheet and i literally do this in a spreadsheet with a couple columns like this and when you listen to this example if this example has car noise in the background you can then make a check mark or other annotation in your spreadsheet to indicate that this example had car noise then you listen to the second example maybe sweetened coffee got mistranscribed as swedish coffee and maybe this example had people noise in the\", metadata={'source': 'quEHyoA94rw', 'title': '#14 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 6]', 'description': 'Unknown', 'view_count': 4840, 'thumbnail_url': 'https://i.ytimg.com/vi/quEHyoA94rw/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVihBMA8=&rs=AOn4CLA_qVxn2Ikv9_XPQSD4CMcAPeXkAg', 'publish_date': '2022-04-20 00:00:00', 'length': 508, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"then you listen to the second example maybe sweetened coffee got mistranscribed as swedish coffee and maybe this example had people noise in the background and maybe one example with sail away song was miss transcribed as selwy song and this again had people noise and let's catch up with transdrive as less ketchup and maybe this example had both call noise and people noise note that these tags up on top don't have to be mutually exclusive during this process of error analysis as you listen to audio clips you may come up with ideas for additional tags let's say this fourth example had a very low bandwidth connection and reflecting on the areas you're spotting you remember huh maybe quite a few of the audio clips have a low bandwidth connection at this point you may decide to add a new column to your spreadsheet with one more tag that says low bandwidth and check that and maybe go back to see if some of the other examples also had a low bandwidth connection so even though i went through this example using a slide when i'm doing error analysis myself sometimes i'll literally fire up a spreadsheet program like google sheets or excel or on a mac the numbers program and do it like this in the spreadsheet this process helps you understand whether the categories as denoted by tags that may be the source of more of the errors and thus may be worthy of further effort and attention until now error analysis has typically been done via a manual process say in a jupyter notebook or\", metadata={'source': 'quEHyoA94rw', 'title': '#14 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 6]', 'description': 'Unknown', 'view_count': 4840, 'thumbnail_url': 'https://i.ytimg.com/vi/quEHyoA94rw/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVihBMA8=&rs=AOn4CLA_qVxn2Ikv9_XPQSD4CMcAPeXkAg', 'publish_date': '2022-04-20 00:00:00', 'length': 508, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"thus may be worthy of further effort and attention until now error analysis has typically been done via a manual process say in a jupyter notebook or tracking errors in the spreadsheet i still sometimes do that way and if that's how you're doing it too that's fine but there are also emerging emma ops tools that making this process easier for developers for example when my team landing ai works on computer vision applications the whole team now uses landing lens which makes this much easier than a spreadsheet you've heard me say that training a model is an initial a model is an iterative process maybe it should come as no surprise that error analysis is also an iterative process where what a typical process would be is you might examine and tag some set of examples with an initial set of tags such as call noise and people noise and based on examining this initial set of examples you may come back and say you want to propose some new tags with the new tags you can then go back to examine and tag even more examples let me step through a few other examples of what such tags could be tick visual inspection you know the problem of finding defects in smartphones some of the tags could be specific class labels such as does this phone have a scratch or does have a dent and so on so it's fine if some of these tags are associated with specific clause labels why or some of the tags could be image properties is this picture of the phone blurry is it against a dark background or light\", metadata={'source': 'quEHyoA94rw', 'title': '#14 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 6]', 'description': 'Unknown', 'view_count': 4840, 'thumbnail_url': 'https://i.ytimg.com/vi/quEHyoA94rw/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVihBMA8=&rs=AOn4CLA_qVxn2Ikv9_XPQSD4CMcAPeXkAg', 'publish_date': '2022-04-20 00:00:00', 'length': 508, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"specific clause labels why or some of the tags could be image properties is this picture of the phone blurry is it against a dark background or light background is there a unwanted reflection in this picture the tags could also come from other forms of metadata what is the phone model what is the factory which is the manufacturing line that captured this specific image and the goal of this type of process where you come over tags label more data common attacks is to try to come up with a few categories where you could productively improve the algorithm such as in our earlier speech example deciding to work on speech with car noise in the background let me step through just one more example product recommendations for an online e-commerce site you might look at what products a system is recommending to users and find the clearly incorrect or irrelevant recommendations and try to figure out if there are specific user demographics such as are we really badly recommending products to younger women or to older men or to something else or are there specific product features or specific product categories where the recommendations are particularly poor and by iteratively brainstorming and applying such tags you can hopefully come up with a few ideas for calories of data that are worth trying to improve your algorithm's performance on as you go through these different tags here are some useful numbers to look at first what fraction of errors have that tagged for example if you\", metadata={'source': 'quEHyoA94rw', 'title': '#14 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 6]', 'description': 'Unknown', 'view_count': 4840, 'thumbnail_url': 'https://i.ytimg.com/vi/quEHyoA94rw/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVihBMA8=&rs=AOn4CLA_qVxn2Ikv9_XPQSD4CMcAPeXkAg', 'publish_date': '2022-04-20 00:00:00', 'length': 508, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"on as you go through these different tags here are some useful numbers to look at first what fraction of errors have that tagged for example if you listen to 100 audio clips and find that 12 percent of them were labeled with the car noise tag then that gives you a sense of how important is it to work on car noise it tells you also that even if you fix all of the car noise issues the performance may improve only by 12 which is actually not bad or you can ask of all the data with that tag what fraction is misclassified so far we've only talked about tagging the mislabeled examples for time efficiency you might focus your attention on tagging the mislabel the misclassified examples but if there's a tag you can apply to both correctly labeled and to mislabeled examples then you can ask of all the data of that tag what fraction is misclassified so for example if you find that of all the data with call noise 18 of it is mistranscribed then that tells you that the performance on data with this type of tag has only a certain level of accuracy and tells you how hard these examples with car noise really are you might also ask what fraction of all the data has that tagged this tells you how important relative to your entire data set are examples with that tag so what fraction of your entire data set has car noise and then lastly how much room for improvement is there on data with that tag and one example that you've already seen for how to do this analysis is to measure human level\", metadata={'source': 'quEHyoA94rw', 'title': '#14 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 6]', 'description': 'Unknown', 'view_count': 4840, 'thumbnail_url': 'https://i.ytimg.com/vi/quEHyoA94rw/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVihBMA8=&rs=AOn4CLA_qVxn2Ikv9_XPQSD4CMcAPeXkAg', 'publish_date': '2022-04-20 00:00:00', 'length': 508, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"room for improvement is there on data with that tag and one example that you've already seen for how to do this analysis is to measure human level performance on data with that tag so by brainstorming different tags you can segment your data into different categories and then use questions like these to try to decide what to prioritize working on let's dive more deeply into an example of doing this in the next video\", metadata={'source': 'quEHyoA94rw', 'title': '#14 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 6]', 'description': 'Unknown', 'view_count': 4840, 'thumbnail_url': 'https://i.ytimg.com/vi/quEHyoA94rw/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVihBMA8=&rs=AOn4CLA_qVxn2Ikv9_XPQSD4CMcAPeXkAg', 'publish_date': '2022-04-20 00:00:00', 'length': 508, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"in the last video you learned about brainstorming and tagging your data with different attributes let's see how you can use this to prioritize where to focus your attention here's the example we had previously with four tags and the accuracy of the algorithm human level performance and what's the gap between the current accuracy and human level performance rather than deciding to work on car noise because the gap to hlp is biggest one other useful factor to look at is what's the percentage of data with that tag let's say that sixty percent of your data is clean speech four percent is dated with car noise 30 has people noise and six percent is low bandwidth audio this tells us that if we could take clean speech and raise our accuracy from 94 to 95 on all the clean speech then multiplying 1 with 60 this tells us that if we could improve our performance on clear speech to human level performance our overall speech system would be 0.6 percent more accurate because we would do 1 better on 60 of the data so this will raise average accuracy by 0.6 percent on car noise if we can improve the performance by four percent on four percent of the data multiplying that out that gives us a 0.16 percent improvement and multiplying these out as well we get 0.6 percent and well this is essentially zero percent because we can't make that any better and so whereas previously we had said there's a lot of room for improvement in car noise in this slightly richer analysis we see that because people\", metadata={'source': 'BdZ6bjcixhk', 'title': '#15 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 7]', 'description': 'Unknown', 'view_count': 4273, 'thumbnail_url': 'https://i.ytimg.com/vi/BdZ6bjcixhk/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGEggTShlMA8=&rs=AOn4CLCtsUYStl02gGIVla8ukpDT_uDw4Q', 'publish_date': '2022-04-20 00:00:00', 'length': 351, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"and so whereas previously we had said there's a lot of room for improvement in car noise in this slightly richer analysis we see that because people noise accounts for such a large fraction of the data it may be more worthwhile to work on either people noise or maybe on clean speech because there's actually larger potential for improvements in both of those than for speech with car noise so to summarize when prioritizing what to work on you might decide on the most important categories to work on based on how much room for improvement there is such as compared to human level performance or according to some baseline comparison how frequently does that carry appear you can also take into account how easy it is to improve accuracy in that category for example if you have some ideas for how to improve the accuracy of speech with car noise maybe your data augmentation that might cause you to prioritize that category more highly than some other category where you just don't have as many ideas for how to improve the system and then finally how important it is to improve performance on that category for example you may decide that improving performance with car noise is especially important because when you're driving you have a stronger desire to do search especially search on maps and find addresses without needing to use your hands if your hands are supposed to be holding the steering wheel there is no mathematical formula that will tell you what to work on but by looking at\", metadata={'source': 'BdZ6bjcixhk', 'title': '#15 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 7]', 'description': 'Unknown', 'view_count': 4273, 'thumbnail_url': 'https://i.ytimg.com/vi/BdZ6bjcixhk/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGEggTShlMA8=&rs=AOn4CLCtsUYStl02gGIVla8ukpDT_uDw4Q', 'publish_date': '2022-04-20 00:00:00', 'length': 351, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"if your hands are supposed to be holding the steering wheel there is no mathematical formula that will tell you what to work on but by looking at these factors i hope you'll be able to make more fruitful decisions once you've decided that you want to work on one category of data say data with car noise once you've decided that there's a category or maybe a few categories where you want to improve the album's performance one fruitful approach is to consider adding data or improving the quality of that data for that one or maybe a small handful of categories so for example if you want to improve performance on speech with car noise you might go out and collect more data with car noise or if you have a way of using data augmentation to get more data from that category that would be another way to improve your album's performance one topic that we'll discuss next week is how to improve label accuracy or data quality you learn more about this when we talk about the data phase of the machine learning project life cycle in machine learning we always would like to have more data but going out to collect more data generically can be very time consuming and expensive by carrying out an analysis like this when you are then going through this iterative process of improving your learning algorithm you can be much more focused in exactly what types of data you collect because if you decide to collect more data with car noise or maybe people noise you can be much more specific in going out\", metadata={'source': 'BdZ6bjcixhk', 'title': '#15 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 7]', 'description': 'Unknown', 'view_count': 4273, 'thumbnail_url': 'https://i.ytimg.com/vi/BdZ6bjcixhk/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGEggTShlMA8=&rs=AOn4CLCtsUYStl02gGIVla8ukpDT_uDw4Q', 'publish_date': '2022-04-20 00:00:00', 'length': 351, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"types of data you collect because if you decide to collect more data with car noise or maybe people noise you can be much more specific in going out to collect more of just that data or using data augmentation without wasting time trying to collect more data from a low bandwidth cell phone connection and this focus on improving your data on the tags that you have determined are most fruitful for you to work on that can help you be much more efficient in how you improve your learning algorithms performance i found this type of error analysis procedure very useful for many of my projects and i hope it will help you too in building production ready machine learning systems next one of the most common challenges we run into is skewed data sets let's go on to the next video to go through some techniques for managing skewed data sets\", metadata={'source': 'BdZ6bjcixhk', 'title': '#15 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 7]', 'description': 'Unknown', 'view_count': 4273, 'thumbnail_url': 'https://i.ytimg.com/vi/BdZ6bjcixhk/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGEggTShlMA8=&rs=AOn4CLCtsUYStl02gGIVla8ukpDT_uDw4Q', 'publish_date': '2022-04-20 00:00:00', 'length': 351, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"data sets where the ratio of positive to negative examples is very far from 50 50 are called skewed data sets let's look at some special techniques for handling them let me start with a manufacturing example if a manufacturing company makes smartphones hopefully the vast majority of them are not defective so if 99.7 have no defect and are labeled y equals zero and only a small fraction is labeled y equals one then print zero which is not a very impressive learning algorithm will achieve 99.7 accuracy or medical diagnosis which was the example we went through in an earlier video if 99 of patients don't have a disease then an algorithm that predicts no one ever has a disease will have 99 accuracy or speech recognition if you're building a system for wake word detection sometimes also called trigger word detection these are systems that listen and see if you say a special word like alexa or ok google or hey siri most of the time that special wake word or trigger word is not being spoken by anyone at that moment in time so when i had built wake word detection systems the data sets were actually quite skewed one of the datasets i use had 96.7 negative examples and 3.3 positive examples when you have a very skewed data set like this raw accuracy is not that useful a metric to look at because prints zero can get very high accuracy instead it's more useful to build something called the confusion matrix a confusion matrix is a matrix where one axis is labeled with the actual label so\", metadata={'source': 'BlxnbyvHTyI', 'title': '#16 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 8]', 'description': 'Unknown', 'view_count': 4307, 'thumbnail_url': 'https://i.ytimg.com/vi/BlxnbyvHTyI/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVihAMA8=&rs=AOn4CLAOF5kbg43FfuI_80CzXRwg6F45EQ', 'publish_date': '2022-04-20 00:00:00', 'length': 734, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"it's more useful to build something called the confusion matrix a confusion matrix is a matrix where one axis is labeled with the actual label so it's the ground truth label y equals zero or y equals one and whose other axis is labeled with the prediction so was your learning algorithms prediction y equals zero or y equals one so if you're building a confusion matrix you throw in with each of these four cells the total number of examples say the number of examples in your dev set in your development set that fell into each of these four buckets let's say that 905 examples in your development set had a ground truth label of y equals zero and your algorithm got it right then you might write 905 there these examples are called true negatives because they were actually negative and your algorithm predicted it was negative next let's throw in the true positives which are the examples where the actual ground truth label is one and the prediction is one maybe there are 68 of them true positives the false negatives are the examples where your algorithm thought it was negative but it was wrong the actual label is positive so these are false negatives some of the 18 of that and lastly false positives are the ones where your algorithm thought it was positive but that turned out to be false so 9 false positives the precision of the learning algorithm if i sum up over the columns 905 plus 9 is 940 and 18 68 is 86. so this is indeed a pretty skewed data set where out of a thousand\", metadata={'source': 'BlxnbyvHTyI', 'title': '#16 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 8]', 'description': 'Unknown', 'view_count': 4307, 'thumbnail_url': 'https://i.ytimg.com/vi/BlxnbyvHTyI/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVihAMA8=&rs=AOn4CLAOF5kbg43FfuI_80CzXRwg6F45EQ', 'publish_date': '2022-04-20 00:00:00', 'length': 734, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"learning algorithm if i sum up over the columns 905 plus 9 is 940 and 18 68 is 86. so this is indeed a pretty skewed data set where out of a thousand examples there were 914 negative examples in just 86 positive examples so 8.6 positive 91.4 percent negative the precision of your learning algorithm is defined as follows it asks of all the examples that the average thought were positive examples what fraction did it get right so precision as is defined as true positives divided by true positives plus false positives in other words it looks at this row so of all the examples that your algorithm thought had a label of 1 which is 68 plus 9 of them 68 of them were actually right so the position is 68 over 68 plus 9 which is a 88.3 in contrast the recall asks of all the examples that were actually positive what fraction did your algorithm get right so recall is defined as true positives divided by true positives plus false negatives which in this case is 68 over 68 plus 18 which is 79.1 and the metrics of precision and recall are more useful than raw accuracy when it comes to evaluating the performance of learning algorithms on very skewed data sets let's see what happens if your learning algorithm outputs zero all the time it turns out it won't do very well on recall taking this example of where we had 914 negative examples and 86 positive examples if the algorithm outputs 0 all the time this is what the confusion matrix would look like 914 times it outputs zero with a ground\", metadata={'source': 'BlxnbyvHTyI', 'title': '#16 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 8]', 'description': 'Unknown', 'view_count': 4307, 'thumbnail_url': 'https://i.ytimg.com/vi/BlxnbyvHTyI/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVihAMA8=&rs=AOn4CLAOF5kbg43FfuI_80CzXRwg6F45EQ', 'publish_date': '2022-04-20 00:00:00', 'length': 734, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"positive examples if the algorithm outputs 0 all the time this is what the confusion matrix would look like 914 times it outputs zero with a ground truth of zero and 86 times it output zero with a ground truth of one so precision is true positives divided by true positives plus false positives which in this case turns out to be zero over zero plus zero which is not defined and unless your algebra actually output no positive labels at all you get some of the number that hopefully isn't zero over zero but more importantly if you look at recall which is true positives over true positives plus false negatives this turns out to be zero over zero plus 86 which is zero percent and so the print zero algorithm achieves zero percent recall which gives you an easy way to flag that this is not detecting any useful positive examples and the learning algorithm with some precision evens the high value precision is not that useful usually if this recall is so low so the standard metrics when i look at when comparing different models on skewed data sets are precision and recall where looking at these numbers helps you figure out and of all the examples that are truly positive examples what fraction did the algorithm manage to catch sometimes you have one model with a better recall and a different model with a better precision so how do you compare two different models there's a common way of combining precision and recall using this formula which is called the f1 score one intuition behind\", metadata={'source': 'BlxnbyvHTyI', 'title': '#16 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 8]', 'description': 'Unknown', 'view_count': 4307, 'thumbnail_url': 'https://i.ytimg.com/vi/BlxnbyvHTyI/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVihAMA8=&rs=AOn4CLAOF5kbg43FfuI_80CzXRwg6F45EQ', 'publish_date': '2022-04-20 00:00:00', 'length': 734, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"two different models there's a common way of combining precision and recall using this formula which is called the f1 score one intuition behind the f1 score is that you want an algorithm to do well on both precision and recall and if it does worse on either precision or recall that's pretty bad and so f1 is a way of combining precision and recall that emphasizes whichever of p or r positional recall is worse in mathematics this is technically called a harmonic mean between precision and recall which is like taking an average but placing more emphasis on whichever is the lower number so if you compute the f1 score of these two models it turns out it to be 83.4 using the formula below here and model 2 has a very bad recall so its f1 score is actually quite low as well and this lets us tell maybe more clearly that model 1 appears to be a superior model than model 2. for your application you may have a different weighting between precision and recall and so f1 isn't the only way to combine precision and recall it's just one metric that's commonly used for many applications let me step through one more example where precision and recall is useful so far we've talked about the binary classification problem with skewed datasets it turns out to also frequently be useful for multi-class classification problems if you're detecting defects in smartphones you may want to detect scratches on them or dents or pit marks this is what it looks like if someone took a screwdriver and poked a\", metadata={'source': 'BlxnbyvHTyI', 'title': '#16 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 8]', 'description': 'Unknown', 'view_count': 4307, 'thumbnail_url': 'https://i.ytimg.com/vi/BlxnbyvHTyI/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVihAMA8=&rs=AOn4CLAOF5kbg43FfuI_80CzXRwg6F45EQ', 'publish_date': '2022-04-20 00:00:00', 'length': 734, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"in smartphones you may want to detect scratches on them or dents or pit marks this is what it looks like if someone took a screwdriver and poked a cell phone or discoloration of the cell phone's lcd screen or other material maybe all four of these defects are actually quite rare but you might want to develop an algorithm that can detect all four of them one way to evaluate how your album is doing on all four of these defects each of which can be quite rare would be to look at precision and recall of each of these four types of defects individually in this example the learning algorithm has 82.1 precision on finding scratches and 99.2 recall you find in manufacturing that many factories will want high recall because you really don't want to let the phone go out that is defective but if an algorithm has slightly lower precision that's okay because through a human re-examining the phone they will hopefully figure out that the phone is actually okay so many factories will emphasize high recall and by combining precision recall using f1 as follows this gives you a single number evaluation metric for how well your lram is doing on the four different types of defects and can also help you benchmark to human level performance and also prioritize what to work on next so instead of accuracy on scratches dense pit marks and discolorations using f1 score can help you to prioritize the most fruitful type of defect to try to work on and the reason we use f1 is because maybe all four\", metadata={'source': 'BlxnbyvHTyI', 'title': '#16 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 8]', 'description': 'Unknown', 'view_count': 4307, 'thumbnail_url': 'https://i.ytimg.com/vi/BlxnbyvHTyI/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVihAMA8=&rs=AOn4CLAOF5kbg43FfuI_80CzXRwg6F45EQ', 'publish_date': '2022-04-20 00:00:00', 'length': 734, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"using f1 score can help you to prioritize the most fruitful type of defect to try to work on and the reason we use f1 is because maybe all four defects are very rare and so accuracy would be very high even if the algorithm was missing a lot of these defects so i hope that these tools will help you both evaluate your algorithm as well as prioritize what to work on both in problems with skewed data sets and for problems with multiple rare classes now to wrap up this section on error analysis there's one final concept i hope to go over with you which is performance auditing i found for many projects this is a key step to make sure that your learning algorithm is working well enough before you push it out to a production deployment let's take a look at performance auditing\", metadata={'source': 'BlxnbyvHTyI', 'title': '#16 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 8]', 'description': 'Unknown', 'view_count': 4307, 'thumbnail_url': 'https://i.ytimg.com/vi/BlxnbyvHTyI/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVihAMA8=&rs=AOn4CLAOF5kbg43FfuI_80CzXRwg6F45EQ', 'publish_date': '2022-04-20 00:00:00', 'length': 734, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"even when your learning algorithm is doing well on accuracy or f1 score or some appropriate metric is often worth one last performance audit before you push it to production and this can sometimes save you from significant post-deployment problems let's take a look you've seen this diagram before after you've gone around this loop multiple times to develop a good learning algorithm it's worthwhile auditing his performance one last time here's a framework for how you can double check your system for accuracy for fairness buyers and for other possible problems step one is brainstorm the different ways the system might go wrong for example does the algorithm perform sufficiently well on different subsets of the data such as individuals of a certain ethnicity or individuals of different genders or does the algorithm make certain errors such as false positives or false negatives which you might worry about in skewed datasets or how does it perform on certain rare and important classes so the types of issues we talked about in the key challenges video earlier this week any of them that concern you you might include them in this list of brainstormed ways that the system might go wrong for all the ways that you're worried about the system going wrong you might then establish metrics to assess the performance of your algorithm against these issues one very common design pattern you see is that you often be evaluating performance on slices of the data so rather than evaluating\", metadata={'source': 'o4je1lSpyaw', 'title': '#17 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 9]', 'description': 'Unknown', 'view_count': 3959, 'thumbnail_url': 'https://i.ytimg.com/vi/o4je1lSpyaw/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgXihEMA8=&rs=AOn4CLAocqZNIlObtACmW4kAhL-qSMhP-A', 'publish_date': '2022-04-20 00:00:00', 'length': 477, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"these issues one very common design pattern you see is that you often be evaluating performance on slices of the data so rather than evaluating performance on your entire def set you may be taking out all of the individuals of a certain ethnicity or all the individuals of a certain gender or all of the examples where there is a scratch defect on the smartphone but to take a subset of the data also call the slice of the data to analyze performance on those slices in order to check against these things that may be problems after establishing appropriate metrics ml ops tools can also help trigger an automatic evaluation for each model to order this performance for instance tensorflow has a package for tensorflow model analysis or tfma that computes detailed metrics on new machine learning models on different slices of data you learn more about this tool in the next course and as part of this process i would also advise you to get buy-in from the business or the product owner that these are the most appropriate set of problems to worry about and a reasonable set of metrics to assess against these possible problems and if you do find a problem then it is great that you discover this problem before pushing your system to production and you can then go back to update the system to address it before deploying a system that may cause problems downstream let's walk through this framework with an example i'm going to use speech recognition again if you built a speech recognition system\", metadata={'source': 'o4je1lSpyaw', 'title': '#17 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 9]', 'description': 'Unknown', 'view_count': 3959, 'thumbnail_url': 'https://i.ytimg.com/vi/o4je1lSpyaw/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgXihEMA8=&rs=AOn4CLAocqZNIlObtACmW4kAhL-qSMhP-A', 'publish_date': '2022-04-20 00:00:00', 'length': 477, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"downstream let's walk through this framework with an example i'm going to use speech recognition again if you built a speech recognition system you might then brainstorm the ways the system might go wrong so one thing i've looked at before for systems i worked on was accuracy on different genders and different ethnicities for example a speech system that does poorly on certain genders may be problematic or also ethnicities one type of analysis i've done before is to carry out analysis of our accuracy depending on the perceived accent of the speaker because we want to understand if the speech system's performance was a huge function of the accent of the speaker or you might worry about the accuracy on different devices because different devices may have different microphones and so if you do much worse on one brand of cell phone so that if there is a problem you can proactively fix it or finally this might not be an example you would have thought of but prevalence of root mis transcriptions here's one example of something that actually happens to some of deep learning.ai's causes one of our instructors lawrence moroney was talking about gans generative adversarial networks but because the transcription system was mistranscribing gans because this unfortunately is not a common word in english language and so the subtitles had a lot of references to gun and gang which were mistranscriptions of what the instructor actually said which is gang so it made it look like there's a lot\", metadata={'source': 'o4je1lSpyaw', 'title': '#17 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 9]', 'description': 'Unknown', 'view_count': 3959, 'thumbnail_url': 'https://i.ytimg.com/vi/o4je1lSpyaw/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgXihEMA8=&rs=AOn4CLAocqZNIlObtACmW4kAhL-qSMhP-A', 'publish_date': '2022-04-20 00:00:00', 'length': 477, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"of references to gun and gang which were mistranscriptions of what the instructor actually said which is gang so it made it look like there's a lot of gun violence in that deep learning.ai course and we actually had to go in to fix it because we didn't want that much gun gang violence in the subtitles it turns out more generally that mistranscribing someone's speech into a rude word or a swear word that's perceived much more negatively than a more neutral mistranscription and so i build speech systems as well where we pay special attention to avoiding mistranscriptions that resulted in the speech system thinking someone said a swear word when maybe they didn't actually say that swear word based on this list of brainstorm ways that a speech system might go wrong you can then establish metrics to assess performance against these issues on the appropriate slices of data for example you can measure the mean accuracy of the speech system for different genders and for different accents represented in the data set and also check for accuracy on different devices and check for offensive or root words in the output i find that the ways a system might go wrong turns out to be very problem dependent different industries different tasks will have very different standards and in fact today all standards in ai for what to consider an unacceptable level of bias or what is fair and what is not fair those standards are still continuing to evolve in ai and in many specific industries so i\", metadata={'source': 'o4je1lSpyaw', 'title': '#17 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 9]', 'description': 'Unknown', 'view_count': 3959, 'thumbnail_url': 'https://i.ytimg.com/vi/o4je1lSpyaw/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgXihEMA8=&rs=AOn4CLAocqZNIlObtACmW4kAhL-qSMhP-A', 'publish_date': '2022-04-20 00:00:00', 'length': 477, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"level of bias or what is fair and what is not fair those standards are still continuing to evolve in ai and in many specific industries so i would advise you to do a search for your industry to see what is acceptable and to keep current with standards of fairness and all of our growing awareness for how to make our systems more fair and less biased one last tip i find that rather than just one person trying to brainstorm what could go wrong for high stakes applications if you can have a team or sometimes even external advisors help you brainstorm things that you want to watch out for that can reduce the risk of you or your team being caught later by something that you hadn't thought of i know that even standards are still evolving from what we consider fair and sufficiently unbiased in many industries but this is one of the topics i think it'd be good for us to get ahead of and to proactively try to identify measure against and solve problems rather than deploy a system to be surprised much later by some unexpected consequences so that's it for performance auditing with this i hope you have higher confidence in your learning algorithm when you go out to push it to production\", metadata={'source': 'o4je1lSpyaw', 'title': '#17 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 9]', 'description': 'Unknown', 'view_count': 3959, 'thumbnail_url': 'https://i.ytimg.com/vi/o4je1lSpyaw/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgXihEMA8=&rs=AOn4CLAocqZNIlObtACmW4kAhL-qSMhP-A', 'publish_date': '2022-04-20 00:00:00', 'length': 477, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"let's say that error analysis has caused you to decide to focus on improving your learning algorithm's performance on data with a certain category attack say speech with car noise in the background let's take a look at how you can take a data centric approach to improving your learning algorithm's performance you've heard me speak before about model centric versus data centric ai development here's a little more detail on what i mean with a model centric view of ai development you would take the data you have and then try to work really hard to develop a model that does as well as possible on the data because a lot of academic research in ai was driven by researchers downloading a benchmark data set and trying to do well on that benchmark most academic research on ai is model centric because the benchmark data set is a fixed quantity so in this view model centric development you would hold the data fix and iteratively improve so in this model centric view you would hold the data fix and iteratively improve the code or the model there's still an important role to play in trying to come up with better models but there's a different view of ai developments which i think is more useful for many applications which is to shift a bit from a model sentry toward a data centric view in this view we think of the quality of the data as paramount and you can use tools such as error analysis or data augmentation to systematically improve the data quality and for many applications i find\", metadata={'source': 'k3UYUmp3Bi4', 'title': '#18 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 10]', 'description': 'Unknown', 'view_count': 3373, 'thumbnail_url': 'https://i.ytimg.com/vi/k3UYUmp3Bi4/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgXihDMA8=&rs=AOn4CLBv5UiQsUTXGCyOgMBq0bVutYddyA', 'publish_date': '2022-04-20 00:00:00', 'length': 160, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"and you can use tools such as error analysis or data augmentation to systematically improve the data quality and for many applications i find that if your data is good enough there are multiple models that will do just fine so in this view you can instead hold the code fix and iteratively improve the data there's a role for model centric development and there's a role for data centric development if you've been used to model-centric thinking for most of your experience with machine learning i would urge you to consider taking a data centric view as well where when you're trying to improve your learning album's performance try asking how can you make your data set even better one of the most important ways to improve the quality of a data set is data augmentation so let's go on to the next video where we'll start to take a look at data augmentation\", metadata={'source': 'k3UYUmp3Bi4', 'title': '#18 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 10]', 'description': 'Unknown', 'view_count': 3373, 'thumbnail_url': 'https://i.ytimg.com/vi/k3UYUmp3Bi4/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgXihDMA8=&rs=AOn4CLBv5UiQsUTXGCyOgMBq0bVutYddyA', 'publish_date': '2022-04-20 00:00:00', 'length': 160, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"there's a picture a conceptual picture that i found useful for thinking about data augmentation and how this can help the performance of a learning algorithm let me share this picture of you since i think you find it useful too when trying to decide whether to use data augmentation take speech recognition there could be many different types of noise in speech input such as call noise play noise train noise machine noise or cafe noise or library noise which isn't that loud or food court noise maybe these types of noises are more similar to each other because they're all mechanical types of noise and these types of noise may be a little bit more similar to each other with mainly people talking and interacting with each other so let me share with you a picture that i keep in mind when i'm planning out my activities on getting more data through data augmentation or through actual data collection of any of these types of data in this diagram the vertical axis represents performance say accuracy and on the horizontal axis and this is a conceptual kind of a thought experiment type of axis i'm going to represent the space of possible inputs so for example there's speech with call noise and play noise and train noise sound a bit like colonoids so they're quite similar and machine noise is a little bit further away by machine noise i'm picturing the sounds of a washing machine or a very loud air conditioner say then you may have speech with cafe noise library noise or food court noise\", metadata={'source': 'uot5sbPz1NQ', 'title': '#19 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 11]', 'description': 'Unknown', 'view_count': 3416, 'thumbnail_url': 'https://i.ytimg.com/vi/uot5sbPz1NQ/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgXihDMA8=&rs=AOn4CLD1UWOjk9WFYj658He3kH_JFY8zxA', 'publish_date': '2022-04-20 00:00:00', 'length': 359, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"the sounds of a washing machine or a very loud air conditioner say then you may have speech with cafe noise library noise or food court noise and those are maybe more similar to each other than to these types of mechanical noise your system will have different levels of performance on these different types of inputs let's say the performance is this for data play noise that with car noise train noise machine noise and it does worse on data with library noise cafe noise food court noise and so i think of there as being a curve or maybe think of this like a one-dimensional piece of rubber band or like a rubber sheet that shows how accurate your speech system is as a function of the type of input it gets a human will have some other level of performance on these different types of data so maybe a human is a bit better with play noise bit better on car noise and so on and maybe they are much better than your algorithm on library noise caffeine noise and food chord noise so the human level performance is represented via some other curve and let me just label this as the current model's performance in blue so this gap represents an opportunity for improvement now what happens if you use data augmentation or maybe not data augmentation but go out to a bunch of actual cafes to collect a lot more data with caffeine noise in the background what you would do is you would take this point imagine grabbing a hold of this blue rubber band or this rubber sheet and pulling it upwards like so\", metadata={'source': 'uot5sbPz1NQ', 'title': '#19 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 11]', 'description': 'Unknown', 'view_count': 3416, 'thumbnail_url': 'https://i.ytimg.com/vi/uot5sbPz1NQ/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgXihDMA8=&rs=AOn4CLD1UWOjk9WFYj658He3kH_JFY8zxA', 'publish_date': '2022-04-20 00:00:00', 'length': 359, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"what you would do is you would take this point imagine grabbing a hold of this blue rubber band or this rubber sheet and pulling it upwards like so that's what you're doing if you collect or somehow get more data with caffeine noise and add that to your training set you're pulling up the performance of the algorithm on inputs with caffeine noise and what that will tend to do is pull up this rubber sheet in the adjacent region as well so if performance on cafe noise goes up probably performance on the nearby points will go up too and performance on far away points may or may not go up as much it turns out that for unstructured data problems pulling up one piece of this rubber sheet is unlikely to cause a different piece of the rubber sheet to dip down really far below instead pulling up one point causes nearby points to be pulled up quite a lot and far away points may be pulled up a little bit or if you're lucky maybe more than a little bit but when i'm planning how to improve my learning album's performance and where i hope to get it to and getting more data in those places to interestingly pull up with those pieces or those parts of the rubber sheet to get them closer to human level performance and when you pull up part of the rubber sheet the location of the biggest gap may shift to somewhere else and error analysis will tell you what is the location of this new biggest gap that may then be worth your effort to collect more data on and therefore to try to pull up one piece\", metadata={'source': 'uot5sbPz1NQ', 'title': '#19 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 11]', 'description': 'Unknown', 'view_count': 3416, 'thumbnail_url': 'https://i.ytimg.com/vi/uot5sbPz1NQ/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgXihDMA8=&rs=AOn4CLD1UWOjk9WFYj658He3kH_JFY8zxA', 'publish_date': '2022-04-20 00:00:00', 'length': 359, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"you what is the location of this new biggest gap that may then be worth your effort to collect more data on and therefore to try to pull up one piece at a time and this turns out to be a pretty efficient way to decide where on the blue rubber sheet to pull up next to try to get performance closer to say human level performance i hold this analogy of a rubber band or a rubber sheet and repeatedly pulling up a point on this driver sheet will help you predict the effects of collecting more data that's associated with a specific category or a specific tag how do you get more of this data let's take a look at how you can perform data augmentation and some best practices doing so in the next video\", metadata={'source': 'uot5sbPz1NQ', 'title': '#19 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 11]', 'description': 'Unknown', 'view_count': 3416, 'thumbnail_url': 'https://i.ytimg.com/vi/uot5sbPz1NQ/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgXihDMA8=&rs=AOn4CLD1UWOjk9WFYj658He3kH_JFY8zxA', 'publish_date': '2022-04-20 00:00:00', 'length': 359, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"data augmentation can be a very efficient way to get more data especially for unstructured data problems such as images audio maybe text but when carrying out data augmentation there are a lot of choices you have to make what are the parameters how do you design the data augmentation setup let's dive into this to look at some best practices take speech recognition given an audio clip like this ai is the new electricity if you take background cafe noise it sounds like this [Music] and add these two audio clips together literally take the two waveforms and sum them up then you can create a synthetic example that sounds like this ai is the new electricity so it sounds like someone's saying ai is a new electricity in a noisy cafe this is one form of data augmentation that lets you efficiently create a lot of data that sounds like data collected in the cafe or if you take the same audio ai as the new electricity and add it to background music then it sounds like someone's saying it with maybe the radio on in the background ai is the new electricity now when carrying out data augmentation there are few decisions you need to make what types of background noise should you use and how loud should the background noise be relative to the speech let's take a look at some ways of making these decisions systematically the goal of data augmentation is to create examples that your learning algorithm can learn from as a framework for doing that i encourage you to think of how you can create\", metadata={'source': 'foCIxwn7VpI', 'title': '#20 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 12]', 'description': 'Unknown', 'view_count': 3530, 'thumbnail_url': 'https://i.ytimg.com/vi/foCIxwn7VpI/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgXChDMA8=&rs=AOn4CLArFSNWIje9nsGXKbxTQq8k7G1rlw', 'publish_date': '2022-04-20 00:00:00', 'length': 527, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"is to create examples that your learning algorithm can learn from as a framework for doing that i encourage you to think of how you can create realistic examples that the algorithm does poorly on because if the algorithm already does well on those examples then there's less for it to learn from but you want the examples to still be ones that a human or maybe some of the baseline can do well on because otherwise one way to generate examples that the algorithm does poorly on would be to just create examples that are so noisy that no one can hear what anyone said but that's not helpful you want examples that are hard enough to challenge the algorithm but not so hard that they're impossible for any human or any algorithm to ever do well on and that's why when i am generating new examples using data augmentation i try to generate examples that meets both of these criteria now one way that some people do data augmentation is to generate an augmented data set and then train the learning algorithm and see if the algorithm does better on the data set and then fiddle around with the parameters for data augmentation and train the learning algorithm again and so on this turns out to be quite inefficient because every time you change your data augmentation parameters you need to train your neural network or train your learning algorithm all over and this can take a long time instead i found that using these principles allows you to sanity check that your new data generated using data\", metadata={'source': 'foCIxwn7VpI', 'title': '#20 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 12]', 'description': 'Unknown', 'view_count': 3530, 'thumbnail_url': 'https://i.ytimg.com/vi/foCIxwn7VpI/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgXChDMA8=&rs=AOn4CLArFSNWIje9nsGXKbxTQq8k7G1rlw', 'publish_date': '2022-04-20 00:00:00', 'length': 527, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"all over and this can take a long time instead i found that using these principles allows you to sanity check that your new data generated using data augmentation is useful without actually having to spend maybe hours or sometimes days of training a learning algorithm on that data to verify that it will result in the performance improvement so specifically here's a checklist you might go through when you are generating new data one does it sound realistic you want your audio to actually sound like realistic audio of the sort that you want your algorithm to perform on two is the x to y mapping clear in other words can humans still recognize what was said this is to verify point two here and three is the algorithm currently doing poorly on this new data and that helps you verify points one if you can generate data that means all of these criteria then that will give you a higher chance that when you put this data into your training set and retrain the algorithm that that will result in you successfully pulling up part of this rubber sheet let's look at one more example using images this time let's say that you have a very small set of images of smartphones with scratches here's how you may be able to use data augmentation you can take the image and flip it horizontally this results in a pretty realistic image the phone buttons are now on the other side but this could be a useful example to add to your training set or you could implement contrast changes uh i've actually\", metadata={'source': 'foCIxwn7VpI', 'title': '#20 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 12]', 'description': 'Unknown', 'view_count': 3530, 'thumbnail_url': 'https://i.ytimg.com/vi/foCIxwn7VpI/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgXChDMA8=&rs=AOn4CLArFSNWIje9nsGXKbxTQq8k7G1rlw', 'publish_date': '2022-04-20 00:00:00', 'length': 527, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"are now on the other side but this could be a useful example to add to your training set or you could implement contrast changes uh i've actually brightened up the image here so the scratch is a little bit more visible or you could try darkening the image but in this example the image is now so dark that even i as a person can't really tell if there's a scratch there or not and so whereas these two examples on top would pass the checklist we had earlier that the human can still detect the scratch well this example is too dark it would fail that checklist and so i would try to choose a data augmentation scheme that generates more examples that look like the ones on top and few of the ones that look like the ones here at the bottom and in fact going off the principle that we want images that look realistic that humans can do well on and hopefully the album does poorly on you can also use more subscripted techniques such as take a picture of the phone with no scratches and use photoshop in order to artificially draw a scratch and this technique literally using photoshop can also be an effective way to generate more examples because this example with a scratch here you may or may not be able to see it depending on the video compression and image contrast where you're watching this video but with a scratch here this looks like a pretty realistic scratch this is actually generated a photoshop and i as a person can recognize the scratch and so if the learning algorithm isn't\", metadata={'source': 'foCIxwn7VpI', 'title': '#20 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 12]', 'description': 'Unknown', 'view_count': 3530, 'thumbnail_url': 'https://i.ytimg.com/vi/foCIxwn7VpI/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgXChDMA8=&rs=AOn4CLArFSNWIje9nsGXKbxTQq8k7G1rlw', 'publish_date': '2022-04-20 00:00:00', 'length': 527, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"a pretty realistic scratch this is actually generated a photoshop and i as a person can recognize the scratch and so if the learning algorithm isn't detecting this right now this would be a great example to add i've also used more advanced techniques like gans generative adversarial networks to synthesize scratches like these automatically although i've found that techniques like that can also be overkill meaning that the simpler techniques are much faster to implement that work just fine without the complexity of building again to synthesize scratches you may have heard of the term model iteration which refers to iteratively training a model using our analysis and then trying to decide how to improve the model taking a data centric approach to ai development sometimes it's useful to instead use a data iteration loop where you repeatedly take the data and the model train your learning algorithm do error analysis and as you go through this loop focus on how to add data or improve the quality of the data and for many practical applications taking this data iteration loop approach with a robust hyper parameter search that's important too but taking a data iteration loop approach results in faster improvement to your learning album's performance depending on your problem so when you're working on an unstructured data problem data augmentation if you can create new data that seems realistic that humans can do quite well on but the album struggles on that can be an efficient way\", metadata={'source': 'foCIxwn7VpI', 'title': '#20 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 12]', 'description': 'Unknown', 'view_count': 3530, 'thumbnail_url': 'https://i.ytimg.com/vi/foCIxwn7VpI/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgXChDMA8=&rs=AOn4CLArFSNWIje9nsGXKbxTQq8k7G1rlw', 'publish_date': '2022-04-20 00:00:00', 'length': 527, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"augmentation if you can create new data that seems realistic that humans can do quite well on but the album struggles on that can be an efficient way to improve your learning algorithm's performance and so if you found through error analysis that your learning algorithm does poorly on speech with cafe noise data augmentation to generate more data with caffeine noise could be an efficient way to improve your learning album's performance now when you add data to your system question i've often often been asked is can adding data hurt your learning album's performance usually for unstructured data performance the answer is no with some caveats but let's dive more deeply into this in the next video\", metadata={'source': 'foCIxwn7VpI', 'title': '#20 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 12]', 'description': 'Unknown', 'view_count': 3530, 'thumbnail_url': 'https://i.ytimg.com/vi/foCIxwn7VpI/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgXChDMA8=&rs=AOn4CLArFSNWIje9nsGXKbxTQq8k7G1rlw', 'publish_date': '2022-04-20 00:00:00', 'length': 527, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"for a lot of machine learning problems the training sets and depth and test set distribution start up being reasonably similar but if you're using data augmentation you're adding to specific parts of the training set such as adding lots of data with cafe noise so now your training set may come from a very different distribution than the deaf set and the test set is this going to hurt your learning algorithms performance usually the answer is no with some caveats when you're working on unstructured data problems but let's take a deeper look at what that really means if you are working on an unstructured data problem and if your model is large such as a neural network that is quite large and has large capacity and thus low bias and if the mapping from x to y is clear and by that i mean given only the input x humans can make accurate predictions then it turns out adding accurately labeled data rarely hurts accuracy this is an important observation because adding data through data augmentation or collecting more of one type of data can really change your input data distribution the probability of x let's say at the start of your problem 20 of your data had cafe noise but using augmentation you added a lot of caffeine noise so now this is 50 of your data is dated with caffeine noise in the background it turns out that so long as your model is sufficiently large then it won't stop it from doing a good job on the caffe noise data as well as doing a good job on non-caffe noise data\", metadata={'source': 'O9ZrPXPLmWg', 'title': '#21 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 13]', 'description': 'Unknown', 'view_count': 3570, 'thumbnail_url': 'https://i.ytimg.com/vi/O9ZrPXPLmWg/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgXChCMA8=&rs=AOn4CLBZUshmQ7mkZ3Mi3HDezBDFkRSxLQ', 'publish_date': '2022-04-20 00:00:00', 'length': 376, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"model is sufficiently large then it won't stop it from doing a good job on the caffe noise data as well as doing a good job on non-caffe noise data in contrast if your model was small then changing your input data distribution this way may cause it to spend too much of its resources modeling caffeine noise settings and this could hurt his performance on non-caffeine noise data but if your model is large enough then this isn't really an issue the second problem that could arise is if the mapping from x to y is not clear meaning given x the true label of y is very ambiguous this doesn't really happen much in speech recognition but let me illustrate this with an example from computer vision this is very rare so it's not something i would worry about for most practical problems but let's see why this is important one of the systems i had worked on many years ago google street view images to read host numbers in order to more accurately geolocate buildings and hoses in google maps so one of the things that system did was take as input pictures like this and figure out what is this digit so clearly this is a one and this is a alphabet i you don't see a lot of eyes in street view images but there are some buildings you know you may see a sign that says navigate to house number 42 i but house numbers really rarely have an alphabet i in it now if you find that your algorithm has very high accuracy on recognizing once but low accuracy on recognizing eyes one thing you might do is add\", metadata={'source': 'O9ZrPXPLmWg', 'title': '#21 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 13]', 'description': 'Unknown', 'view_count': 3570, 'thumbnail_url': 'https://i.ytimg.com/vi/O9ZrPXPLmWg/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgXChCMA8=&rs=AOn4CLBZUshmQ7mkZ3Mi3HDezBDFkRSxLQ', 'publish_date': '2022-04-20 00:00:00', 'length': 376, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"it now if you find that your algorithm has very high accuracy on recognizing once but low accuracy on recognizing eyes one thing you might do is add a lot more examples of eyes into your training set and the problem and this is a rare problem is there are some images that are truly ambiguous is this a one or is this an eye and if you were to add a lot of new eyes to your training set especially ambiguous examples like this then that may skew the data set to have a lot more eyes and hurt performance because we know that there are a lot more ones than eyes on house numbers if the learning algorithm sees a picture like this it would be safer to guess that this is a one rather than that this is an i but if data augmentation skews the data set in the direction of having a lot more eyes rather than a lot of ones then it may cause the algorithm to guess poorly on an ambiguous example like this so this is one rare example where adding more data could hurt performance and this example of one versus i is one that contradicts the second bullet because for some images the mapping from x to y is not clear in particular given only an image like this on the right even a human can't really tell what this is just to be clear the example that we just went through together is a pretty rare almost corner case and it's quite unusual for data augmentation or adding more data to hurt the performance of your learning algorithm so long as your model is big enough maybe your neural network is big\", metadata={'source': 'O9ZrPXPLmWg', 'title': '#21 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 13]', 'description': 'Unknown', 'view_count': 3570, 'thumbnail_url': 'https://i.ytimg.com/vi/O9ZrPXPLmWg/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgXChCMA8=&rs=AOn4CLBZUshmQ7mkZ3Mi3HDezBDFkRSxLQ', 'publish_date': '2022-04-20 00:00:00', 'length': 376, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"or adding more data to hurt the performance of your learning algorithm so long as your model is big enough maybe your neural network is big enough to learn from a diverse set of data sources but i hope that understanding this rare case where it could hypothetically hurt gives you more comfort with using data augmentation or collecting more data to improve the performance of your algorithm even if it causes your training set distribution to become different from your def set and test set distribution so far our discussion has focused on unstructured data problems how about structured data problems it turns out there's a different set of techniques that's useful for structured data let's take a look at that in the next video\", metadata={'source': 'O9ZrPXPLmWg', 'title': '#21 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 13]', 'description': 'Unknown', 'view_count': 3570, 'thumbnail_url': 'https://i.ytimg.com/vi/O9ZrPXPLmWg/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgXChCMA8=&rs=AOn4CLBZUshmQ7mkZ3Mi3HDezBDFkRSxLQ', 'publish_date': '2022-04-20 00:00:00', 'length': 376, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"for many structured data problems it turns out that creating brand new training examples is difficult but there's something else you could do which is to take existing training examples and figure out if there are additional useful features you can add to it let's take a look at an example let me use an example of restaurant recommendations where if you're running an app that has to recommend restaurants to users that may be interested in checking out certain restaurants one way to do this would be to have a set of features for each user or for each person and a set of features for each restaurant that then get fed in to some learning algorithm say a neural network and then your network whose job it is to predict whether or not this is a good recommendation whether to recommend this restaurant to that person in this particular example which is a real example error analysis showed that the system was unfortunately frequently recommending to vegetarians restaurants that only had meat options there were users that were pretty clearly vegetarian based on what they had ordered before and the system was still sending to them maybe a hot new restaurant that they recommended because it's a hot new restaurant but it didn't have good vegetarian options so this wasn't a good experience for anyone and there was a strong desire to change this now i didn't know how to synthesize new examples of uses or new examples of restaurants because this application had a fixed pool of uses and there\", metadata={'source': 'DTd7TyY7a-0', 'title': '#22 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 14]', 'description': 'Unknown', 'view_count': 3318, 'thumbnail_url': 'https://i.ytimg.com/vi/DTd7TyY7a-0/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgVyg9MA8=&rs=AOn4CLDZS1Q29bPl7h9Wo00G07c0HXazHA', 'publish_date': '2022-04-20 00:00:00', 'length': 524, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"now i didn't know how to synthesize new examples of uses or new examples of restaurants because this application had a fixed pool of uses and there were only so many restaurants so rather than trying to use data augmentation to create brand new people or restaurants to feed the training set i thought it was more fruitful to see if there were features to add to either the person inputs or to the restaurant inputs specifically one feature you can consider adding is a feature that indicates whether this person appears to be vegetarian and this doesn't need to be a binary value feature zero one it could be soft features such as the percentage of food ordered that was vegetarian or some other measure of how likely they seem to be vegetarian and a feature to add on the restaurant side would be does this restaurant have vegetarian options or good vegetarian options based on the menu for structured data problems usually you have a fixed set of users or a fixed set of restaurants or fixed set of products making it hard to use data augmentation or collect new data from new users that you don't have yet on restaurants that may or may not exist instead adding features can be a more fruitful way to improve the performance of the algorithm to fix problems like this one identified through error analysis additional features like these can be hand coded or they could in turn be generated by some learning algorithm such as having a learning algorithm try to read the menu and classify meals as\", metadata={'source': 'DTd7TyY7a-0', 'title': '#22 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 14]', 'description': 'Unknown', 'view_count': 3318, 'thumbnail_url': 'https://i.ytimg.com/vi/DTd7TyY7a-0/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgVyg9MA8=&rs=AOn4CLDZS1Q29bPl7h9Wo00G07c0HXazHA', 'publish_date': '2022-04-20 00:00:00', 'length': 524, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"coded or they could in turn be generated by some learning algorithm such as having a learning algorithm try to read the menu and classify meals as vegetarian or not or having people code this manually could also work depending on your application some other food delivery examples we found that there were some users that would only ever order a tea and coffee and some users they would only ever order a pizza so if the product team wants to improve the experience of these users a machine learning team might ask what are the additional features we can add to detect who are the people that only order tea or coffee or who are the people that only ever order pizza and enrich the user features so as to help the learning algorithm make better recommendations for restaurants that these users may be interested in over the last several years there's been a trend in product recommendations of a shift from collaborative filtering approaches to what content-based filtering approaches collaborative filtering approaches is loosely an approach that looks at the user tries to figure out who's similar to that user and then recommends things to you that people like you also liked in contrast a content based filtering approach will tend to look at you as a person and look at the description of the restaurant or look at the menu of the restaurants and look at other information about the restaurant to see if that restaurant is a good match for you or not the advantage of content based filtering is\", metadata={'source': 'DTd7TyY7a-0', 'title': '#22 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 14]', 'description': 'Unknown', 'view_count': 3318, 'thumbnail_url': 'https://i.ytimg.com/vi/DTd7TyY7a-0/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgVyg9MA8=&rs=AOn4CLDZS1Q29bPl7h9Wo00G07c0HXazHA', 'publish_date': '2022-04-20 00:00:00', 'length': 524, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"look at other information about the restaurant to see if that restaurant is a good match for you or not the advantage of content based filtering is that even if there's a new restaurant or a new product that hardly anyone else has liked by actually looking at the description of the restaurant rather than just looking at who else likes the restaurants you can more quickly make good recommendations this is sometimes also called the code start problem of how do you recommend a brand new product that almost no one else has purchased or liked or disliked so far and one of the ways to do that is to make sure that you capture good features for the things that you might want to recommend unlike collaborative filtering which requires a bunch of people to look at the product and decide if they like it or not before it can decide whether a new user should be recommended the same product so data iteration for structured data problems may look like this you saw that with some model train the model and then carry out error analysis error analysis can be harder on structured data problems if there is no good baseline such as human level performance to compare to and human level performance is hard for structured data because it's really difficult for people to recommend good restaurants even to each other but i found that error analysis can discover ideas for improvement so can user feedback and so can benchmarking to competitors but through these methods if you can identify a academy or a\", metadata={'source': 'DTd7TyY7a-0', 'title': '#22 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 14]', 'description': 'Unknown', 'view_count': 3318, 'thumbnail_url': 'https://i.ytimg.com/vi/DTd7TyY7a-0/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgVyg9MA8=&rs=AOn4CLDZS1Q29bPl7h9Wo00G07c0HXazHA', 'publish_date': '2022-04-20 00:00:00', 'length': 524, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"ideas for improvement so can user feedback and so can benchmarking to competitors but through these methods if you can identify a academy or a certain type of tag associated with your data that you want to drive improvement then you may be able to go back to select some features to add such as features to figure out who's vegetarian and what restaurants have good vegetarian options that would help you to improve your model and because the specific application may have only a finite list of uses and restaurants the users and restaurants you have maybe all the data you have which is why adding features to the examples you have may be a more fruitful approach compared to trying to come up with new users or new restaurants and of course i think features are a form of data too which is why this form of data iteration where error analysis helps you decide how to modify the features that can be an efficient way as well of improving your learning algorithm's performance i know that many years ago before the rise of deep learning part of the hope for deep learning was that you don't have to hand design features anymore i think that has for the most part come true for unstructured data problems so i use the hand design features for images i just don't do that anymore let the learning album figure it out but even with the rise of modern deep learning if your data set size isn't massive there is still designing of features driven by error analysis that can be useful for many\", metadata={'source': 'DTd7TyY7a-0', 'title': '#22 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 14]', 'description': 'Unknown', 'view_count': 3318, 'thumbnail_url': 'https://i.ytimg.com/vi/DTd7TyY7a-0/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgVyg9MA8=&rs=AOn4CLDZS1Q29bPl7h9Wo00G07c0HXazHA', 'publish_date': '2022-04-20 00:00:00', 'length': 524, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"of modern deep learning if your data set size isn't massive there is still designing of features driven by error analysis that can be useful for many applications today the larger data set the more likely it is that a pure end-to-end deep learning algorithm can work but for anyone other than the largest tech companies and sometimes even them for some applications designing features especially for structured data problems can still be a very important driver of performance improvements maybe just don't do that for unstructured data nearly as much because learning algorithms are very good and learning features automatically for images audio and for attacks maybe but for structured data it's okay to go in and work on the features\", metadata={'source': 'DTd7TyY7a-0', 'title': '#22 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 14]', 'description': 'Unknown', 'view_count': 3318, 'thumbnail_url': 'https://i.ytimg.com/vi/DTd7TyY7a-0/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgVyg9MA8=&rs=AOn4CLDZS1Q29bPl7h9Wo00G07c0HXazHA', 'publish_date': '2022-04-20 00:00:00', 'length': 524, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"as you're working to iteratively improve your algorithm one thing that'll help you be a bit more efficient is to make sure that you have robust experiment tracking let's take a look at some best practices when you're running dozens or hundreds or maybe even more experiments it's easy to forget what experiments you have already run having a system for tracking your experiments can help you be more efficient in making the decisions on the data or the model or hyper parameters to systematically improve your algorithm's performance when you're tracking the experiments you've run meaning the models you've trained here are some things i would urge you to track one is to keep track of what album you're using and what version of code um keeping a record of this will make it much easier for you to go back and replicate an experiment you had run maybe two weeks ago and whose details you may not fully remember anymore second keep track of the data set you use third hyperparameters and fourth save the results somewhere this should include at least the high level metrics such as accuracy or f1 score or the relevant metrics but if possible it'd be useful to just save a copy of the trained model so how can you track these things here are some tracking tools you might consider a lot of individuals and sometimes even teams will start off with text files so when i'm running experiment by myself i might use a text file to just make a note with a few lines of text per experiment to note down\", metadata={'source': 'A2bnWAIpLIo', 'title': '#23 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 15]', 'description': 'Unknown', 'view_count': 2862, 'thumbnail_url': 'https://i.ytimg.com/vi/A2bnWAIpLIo/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGEYgTihyMA8=&rs=AOn4CLBU1B8wMlV4vitFPVpHPnfb914PLA', 'publish_date': '2022-04-20 00:00:00', 'length': 283, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"text files so when i'm running experiment by myself i might use a text file to just make a note with a few lines of text per experiment to note down what i was doing this does not scale well but it may be okay for small experiments a lot of teams then migrate from text files to spreadsheets especially shared spreadsheets if you're working on a team where different columns of a spreadsheet can keep track of the different things you want to track for the different experiments you're running and spreadsheets actually scale quite a bit further especially shared spreadsheets that multiple members of a team may be able to look at but beyond a certain point some teams will also consider migrating to a more formal experiment tracking system the space of experiment tracking systems is still evolving rapidly and so there's a growing set of tools out there but some examples include waste and biases comets ml flow sagemaker studio landing ai ram ceo also has his own experiment tracking to focusing on computer vision and manufacturing applications when i'm trying to use a tracking tool whether a text file or a spreadsheet or some larger system here are some of the things i look at first is does it give me all the information needed to replicate the results and when in terms of rep in terms of replicability one thing to watch out for is if your learning algorithm pulls data off the internet because data of the internet can change that can decrease replicability unless you're careful in\", metadata={'source': 'A2bnWAIpLIo', 'title': '#23 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 15]', 'description': 'Unknown', 'view_count': 2862, 'thumbnail_url': 'https://i.ytimg.com/vi/A2bnWAIpLIo/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGEYgTihyMA8=&rs=AOn4CLBU1B8wMlV4vitFPVpHPnfb914PLA', 'publish_date': '2022-04-20 00:00:00', 'length': 283, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"your learning algorithm pulls data off the internet because data of the internet can change that can decrease replicability unless you're careful in how your system is implemented second tools that help you quickly understand the experimental results of a specific training run ideally with useful summary metrics and maybe even a bit of a in-depth analysis can help you more quickly look at your most recent experiments or even look at older experiments and remember what had happened finally some other features to consider resource monitoring how much cpu or gpu memory resources did they use or tools to help you visualize the trained model or even tools to help you with a more in-depth error analysis i found all of these to sometimes be useful features of experiment tracking frameworks rather than worrying too much about exactly which experiment tracking framework to use though the number one thing i hope you take away from this video is do try to have some system even if it's just a text file or just a spreadsheet for keeping track of your experiments and include as much information as is convenient to include because later on if you're trying to look back remember how you had generated a certain model having that information would be really useful for helping you to replicate your own result\", metadata={'source': 'A2bnWAIpLIo', 'title': '#23 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 15]', 'description': 'Unknown', 'view_count': 2862, 'thumbnail_url': 'https://i.ytimg.com/vi/A2bnWAIpLIo/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGEYgTihyMA8=&rs=AOn4CLBU1B8wMlV4vitFPVpHPnfb914PLA', 'publish_date': '2022-04-20 00:00:00', 'length': 283, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"you've learned about taking a data-centric approach to ai development i'd like to leave you with a thought on shifting from big data to good data here's what i mean a lot of modern ai had grown up in large consumer internet companies with maybe a billion users and thus companies like that have a lot of data on their users if you have big data like that by all means it could help the performance if you have room tremendously but both for software consumer internet but equally importantly for many other industries there just isn't a billion data points and i think it may be even more important for those applications to focus not just on big data but on good data i found that if you're able to ensure consistently high quality data in all phases of the machine learning project life cycle that is key to making sure that you have a high performance and reliable machine learning deployment what do i mean by good data i think good data covers the important cases so you should have good coverage of different input x and if you find out that you don't have enough data with speech with caffeine noise data augmentation can help you get more data get more diverse inputs x to give you that coverage so we spent quite a bit of time talking about this in this week's material good data is also defined consistently with definition of labels why that's unambiguous we haven't talked about this yet but we'll go into much greater depth on this next week good data also has timely feedback from\", metadata={'source': 'qOEeK1SNF3k', 'title': '#24 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 16]', 'description': 'Unknown', 'view_count': 2736, 'thumbnail_url': 'https://i.ytimg.com/vi/qOEeK1SNF3k/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgWihJMA8=&rs=AOn4CLDssYizzJaag1cLBvt5RrhecBOlIg', 'publish_date': '2022-04-20 00:00:00', 'length': 211, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"that's unambiguous we haven't talked about this yet but we'll go into much greater depth on this next week good data also has timely feedback from production data we actually talked about this last week when we were covering the deployment section in terms of having monitoring systems to track concept drift and data drift and finally you do need a reasonable size data set so to summarize during the machine learning project life cycle we've talked about during the deployment phase last week how to make sure you have timely feedback this week as we talked about modeling we also included in our discussion how to make sure you have hopefully good coverage of important cases next week when we dive into data definition we'll spend much more time to talk about how to make sure your data is defined consistently and i hope that with the ideas conveyed last week this week and next week you'll be armed with the tools you need to give your learning algorithm good data through all phases of the machine learning project life cycle so that's it congratulations on getting to the end of this week's videos on modeling i look forward to diving more deeply with you into the data part of the full cycle of a machine learning project and next week we'll also have a short optional section on scoping machine learning projects i look forward to seeing you next week\", metadata={'source': 'qOEeK1SNF3k', 'title': '#24 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 16]', 'description': 'Unknown', 'view_count': 2736, 'thumbnail_url': 'https://i.ytimg.com/vi/qOEeK1SNF3k/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgWihJMA8=&rs=AOn4CLDssYizzJaag1cLBvt5RrhecBOlIg', 'publish_date': '2022-04-20 00:00:00', 'length': 211, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"you're now in the third and final week of this course just one more week and then you'll be done with this first course of the specialization in this week we'll dive into data how do you get data that sets up your training your modeling for success but first why is defining what data to use even hard let's look at an example i'm going to use the example of detecting iguanas one of my friends and cartoon fruit is really like iguanas so have a bunch of iguana pictures floating around let's say that you've gone into the forest and collected hundreds of pictures like these and you sent these pictures to labelers with the instructions please use bounding boxes to indicate the position of iguanas one labeler may label it like this and say one iguana to iguanis this label did a good job a second labor that is equally hardworking equally diligent may say look the iguana on the left has a tail that goes all the way to the right of this image so the second labor may say one iguana to iguanas good job labor hard to fault this labor either a third layer may say well i'm going to look through all hundreds of images and label them all and i'm going to use boundary boxes and so let me indicate the position you go honors and draw a bounding box like that three diligent hard-working laborers can come up with these three very different ways of labeling iguanas and maybe any of these is actually fine i would prefer the top two rather than third one but any of these labeling conventions could\", metadata={'source': '0aDhjrs8FMw', 'title': '#25 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 1]', 'description': 'Unknown', 'view_count': 2986, 'thumbnail_url': 'https://i.ytimg.com/vi/0aDhjrs8FMw/hqdefault.jpg?sqp=-oaymwExCJADEOABSFryq4qpAyMIARUAAIhCGAHwAQH4Af4JgALQBYoCDAgAEAEYQiBKKGUwDw==&rs=AOn4CLASlQF7TraSGGTeO8yqdr6b_plvVg', 'publish_date': '2022-04-20 00:00:00', 'length': 258, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"labeling iguanas and maybe any of these is actually fine i would prefer the top two rather than third one but any of these labeling conventions could result in your learning algorithm learning a pretty good iguana detector but what is not fine is if one-third of your label is used the first and one-third the second and one-third the third labeling convention because then your labels are inconsistent and this is confusing to the learning algorithm while the iguana example was a fun one you see this type of effect in many practical computer vision problems as well let's use the phone defect detection example if you ask the labor to use bounding boxes to indicate significant defects say maybe one labor will look at and go oh well clearly the scratch is the most significant defect let me draw a bounty bounce on that a second labeler may look at this phone and say there are actually two significant defects there's a big scratch and then there's that small mark there it's called a pit mark kind of like if someone poked the phone with a sharp screwdriver i think the second layer probably did a better job but then a third laborer may look at this and say well here's a bounding box that shows you where the defects are between these three labels probably the one in the middle would work the best but this is a very typical example of inconsistent labeling that you will get back from a labeling process with even slightly ambiguous labeling instructions and if you can consistently label\", metadata={'source': '0aDhjrs8FMw', 'title': '#25 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 1]', 'description': 'Unknown', 'view_count': 2986, 'thumbnail_url': 'https://i.ytimg.com/vi/0aDhjrs8FMw/hqdefault.jpg?sqp=-oaymwExCJADEOABSFryq4qpAyMIARUAAIhCGAHwAQH4Af4JgALQBYoCDAgAEAEYQiBKKGUwDw==&rs=AOn4CLASlQF7TraSGGTeO8yqdr6b_plvVg', 'publish_date': '2022-04-20 00:00:00', 'length': 258, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"labeling that you will get back from a labeling process with even slightly ambiguous labeling instructions and if you can consistently label the data with one convention maybe the one in middle your learning algorithm will do better what we will do in this week is dive into best practices for the data stage of the full cycle of a machine learning project specifically we'll talk about how to define what is the data what should be x and what should be y and establish a baseline and doing that well will set you up to label and organize the data well which will give you a good data set for when you move into the modeling phase which you already saw last week many machine learning researchers and many machine learning engineers had started off downloading data off the internet to experiment with models so using data prepared by someone else nothing at all wrong with that and for many practical applications the way you prepare your data sets will have a huge impact on the success of your machine learning project in the next video we'll take a look at some more examples of how data can be ambiguous so that this will set us up later this week for some techniques for improving the quality of your data let's go on to the next video\", metadata={'source': '0aDhjrs8FMw', 'title': '#25 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 1]', 'description': 'Unknown', 'view_count': 2986, 'thumbnail_url': 'https://i.ytimg.com/vi/0aDhjrs8FMw/hqdefault.jpg?sqp=-oaymwExCJADEOABSFryq4qpAyMIARUAAIhCGAHwAQH4Af4JgALQBYoCDAgAEAEYQiBKKGUwDw==&rs=AOn4CLASlQF7TraSGGTeO8yqdr6b_plvVg', 'publish_date': '2022-04-20 00:00:00', 'length': 258, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"in the last video you saw how the right bounding boxes for an image can be ambiguous let's take a look at some more label ambiguity examples we briefly touched on speech recognition in the first week of this course here's another example given this audio clip sounds like someone was standing on a busy roadside asking for the nearest gas station and then a car drove past so did they say something right after that i don't know so one way to transcribe this would be um nearest gas station and in some places people spell um with two m's so that would be a different way to spell it and we could have used dot dot dots or ellipses instead of the comma as well which would be another ambiguity or given the audio had noise after the last words um did they say something off the nearest gas station i'm not sure actually so would you transcribe it like this instead so there are combinatorially many ways to transcribe this um with one m or two m's commodore ellipses whether to write unintelligible at the end of this being able to standardize on one convention will help your speech recognition algorithm let's also look at an example of structured data a common application in many large companies is user id merge that's when you have multiple data records that you think correspond to the same person and you want to merge these user data records together for example say you run a website that offers online listings of jobs so this may be one data record that you have from one of your\", metadata={'source': 'mzv1mkJRA10', 'title': '#26 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3 Lesson 2]', 'description': 'Unknown', 'view_count': 2855, 'thumbnail_url': 'https://i.ytimg.com/vi/mzv1mkJRA10/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVyhCMA8=&rs=AOn4CLDZuAAc0G20CAmRfo6_AKoLxwZWCw', 'publish_date': '2022-04-20 00:00:00', 'length': 550, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"records together for example say you run a website that offers online listings of jobs so this may be one data record that you have from one of your registered users with the email first name last name and address now say your company acquires a second company that runs a mobile app that allows people to log in to chat and get advice from each other about their resumes it seems synergistic for your business if you run a listing of online jobs maybe you merge or acquire a second company that runs a mobile app that lets people chat about their resumes and from this mobile app you have a different database of users so given this data record and this one do you think these two are the same person one approach to the user id merge problem is to use a supervised learning algorithm that takes as input to user data records and tries to output either one or zero based on whether it thinks these two are actually the same physical human being if you have a way to get ground truth data records such as if a handful of users are willing to explicitly link the two accounts then that could be a good set of labeled examples to train an algorithm but if you don't have such a ground true set of data what many companies have done is ask human laborers sometimes a product management team to just manually look at some pairs of records that have been filtered to maybe similar names or similar zip codes and then to just use human judgment to determine if these two records appear to be the same\", metadata={'source': 'mzv1mkJRA10', 'title': '#26 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3 Lesson 2]', 'description': 'Unknown', 'view_count': 2855, 'thumbnail_url': 'https://i.ytimg.com/vi/mzv1mkJRA10/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVyhCMA8=&rs=AOn4CLDZuAAc0G20CAmRfo6_AKoLxwZWCw', 'publish_date': '2022-04-20 00:00:00', 'length': 550, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"been filtered to maybe similar names or similar zip codes and then to just use human judgment to determine if these two records appear to be the same person because whether these two records really is the same person is genuinely ambiguous they may and they may not be different people will label these records inconsistently and if there's a way to just get them to label the data a little more consistently you see some examples of how to do this later even when the ground truth is ambiguous then that can help the performance of your learning algorithm user id merging is a very common function in many companies let me just ask you to please do this only in ways that are respectful of the user's data and their privacy and only if you are using the data in a way consistent with what they have given you permission for you know user privacy is really important a few other examples from structured data if you are trying to use a learning algorithm to look at a user account like these and predict is it a bot or a spam account sometimes that can be ambiguous or if you look at a online purchase is this a fraudulent transaction so has someone stole an account and is using a stolen accounts to interact with your website or to make purchases sometimes that too is ambiguous or if you look at someone's interactions with your website and you want to know are they looking for a new job at this moment in time based on how someone behaves on a job board website or a resume chat app you can\", metadata={'source': 'mzv1mkJRA10', 'title': '#26 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3 Lesson 2]', 'description': 'Unknown', 'view_count': 2855, 'thumbnail_url': 'https://i.ytimg.com/vi/mzv1mkJRA10/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVyhCMA8=&rs=AOn4CLDZuAAc0G20CAmRfo6_AKoLxwZWCw', 'publish_date': '2022-04-20 00:00:00', 'length': 550, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"want to know are they looking for a new job at this moment in time based on how someone behaves on a job board website or a resume chat app you can sometimes guess if they're looking for a job but it's hard to be sure so that's also a little bit ambiguous in the face of potentially very important and valuable prediction tiles like these the ground truth can be ambiguous and so if you ask people to take their best guess at the ground truth label for tasks like these giving labeling instructions that results in more consistent and less noisy and less random labels will improve the performance of your learning algorithm so when defining the data for your learning algorithm here are some here are some important questions first what is the input x for example if you're trying to detect defects on smartphones for the pictures you're taking is the lighting good enough is the camera contrast good enough is the camera resolution good enough so if you find that you have a bunch of pictures like these which is so dark it's hard even for a person to see what's going on the right thing to do may not be to take this input x and just label it it may be to go to the factory and politely request improving the lighting because it is only with this better image quality that the labeler can then more easily see scratches like this and label them so sometimes if your sensor or your imaging solution or your audio recording solution is not good enough the best thing you could do is recognize that\", metadata={'source': 'mzv1mkJRA10', 'title': '#26 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3 Lesson 2]', 'description': 'Unknown', 'view_count': 2855, 'thumbnail_url': 'https://i.ytimg.com/vi/mzv1mkJRA10/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVyhCMA8=&rs=AOn4CLDZuAAc0G20CAmRfo6_AKoLxwZWCw', 'publish_date': '2022-04-20 00:00:00', 'length': 550, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"sometimes if your sensor or your imaging solution or your audio recording solution is not good enough the best thing you could do is recognize that if even a person can't look at the input and tell what's going on then improving the quality of your sensor or improving the quality of the input x that can be an important first step to ensuring your learning algorithm kind of reasonable performance and for structured data problems defining whether the features to include can have a huge impact on your learning algorithm's performance for example for user id merge if you have a way of getting the user's location even a rough gps location if you have permission from the user to use that can be a very useful cue for deciding whether two user accounts actually belong to the same person and of course please do this type of thing only if you have permission from the user to use their data this way in addition to defining the input x you also have to figure out what should be the target label y and as you've seen from the preceding examples one key question is how can we ensure labelers give consistent labels in the last video in this video you saw a variety of problems with the labels being ambiguous or in some cases the input x not being sufficiently informative such as if the image is too dark let's take these data issues and put them into a more systematic framework that will allow us to devise solutions in a more systematic way let's go on to the next video to take a look\", metadata={'source': 'mzv1mkJRA10', 'title': '#26 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3 Lesson 2]', 'description': 'Unknown', 'view_count': 2855, 'thumbnail_url': 'https://i.ytimg.com/vi/mzv1mkJRA10/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVyhCMA8=&rs=AOn4CLDZuAAc0G20CAmRfo6_AKoLxwZWCw', 'publish_date': '2022-04-20 00:00:00', 'length': 550, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"i'd like to share with you a useful framework for thinking about different major types of machine learning projects it turns out that the best practices for organizing data for one type can be quite different than the best practices for a totally different type let's take a look at one of these major types of machine learning projects let's fill in this two by two grid one axis will be whether your machine learning problem uses unstructured data or structured data i found that the best practices for these are very different mainly because humans are great at processing unstructured data like images and audio and text and not as good at processing structured data like database records the second axis is the size of your data set do you have a relatively small data set or do you have a very large data set there's no precise definition of what exactly is small and what is large but i'm going to use as a slightly arbitrary threshold whether you have over 10 000 examples or not and clearly this boundary is a little bit fuzzy and the transitions from small to big data sets is a gradual one but i found that best practices for if you have say a hundred or a thousand examples smaller data sets is pretty different than when you have a very large data set and the reason i chose the number 10 000 is that's roughly the size beyond which it becomes quite painful to examine every single example yourself you know if you have a thousand examples you could probably examine every example\", metadata={'source': 's5qFpEPNXEY', 'title': '#27 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 3]', 'description': 'Unknown', 'view_count': 2840, 'thumbnail_url': 'https://i.ytimg.com/vi/s5qFpEPNXEY/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgXShFMA8=&rs=AOn4CLCMBcA2NRYVltcTERe3pDn1bKPC-g', 'publish_date': '2022-04-20 00:00:00', 'length': 677, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"it becomes quite painful to examine every single example yourself you know if you have a thousand examples you could probably examine every example yourself but when you have a hundred thousand examples ten thousand hundred thousand million examples is very it becomes very time consuming for you as an individual or maybe a couple of machine learning engineers to manually look at every example so that affects the best practices as well let's look at some examples if you are training a manufacturing visual inspection from just 100 examples of scratch phones that's unstructured data because this is image data and it's a pretty small data set if you are trying to predict housing prices based on the size of the house and other features in the house from just 50 training examples then there's a structured data set with just real value features and a relatively small data set if you are carrying out speech recognition from 50 million training examples there's unstructured data but you have a lot of data or if you are trying to recommend products so online shopping recommendations and you have a million users in your database then there's a structured problem with relatively large amount of data for a lot of unstructured data problems people can help you to label data and data augmentation such as synthesizing new images or synthesizing the audio and there's some emerging techniques for synthesizing new text as well but data augmentation can help so for manufacturing visual\", metadata={'source': 's5qFpEPNXEY', 'title': '#27 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 3]', 'description': 'Unknown', 'view_count': 2840, 'thumbnail_url': 'https://i.ytimg.com/vi/s5qFpEPNXEY/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgXShFMA8=&rs=AOn4CLCMBcA2NRYVltcTERe3pDn1bKPC-g', 'publish_date': '2022-04-20 00:00:00', 'length': 677, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"the audio and there's some emerging techniques for synthesizing new text as well but data augmentation can help so for manufacturing visual inspection you can use data augmentation to maybe generate more pictures of smartphones or for speech recognition data augmentation can help you synthesize audio clips with different background noise in contrast for structured data problems it can be harder to obtain more data and also harder to use data augmentation if only 50 houses have been so recently in that geography well it's hard to synthesize new houses that don't exist or if you have a million users in your database well again it's hard to synthesize new users that don't really exist and it's also harder not impossible still worth trying but it may or may not be possible to get humans to label the data so i find that the best practices for unstructured versus structured data are quite different the second axis is the size your data set when you have a relatively small data set having clean labels is critical if you have a hundred training examples then if just one of the examples is mislabeled that's one percent of your data set and because the data set is small enough for you or a small team to go through it efficiently it may well be worth your while to go through that hundred examples and make sure that every one of those examples is labeled in a clean and consistent way meaning according to a consistent labeling standard in contrast if you have a million data points it can\", metadata={'source': 's5qFpEPNXEY', 'title': '#27 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 3]', 'description': 'Unknown', 'view_count': 2840, 'thumbnail_url': 'https://i.ytimg.com/vi/s5qFpEPNXEY/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgXShFMA8=&rs=AOn4CLCMBcA2NRYVltcTERe3pDn1bKPC-g', 'publish_date': '2022-04-20 00:00:00', 'length': 677, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"is labeled in a clean and consistent way meaning according to a consistent labeling standard in contrast if you have a million data points it can be harder maybe impossible for a small machine learning team to manually go through every example having clean labels is still very helpful don't get me wrong even when you have a lot of data clean labels is better than non-clean ones but because of the difficulty of having the machine learning engineering team go through every example the emphasis is on data processes in terms of how you collect and store the data the labeling instructions you may write for a large team of crowd source labelers and once you have executed some data process such as asked a large team of labelers to label a large set of audio clips it can also be much harder to go back and change your mind and get everything relabeled so let's summarize for unstructured data problems you may or may not have a huge collection of unlabeled examples x maybe in your factory you actually took many thousands of images of smartphones but you just haven't bothered to label all of them yet this is also common in the self-driving car industry where many self-driving car companies have collected tons of images of cars driving around but just have not yet gotten that data labeled for these unstructured data problems you can sometimes get more data by taking your unlabeled data x and asking humans to just label more of it this doesn't apply to every problem but for the problems\", metadata={'source': 's5qFpEPNXEY', 'title': '#27 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 3]', 'description': 'Unknown', 'view_count': 2840, 'thumbnail_url': 'https://i.ytimg.com/vi/s5qFpEPNXEY/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgXShFMA8=&rs=AOn4CLCMBcA2NRYVltcTERe3pDn1bKPC-g', 'publish_date': '2022-04-20 00:00:00', 'length': 677, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"get more data by taking your unlabeled data x and asking humans to just label more of it this doesn't apply to every problem but for the problems where you do have tons of unlabeled data this can be very helpful and as we've already mentioned data augmentation can also be helpful for structured data problems it's usually harder to obtain more data because you only have so many users or only so many houses or so that you can collect data from and human labeling on average is also harder although there are some exceptions such as in the last video where you saw that we could try to ask people to label examples for the user id merge problem but in many cases where we ask humans to label structured data even when it's a completely fine idea completely worthwhile to ask people to try to label if two records are the same person there's more likely to be a little bit more ambiguity where even human labor sometimes finds it hard to be sure what is the correct label lastly let's look at small versus big data where i use the slightly arbitrary threshold of whether you have more or less than say 10 000 labor training examples for small data sets clean labels are critical and the data set may be small enough for you to manually look through the entire data set and fix any inconsistent labels further the labeling team is probably not that large it may be one or two or just a handful of people that created all the labels so if you discover an inconsistency in the labels say one person\", metadata={'source': 's5qFpEPNXEY', 'title': '#27 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 3]', 'description': 'Unknown', 'view_count': 2840, 'thumbnail_url': 'https://i.ytimg.com/vi/s5qFpEPNXEY/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgXShFMA8=&rs=AOn4CLCMBcA2NRYVltcTERe3pDn1bKPC-g', 'publish_date': '2022-04-20 00:00:00', 'length': 677, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"large it may be one or two or just a handful of people that created all the labels so if you discover an inconsistency in the labels say one person label iguana is one way and a different person labeled iguanas a different way you can just get the two or three labels together and have them talk to each other and hash out and agree on one labeling convention for the very large data sets the emphasis has to be on data process and if you have 100 labelers or even more it's just harder to get 100 people into a room to all talk to each other and hashtag the process and so you might have to rely on a smaller team to establish a consistent label definition and then share that definition with all say 100 or more labelers and ask them to all implement the same process i want to leave you with one last thought which is that i found this categorization of problems into unstructured versus structures small versus big data i found this to be helpful for predicting not just whether data processes generalized from one to another problem but also whether other machine learning ideas generalize from one to another so one tip if you are working on a problem from one of these four quadrants then on average advice from someone that has worked on problems in the same quadrants will probably be more useful than advice from someone that's worked in a different quadrant i found also in hiring machine learning engineers someone that's worked in the same quadrant as the problem i'm trying to solve\", metadata={'source': 's5qFpEPNXEY', 'title': '#27 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 3]', 'description': 'Unknown', 'view_count': 2840, 'thumbnail_url': 'https://i.ytimg.com/vi/s5qFpEPNXEY/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgXShFMA8=&rs=AOn4CLCMBcA2NRYVltcTERe3pDn1bKPC-g', 'publish_date': '2022-04-20 00:00:00', 'length': 677, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"a different quadrant i found also in hiring machine learning engineers someone that's worked in the same quadrant as the problem i'm trying to solve will usually be able to adapt more quickly to working on other problems in that quadrant because the instincts and decisions are more similar within one quadrant than if you shift to a totally different quadrant in this chart i've sometimes heard people give advice like oh if you're building a computer vision system always get at least a thousand labeled examples and i think people that give advice like that are well meaning and i appreciate that they're trying to give good advice but i found that advice to not really be useful um for all problems machine learning is very diverse and it's hard to find one-size-fits-all advice like that i've seen computer vision problems built with 100 examples or 100 examples per class a speed system is built with 100 million examples and so if you are looking for advice uh on the machine learning project try to find someone that's worked in the same quadrant as the problem you're trying to solve now we talked about one formulation of different types of machine learning problems there's one aspect i would like to dive into with you in the next video which is how for small data problems having clean data is especially important let's take a look at the next video of why this is true\", metadata={'source': 's5qFpEPNXEY', 'title': '#27 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 3]', 'description': 'Unknown', 'view_count': 2840, 'thumbnail_url': 'https://i.ytimg.com/vi/s5qFpEPNXEY/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgXShFMA8=&rs=AOn4CLCMBcA2NRYVltcTERe3pDn1bKPC-g', 'publish_date': '2022-04-20 00:00:00', 'length': 677, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"in problems of a small data set having clean and consistent labels is especially important let's start with an example one of the things i used to do is use machine learning to fly helicopters one things you might want to do is take as input the voltage applied to the motor or to the helicopter rotor and predict what is the speed of the rotor you can have this type of problem not just flying helicopters but for other control problems when you're controlling the speed of a motor so let's say you have a data set that looks like this where you have five examples so a pretty small data set because this data set that is the output y is pretty noisy it's difficult to know what is the function you should use to map voltage to the rotor speed in rpm maybe it should be a straight line something like that or maybe something like that or maybe it should go up and then be flat like that or maybe it should be a curve like that really hard to tell when you have a small data set five examples and noisy labels is difficult to fit a function confidently now if you have a ton of data this data set is equally noisy as the one on the left but you just have a lot more data then the learning algorithm can average over the noisy data sets and you can now fit a function you know pretty confidently looks like curve should be something like that a lot of ai had recently grown up in large consumer internet companies which may have 100 million users or a billion users and does very large data sets and\", metadata={'source': 'f5sN3xAEAWQ', 'title': '#28 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 4]', 'description': 'Unknown', 'view_count': 2711, 'thumbnail_url': 'https://i.ytimg.com/vi/f5sN3xAEAWQ/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGEggTihlMA8=&rs=AOn4CLBldAVh9-dimD71XdZncgqrZ4Lojw', 'publish_date': '2022-04-20 00:00:00', 'length': 497, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"ai had recently grown up in large consumer internet companies which may have 100 million users or a billion users and does very large data sets and so i think some of the practices for how to deal with small data sets have not been emphasized as much as would be needed to tackle problems where you don't have a hundred million examples but only a thousand or even fewer so to me the interesting case is one of you still have a small data set five examples same as the example on the left but you now have clean and consistent labels in this case you can pretty confidently fit a function through your data and with only five examples you can build a pretty good model for predicting for predicting speed as a function of the input voltage i've trained computer vision systems with just 30 images and had it worked just fine and the key is usually to make sure that the labels are clean and consistent let's take a look at another example of phone defect inspection the task is to take as input pictures like these and to decide whether there is a defect or not on the phone now if labeling instructions are initially unclear then labelers will label images inconsistently it may be that when there's a giant scratch you know sufficiently large one that everyone will agree as a defect and if there's a tiny little thing that inspectors will ignore it but there's this region of ambiguity where different inspectors will label different scratches with a length between point two and point four in\", metadata={'source': 'f5sN3xAEAWQ', 'title': '#28 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 4]', 'description': 'Unknown', 'view_count': 2711, 'thumbnail_url': 'https://i.ytimg.com/vi/f5sN3xAEAWQ/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGEggTihlMA8=&rs=AOn4CLBldAVh9-dimD71XdZncgqrZ4Lojw', 'publish_date': '2022-04-20 00:00:00', 'length': 497, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"it but there's this region of ambiguity where different inspectors will label different scratches with a length between point two and point four in slightly inconsistent ways so one solution to this would be to say why don't we try to get a lot more pictures of phones and scratches and then see what the inspectors do and then maybe eventually we can train a neural network they can figure out from the image what is and what is in the scratch on average maybe that approach could work but it'd be a lot of work and require collecting a lot of images i found that it can be more fruitful to ask the inspectors to sit down and just try to reach agreement on what is the size of scratch that would cause them to label a stretch with a bounding box versus the side is too small and not worth bothering labeling so in this example if the labelers can agree that the point of transition from where little ding becomes a defect is a length of 0.3 then the way they label the images becomes much more consistent and it becomes much easier for learning algorithm to take as input images like this and consistently decide whether something is a scratch or a defect just to be clear in this example the input to the learning algorithm is images like that on the left not the stretch length like that on the right but the point is if you can get inspectors to agree what is a scratch and what is in the scratch and to define the toss as putting bounding boxes around defects they're over 0.3 millimeters in\", metadata={'source': 'f5sN3xAEAWQ', 'title': '#28 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 4]', 'description': 'Unknown', 'view_count': 2711, 'thumbnail_url': 'https://i.ytimg.com/vi/f5sN3xAEAWQ/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGEggTihlMA8=&rs=AOn4CLBldAVh9-dimD71XdZncgqrZ4Lojw', 'publish_date': '2022-04-20 00:00:00', 'length': 497, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"to agree what is a scratch and what is in the scratch and to define the toss as putting bounding boxes around defects they're over 0.3 millimeters in length then that will cause your images to be labeled more consistently and allow your learning algorithm to achieve higher accuracy even when your data set isn't that big so you've seen a couple examples now of how label consistency helps a learning algorithm i want to wrap up this video with one more thought which is that big data problems can have small data challenges too specifically problems with a large data set but where there's a long tail of rare events in the input will have small data challenges too for example the launch web search engine companies all have very large data sets of web search queries but many web queries are actually very rare and so the amount of click stream data for the rare queries is actually small take self-driving cars self-driving car companies tend to have very large data sets collected from driving hundreds of thousands or millions of hours or more but there are rare occurrences that are critical to get right to make sure a self-driving car is safe such as that very rare occurrence of a young child running across the highway or that very rare occurrence of a truck popped across a highway so even if a self-driving car has a very large data set the number of examples it may have of these rare events is actually very small and so ensuring label consistency in terms of how these rare events\", metadata={'source': 'f5sN3xAEAWQ', 'title': '#28 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 4]', 'description': 'Unknown', 'view_count': 2711, 'thumbnail_url': 'https://i.ytimg.com/vi/f5sN3xAEAWQ/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGEggTihlMA8=&rs=AOn4CLBldAVh9-dimD71XdZncgqrZ4Lojw', 'publish_date': '2022-04-20 00:00:00', 'length': 497, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"the number of examples it may have of these rare events is actually very small and so ensuring label consistency in terms of how these rare events are detected and labeled is still very helpful for improving self-driving cars or product recommender systems if you have a catalog of hundreds of thousands or millions or more items or product recommendation systems if you have an online catalog of anywhere from thousands to hundreds of thousands to sometimes even millions of catalogs to sometimes even millions of items then you will have a lot of products where the number sold of that item is quite small and so the amount of data you have of users interacting with the items in the long tail is actually small and if there's a way which is not easy but there's a way to make sure that data is clean and consistent then that too will help your learning algorithm in terms of how i recommend so it doesn't recommend items in the long tail where the amount of data per item will tend to be low so when you have a small data set label consistency is critical even when you have a big data set label consistency can be very important it's just that i found it easier on average to get to label consistency on smaller datasets than on very large ones in the next video we'll look at some concrete ideas and best practices for improving your datasets label consistency let's go on to the next video\", metadata={'source': 'f5sN3xAEAWQ', 'title': '#28 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 4]', 'description': 'Unknown', 'view_count': 2711, 'thumbnail_url': 'https://i.ytimg.com/vi/f5sN3xAEAWQ/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGEggTihlMA8=&rs=AOn4CLBldAVh9-dimD71XdZncgqrZ4Lojw', 'publish_date': '2022-04-20 00:00:00', 'length': 497, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"let's take a look at some ways to improve the consistency of your labels here's a general process you can use if you are worried about labels being inconsistent find a few examples and have multiple labelers label the same example in some cases you can also have the same labeler label an example wait a while until they've hopefully forgotten or technical term is wash out but have them take a break and then come back and re-label it and see if they're even consistent with themselves when you find that these disagreements have the people responsible for labeling this could be the machine learning engineer it could be the subject matter expert such as the manufacturing expert that's responsible for labeling what is a scratch and what is in scratch and or the dedicated labelers discuss together what they think should be a more consistent definition of a label why and try to have them reach an agreement and ideally also document and write down that agreement and this definition of why can then become an updated set of labeling instructions that they can go back to label new data or to relabel old data during this discussion in some cases the labels will come back and say they don't think the input x has enough information if that's the case consider changing the input x so for example when we saw the pictures of phones they were so dark that we couldn't even tell what was going on that was a sign that we should consider increasing the illumination the lighting with which the\", metadata={'source': 'a-oCxdzFapE', 'title': '#29 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 5]', 'description': 'Unknown', 'view_count': 2464, 'thumbnail_url': 'https://i.ytimg.com/vi/a-oCxdzFapE/hqdefault.jpg?sqp=-oaymwExCJADEOABSFryq4qpAyMIARUAAIhCGAHwAQH4Af4JgALQBYoCDAgAEAEYRSBLKGUwDw==&rs=AOn4CLCEhc2Z01CiZrw15lDpnTCR1-D7ug', 'publish_date': '2022-04-20 00:00:00', 'length': 549, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"so dark that we couldn't even tell what was going on that was a sign that we should consider increasing the illumination the lighting with which the pictures were taken but of course i know this isn't always possible but sometimes this can be a big hole and then all this is an iterative process so after improving x or after improving the label instructions you would ask the team to label more data and if you think there are still disagreements then repeat the whole process of having multiple labelers label the same example measure disagreement and so on let's look at some examples one common outcome of this type of exercise is to standardize the definition of labels so between these ways of labeling the audio clip you heard on the earlier video perhaps the labels will standardize on this as the convention or maybe they'll pick a different one and that could be okay too but at least this makes the data more consistent another common decision that i've seen come out of a process like this is merging classes so if in your labeling guidelines you ask labelers to label deep scratches on the surface of the phone as well as shallow scratches on the surface of the phone but if the definition between what constitutes a deep scratch versus a shallow scratch barely visible here i know it's unclear then you end up with labels very inconsistently labeling things as deep versus shallow scratches sometimes the factory does really need to distinguish between deep versus shallow scratches\", metadata={'source': 'a-oCxdzFapE', 'title': '#29 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 5]', 'description': 'Unknown', 'view_count': 2464, 'thumbnail_url': 'https://i.ytimg.com/vi/a-oCxdzFapE/hqdefault.jpg?sqp=-oaymwExCJADEOABSFryq4qpAyMIARUAAIhCGAHwAQH4Af4JgALQBYoCDAgAEAEYRSBLKGUwDw==&rs=AOn4CLCEhc2Z01CiZrw15lDpnTCR1-D7ug', 'publish_date': '2022-04-20 00:00:00', 'length': 549, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"labeling things as deep versus shallow scratches sometimes the factory does really need to distinguish between deep versus shallow scratches sometimes factory need to do this to figure out what was the cause of the defect but sometimes i found that you don't really need to distinguish between these two classes and you can instead merge the two classes into a single clause say the scratch class and this gets rid of all of the inconsistencies with different labels labeling the same thing deep versus shallow so merging classes isn't always applicable but when it is it simplifies the task for the learning algorithm one other technique i've used is to create a new class or create a new label to capture uncertainty so for example let's say you ask labelers to label phones as defective or not based on the length of the scratch so here's a sequence of smartphones with larger and larger scratches so not sure if you can see these on your display but let me just make them a little bit more visible here and i know that all of these are really large scratches if this is a real phone you're buying so this is just for illustrative purposes and maybe everyone agrees that the giant scratches the defect tiny scratch is not a defect but they don't agree on what's in between if it was possible to get them to agree then that would be one way to reduce label ambiguity but if that turns out to be difficult then here's another option which is to create a new class where you now have three labels\", metadata={'source': 'a-oCxdzFapE', 'title': '#29 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 5]', 'description': 'Unknown', 'view_count': 2464, 'thumbnail_url': 'https://i.ytimg.com/vi/a-oCxdzFapE/hqdefault.jpg?sqp=-oaymwExCJADEOABSFryq4qpAyMIARUAAIhCGAHwAQH4Af4JgALQBYoCDAgAEAEYRSBLKGUwDw==&rs=AOn4CLCEhc2Z01CiZrw15lDpnTCR1-D7ug', 'publish_date': '2022-04-20 00:00:00', 'length': 549, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"label ambiguity but if that turns out to be difficult then here's another option which is to create a new class where you now have three labels you can say it's clearly not a defect or clearly a defect or just acknowledge that some examples are ambiguous and put them in a new borderline clause and if it becomes easier to come up with consistent instructions for this three-class problem because maybe some examples are genuinely borderline then that could potentially improve labeling consistency let me use speech illustration to illustrate this further given this audio clip nearest grocery i really can't tell what they said nearest grocery and if you were to force everyone to transcribe it some labelers will transcribe nearly go some will say maybe they'll say nearest grocery and it's very difficult to get to consistency because the audio clip is genuinely ambiguous to improve labeling consistency it may be better to create a new tag the unintelligible tag and just ask everyone to label this as nearest nearest unintelligible nearest grocery and this can result in more consistent labels than you were to ask everyone to guess what they heard when it really is unintelligible let me wrap up with some suggestions for working with small versus big data sets to improve label consistency and we've just been talking about unstructured data or problems where we can count on people to label the data for small data sets there's usually a small number of labelers and so when you find an\", metadata={'source': 'a-oCxdzFapE', 'title': '#29 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 5]', 'description': 'Unknown', 'view_count': 2464, 'thumbnail_url': 'https://i.ytimg.com/vi/a-oCxdzFapE/hqdefault.jpg?sqp=-oaymwExCJADEOABSFryq4qpAyMIARUAAIhCGAHwAQH4Af4JgALQBYoCDAgAEAEYRSBLKGUwDw==&rs=AOn4CLCEhc2Z01CiZrw15lDpnTCR1-D7ug', 'publish_date': '2022-04-20 00:00:00', 'length': 549, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"or problems where we can count on people to label the data for small data sets there's usually a small number of labelers and so when you find an inconsistency you can ask the labelers to sit down and discuss a specific image or specific audio clip and try to drive toward agreement for big data sets it will be more common to try to get to consistent definition with a small group and then send the labeling instructions to a larger group of labelers one other technique that is commonly used but i think overuse in my opinion is that you can have multiple labelers label every example and then let them vote and voting is sometimes called consensus labeling in order to increase accuracy i find that this type of voting mechanism technique it can work but it's probably overused in machine learning today where what i've seen a lot of teams do is have inconsistent labeling instructions and then try to have a lot of labels and then voting to try to make it more consistent but before resorting to this which i do use but more of a last resort i would usually first try to get to more consistent label definitions to try to make the individual labeler's choices less noisy in the first place rather than take a lot of noisy data and then try to use voting to reduce the noise i hope that the tools you just learned for improving label consistency will help you to get better data for your machine learning tools one of the gaps i see in the machine learning world today is that there's still a\", metadata={'source': 'a-oCxdzFapE', 'title': '#29 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 5]', 'description': 'Unknown', 'view_count': 2464, 'thumbnail_url': 'https://i.ytimg.com/vi/a-oCxdzFapE/hqdefault.jpg?sqp=-oaymwExCJADEOABSFryq4qpAyMIARUAAIhCGAHwAQH4Af4JgALQBYoCDAgAEAEYRSBLKGUwDw==&rs=AOn4CLCEhc2Z01CiZrw15lDpnTCR1-D7ug', 'publish_date': '2022-04-20 00:00:00', 'length': 549, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"will help you to get better data for your machine learning tools one of the gaps i see in the machine learning world today is that there's still a lack of tools and ml also machine learning ops tools for helping teams to carry out this type of process more consistently and repeatedly so it's not you know us trying to figure this out in a jupiter notebook but instead to have tools help us to detect when labels are consistent and to help facilitate the process in improving the quality of the data so this is something i look forward to hopefully our community working on and developing in terms of improving label quality one of the questions that often comes up is what is human level performance on a task i find human level performance be important and sometimes misused concept let's take a deeper look at this in the next video\", metadata={'source': 'a-oCxdzFapE', 'title': '#29 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 5]', 'description': 'Unknown', 'view_count': 2464, 'thumbnail_url': 'https://i.ytimg.com/vi/a-oCxdzFapE/hqdefault.jpg?sqp=-oaymwExCJADEOABSFryq4qpAyMIARUAAIhCGAHwAQH4Af4JgALQBYoCDAgAEAEYRSBLKGUwDw==&rs=AOn4CLCEhc2Z01CiZrw15lDpnTCR1-D7ug', 'publish_date': '2022-04-20 00:00:00', 'length': 549, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"some machine learning tasks are trying to predict an inherently ambiguous output and human level performance can establish a useful baseline of performance as a reference but human level performance is also sometimes misused let's take a look one of the most important uses of measuring human level performance or hrp is to estimate bayes error or irreducible error especially on unstructured data toss in order to help with error analysis and prioritization and just establish what might be possible take a visual inspection task this may have happened to you before but i have gotten requests from business owners saying hey andrew can you please build a system that's 99 accurate or maybe 99.9 accurate so one way to establish what might be possible would be to take a data set and look at the ground truth data say you have six examples where the ground truth label is these and then to ask a human inspector to label the same data blinded to the ground truth label of course and see what they come up with and if they come up with these you would say this inspector agreed to the ground truth on four other six examples and disagreed on two out of six and so human level performance is you know 66.7 and so this would let you go back to the business owner and say look even your inspector is only 66.7 accuracy how can you expect me to get 99 accuracy so hrp is useful for establishing a baseline in terms of what might be possible there's one question that is often not asked which is what\", metadata={'source': 'eW546hpa744', 'title': '#30 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 6]', 'description': 'Unknown', 'view_count': 2495, 'thumbnail_url': 'https://i.ytimg.com/vi/eW546hpa744/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVihAMA8=&rs=AOn4CLDVWH1jGxXYbt2YHJX0Ghu_0QVidw', 'publish_date': '2022-04-20 00:00:00', 'length': 628, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"accuracy so hrp is useful for establishing a baseline in terms of what might be possible there's one question that is often not asked which is what exactly is this ground truth label because rather than just measuring how well we can do compared to some ground truth label which was probably written by some other human are we really measuring what is possible or are we just measuring how well two different people happen to agree with each other when the ground truth label is itself determined by a person there's a very different approach to thinking about human level performance which i want to share with you in this and the next video beyond this purpose of estimating bayes error and establishing what's possible using that to help with error analysis and prioritization here are some other uses of human level performance in academia hlp is often used as a respectable benchmark and so when you establish that people are only 92 accurate or some of the number on a speech recognition data set and if you can beat human level performance then that establishes then that helps you to quote proof that your learning algorithm is doing something hard and helps get the paper published i'm not saying this is a great use of hlp but in academia showing you can beat hlp maybe for the first time has been a tried and true formula for establishing the academic significance of a piece of work and helps with getting something published we discussed briefly on the last slide what to do if a\", metadata={'source': 'eW546hpa744', 'title': '#30 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 6]', 'description': 'Unknown', 'view_count': 2495, 'thumbnail_url': 'https://i.ytimg.com/vi/eW546hpa744/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVihAMA8=&rs=AOn4CLDVWH1jGxXYbt2YHJX0Ghu_0QVidw', 'publish_date': '2022-04-20 00:00:00', 'length': 628, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"the academic significance of a piece of work and helps with getting something published we discussed briefly on the last slide what to do if a business or product owner asks for 99 accuracy and if you think that's unrealistic then measuring hlp may help you to establish a more reasonable target there's one other use of hlp that you might hear about that i'll be cautious about which is i've seen many projects with a machine learning team wants to use hlp or beating hlp to prove that the machine learning system is superior to the humans doing the job and as tempting as it is to go to someone and says look i've proved that my machine learning system is more accurate than humans inspecting the phones or the radiologists reading x-rays or something and now that i've mathematically proved the superiority of my learning outro you have to use it right i know the logic of that is tempting but as a practical matter this approach rarely works and you also saw last week that businesses need systems that do more than just doing well on average tested accuracy so if you ever find yourself in this situation i would urge you to just use this type of logic with caution or maybe even more preferably just don't use these arguments i've usually found other arguments than this to be more effective at working with a business to see if they should adopt a machine learning system the problem with beating human level performance as proof of machine learning superiority is multifold beyond the fact\", metadata={'source': 'eW546hpa744', 'title': '#30 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 6]', 'description': 'Unknown', 'view_count': 2495, 'thumbnail_url': 'https://i.ytimg.com/vi/eW546hpa744/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVihAMA8=&rs=AOn4CLDVWH1jGxXYbt2YHJX0Ghu_0QVidw', 'publish_date': '2022-04-20 00:00:00', 'length': 628, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"a machine learning system the problem with beating human level performance as proof of machine learning superiority is multifold beyond the fact that most applications require more than just high average tested accuracy one of the problems with this metric is that it sometimes gives a learning algorithm an unfair advantage when labeling instructions are inconsistent let me show you what i mean if you have inconsistent labeling instructions so that when an audio clip says nearest gas station let's say 70 percent of laborers use this labeling convention and 30 percent of labelers use this labeling convention neither one is a superior transcript to the other both seem completely fine but just by luck of the draw 70 percent of laborers choose the first one 30 choose the second one so if the ground truth is established by a labeler maybe just a label with a slightly bigger title but really by one labeler then the chance that two random labelers will agree will be 0.7 squared plus 0.3 squared which is 0.58 so we had two labels use the first convention there's a point seven square chars of that or if both of your random labels use the second convention there's a point three squared charge of that then the two of them will agree so the chance of two labels are green is 0.58 and in the usual way of measuring human level performance you will conclude that human level performance is 0.58 but what you're really measuring is the chance of two random labelers agreeing this is where a\", metadata={'source': 'eW546hpa744', 'title': '#30 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 6]', 'description': 'Unknown', 'view_count': 2495, 'thumbnail_url': 'https://i.ytimg.com/vi/eW546hpa744/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVihAMA8=&rs=AOn4CLDVWH1jGxXYbt2YHJX0Ghu_0QVidw', 'publish_date': '2022-04-20 00:00:00', 'length': 628, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"you will conclude that human level performance is 0.58 but what you're really measuring is the chance of two random labelers agreeing this is where a machine learning algorithm has an unfair advantage i think either of these labeling conventions is completely fine but the learning algorithm is a little bit better at gathering statistics of how often ellipses versus commas are used in such a context then the learning algorithm may be able to always use the first labeling convention because it knows that statistically it has a 70 chance of getting it right if it uses ellipses or dot dot so a learning algorithm will agree with humans 70 percent of the time just by choosing the first laden convention but this 12 improvement in performance whereas human level performance is 58 and your learning algorithm is 12 better is 0.70 this 12 better performance is not actually important for anything between these two equally good slightly arbitrary choices the learning algorithm just consistently picks the first one so it gains what seems like a 12 advantage on this type of on this type of query but it's not actually outperforming any human in any way that a user would care about and one side effect of this is that if your speech recognition task has multiple types of audio for some there's this dot dot or ellipses versus common ambiguity and the learning algorithm does 12 percent better on this if your learning algorithm makes some more significant errors on other types of input audio\", metadata={'source': 'eW546hpa744', 'title': '#30 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 6]', 'description': 'Unknown', 'view_count': 2495, 'thumbnail_url': 'https://i.ytimg.com/vi/eW546hpa744/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVihAMA8=&rs=AOn4CLDVWH1jGxXYbt2YHJX0Ghu_0QVidw', 'publish_date': '2022-04-20 00:00:00', 'length': 628, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"and the learning algorithm does 12 percent better on this if your learning algorithm makes some more significant errors on other types of input audio then when is performance where it actually does worse could be average out by queries like these where kind of fake looks like is doing better and this will therefore mask or hide the fact that your learning algorithm is actually creating worse transcripts than humans actually are and what this means is that a machine learning system can look like it's doing better than hlp but actually be producing worse transcripts than people because it's just doing better on this type of problem which is not important to do better on while potentially actually doing worse on some other types of input audio given these problems of human level performance what are we supposed to do measuring human level performance is useful for establishing a baseline using that to drive air analysis and prioritization but using it to benchmark machines and humans sometimes runs into problematic cases like this i found that when my goal is to build a useful application not publish a paper you publish a paper let's prove we can outperform people that helps publish paper but found that when my goal is to build a useful application rather than trying to beat human level performance i found it is often useful to instead try to raise human level performance because we raise human level performance by improving label consistency and that ultimately results in\", metadata={'source': 'eW546hpa744', 'title': '#30 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 6]', 'description': 'Unknown', 'view_count': 2495, 'thumbnail_url': 'https://i.ytimg.com/vi/eW546hpa744/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVihAMA8=&rs=AOn4CLDVWH1jGxXYbt2YHJX0Ghu_0QVidw', 'publish_date': '2022-04-20 00:00:00', 'length': 628, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"instead try to raise human level performance because we raise human level performance by improving label consistency and that ultimately results in better learning outcome performance as well let's take a deeper look at this in the next video\", metadata={'source': 'eW546hpa744', 'title': '#30 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 6]', 'description': 'Unknown', 'view_count': 2495, 'thumbnail_url': 'https://i.ytimg.com/vi/eW546hpa744/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVihAMA8=&rs=AOn4CLDVWH1jGxXYbt2YHJX0Ghu_0QVidw', 'publish_date': '2022-04-20 00:00:00', 'length': 628, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"i think the use of hlp and machine learning had taken off partly because it helped people get papers published to show they can beat hlp there's also been a bit misused in settings where the goal is to build a valuable application not just to publish a paper when the ground truth is externally defined then there are fewer problems with hlp when the ground tree really is some real ground truth for example i've done a lot of work on medical imaging uh working on you know ai for diagnosing from x-rays or things like these and given an x-ray image if you want to predict the diagnosis if the diagnosis is defined according to say a biopsy so a biological or medical test then hlp helps you measure how well does a doctor versus a learning algorithm predict the outcome of a biopsy or a biological medical test i find that to be really useful but when the ground truth is defined by a human maybe even a doctor labeling an x-ray image then hlp is just measuring how well can one doctor predict another doctor's label versus how well can one learning algorithm predict another doctor's label and that too is useful but it's different than if you're measuring how well you versus a doctor are predicting some ground truth outcome from a medical biopsy so to summarize when the ground truth label is externally defined such as the medical biopsy then hrp gives an estimate for base error and irreducible error in terms of predicting the outcome of that medical test the biopsy but there are also a lot\", metadata={'source': 'Ny970B12IQk', 'title': '#31 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 7]', 'description': 'Unknown', 'view_count': 2499, 'thumbnail_url': 'https://i.ytimg.com/vi/Ny970B12IQk/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGEMgRyhlMA8=&rs=AOn4CLDXyvd5QisZmcx-Yb0Y8eFiMJvC6A', 'publish_date': '2022-04-20 00:00:00', 'length': 542, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"gives an estimate for base error and irreducible error in terms of predicting the outcome of that medical test the biopsy but there are also a lot of problems where the ground truth is just another human label the visual inspection example we had from the previous video showed this where the inspector had 66.7 accuracy rather than just aspiring to beat the human inspector it may be more useful to see why the ground truth which is just some other inspector compared to this inspector don't agree for example if we look at the length of the different scratches that they label say on these six examples these were the lengths of the scratches and if we speak of the inspectors and have them agree that 0.3 mm is the threshold above which a stretch becomes a defect then what we would do is then what we realize is that for the first example both labeled it one totally appropriately for the second example the ground truth here is one but is less than 0.3 so we really should change this to 0 then 0.5 gets 1 1 0.200.1 and this example has a stretch of 0.1 but really this should have been a zero if we go through this exercise of getting the ground truth labor and this inspector to agree then we actually just raise human level performance from 66.7 percent to 100 at least as measured on these six examples so but notice what we've done by raising hlp to 100 we've made it pretty much impossible for a learning algorithm to beat hlp so that seems terrible you can't tell the business owner\", metadata={'source': 'Ny970B12IQk', 'title': '#31 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 7]', 'description': 'Unknown', 'view_count': 2499, 'thumbnail_url': 'https://i.ytimg.com/vi/Ny970B12IQk/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGEMgRyhlMA8=&rs=AOn4CLDXyvd5QisZmcx-Yb0Y8eFiMJvC6A', 'publish_date': '2022-04-20 00:00:00', 'length': 542, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"raising hlp to 100 we've made it pretty much impossible for a learning algorithm to beat hlp so that seems terrible you can't tell the business owner anymore you beat hlp and does they must use your system but the benefit of this is you now have much cleaner more consistent data and that ultimately will allow your learning algorithm to do better so when you go is to come up with a learning algorithm that actually generates accurate predictions rather than just prove for some reason that you can beat hlp i find this approach of working to raise hlp to be more useful to summarize when the ground truth label y comes from a human hlp being quite a bit less than 100 may just indicate that the labeling instructions or labeling convention is ambiguous on the last slide you saw an example of this in visual inspection you also see this in speech recognition where the um comma versus um ellipsis dot dot that type of ambiguous labeling convention will also cause hlp to be less than 100 improving labor consistency will raise human level performance and this makes it harder unfortunately for your learning algorithm to beat hlp but the more consistent labels will raise your machine learning algorithm performance which is ultimately likely to benefit the actual application so far we've been discussing hrp on unstructured data but some of these issues apply to structured data as well you already know that structured data problems are less likely to involve human labors and thus hlp is less\", metadata={'source': 'Ny970B12IQk', 'title': '#31 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 7]', 'description': 'Unknown', 'view_count': 2499, 'thumbnail_url': 'https://i.ytimg.com/vi/Ny970B12IQk/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGEMgRyhlMA8=&rs=AOn4CLDXyvd5QisZmcx-Yb0Y8eFiMJvC6A', 'publish_date': '2022-04-20 00:00:00', 'length': 542, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"issues apply to structured data as well you already know that structured data problems are less likely to involve human labors and thus hlp is less frequently used but there are exceptions you saw previously the user id merging example where you might have a human label where the two records belong to the same person or i've worked on projects where we will look at network traffic into a computer to try to figure out if the computer was hacked and we asked human i.t experts to provide labels for us sometimes it's hard to know if a transaction is fraudulent and you just ask a human to label that or is this account a spam account or a bot generated account or from gps what is the mode of transportation is this person on foot or on a bike or in the car or on the bus it turns out buses stop at bus stops and so you can actually kind of tell if someone's in the bus or in the car based on their gps trace and for problems like these it would be quite reasonable to ask a human to label the data at least on the first pass for a learning algorithm to make such predictions as these and so when the ground truth label you're trying to predict comes from one human the same questions of what does hlp mean it is a useful baseline to figure out what is possible but sometimes when measuring hlp you realize that low hlp stems from inconsistent labels and working to improve hlp by coming up with a more consistent labeling standard will both raise hlp and give you cleaner data with which to\", metadata={'source': 'Ny970B12IQk', 'title': '#31 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 7]', 'description': 'Unknown', 'view_count': 2499, 'thumbnail_url': 'https://i.ytimg.com/vi/Ny970B12IQk/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGEMgRyhlMA8=&rs=AOn4CLDXyvd5QisZmcx-Yb0Y8eFiMJvC6A', 'publish_date': '2022-04-20 00:00:00', 'length': 542, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"labels and working to improve hlp by coming up with a more consistent labeling standard will both raise hlp and give you cleaner data with which to improve your learning algorithms performance here's what i hope you take away from this video first hlp is important for problems where human level performance can provide a useful reference i do measure it and use it as a reference for what might be possible and to drive error analysis and prioritization having said that when you're measuring hlp if you find the hlp is much less than 100 also ask yourself if some of the gap between hlp and complete consistency is due to inconsistent labeling instructions because if that turns out to be the case then improving labeling consistency will raise hlp and also give cleaner data for your learning algorithm which will ultimately result in better machine learning algorithm performance here's what i hope you take away from this video hlp is useful and important for many applications for problems where i think how well humans perform is a useful reference i do measure hrp and i use that to get a sense of what might be possible and also use hlp to drive error analysis and prioritization having said that if in the process of measuring hlp you find that hlp is much less than perfect performance much lower than 100 this is also worth asking yourself if that gap between hlp and 100 accuracy may be due to inconsistent labeling instructions because if that's the case then improving labeling\", metadata={'source': 'Ny970B12IQk', 'title': '#31 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 7]', 'description': 'Unknown', 'view_count': 2499, 'thumbnail_url': 'https://i.ytimg.com/vi/Ny970B12IQk/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGEMgRyhlMA8=&rs=AOn4CLDXyvd5QisZmcx-Yb0Y8eFiMJvC6A', 'publish_date': '2022-04-20 00:00:00', 'length': 542, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"yourself if that gap between hlp and 100 accuracy may be due to inconsistent labeling instructions because if that's the case then improving labeling consistency will both raise hlp but more importantly help you get cleaner and more consistent labels which will improve your learning algorithm's performance\", metadata={'source': 'Ny970B12IQk', 'title': '#31 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 7]', 'description': 'Unknown', 'view_count': 2499, 'thumbnail_url': 'https://i.ytimg.com/vi/Ny970B12IQk/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGEMgRyhlMA8=&rs=AOn4CLDXyvd5QisZmcx-Yb0Y8eFiMJvC6A', 'publish_date': '2022-04-20 00:00:00', 'length': 542, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"you've learned about how to define what should be the data what should be the definition of why what should be the definition of the input x but how do you actually go about obtaining data for your task let's take a look at some best practices one key question i would urge you to think about is how long how much time should you spend obtaining data you know that machine learning is a highly iterative process where you need to pick a model hyper parameters have a data set then train you can carry out our analysis and go around this loop multiple times to get to a good model let's say for the sake of arguments that training your model for the first time takes a couple days maybe much shorter or maybe longer and let's say just for the sake of arguments that carrying out error analysis for your project for the first time may take a couple days if this is the case i would urge you not to spend 30 days collecting data because that will delay by a whole month you're getting into this iteration instead i urge you to get in this iteration loop as quickly as possible so training a model and error analysis might take just a couple days i would urge you to ask yourself what if you were to give yourself only two days to collect data would that help get you into this loop much more quickly maybe two days is too short but i've seen far too many teams take too long to collect their initial data set before they train the initial model whereas i've rarely come across a team where i said hey\", metadata={'source': 'qt9tXjtlQt4', 'title': '#32 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 8]', 'description': 'Unknown', 'view_count': 2478, 'thumbnail_url': 'https://i.ytimg.com/vi/qt9tXjtlQt4/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVyhAMA8=&rs=AOn4CLAZ15fMH17NqAT32-PzpH69uGTrKw', 'publish_date': '2022-04-20 00:00:00', 'length': 747, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"teams take too long to collect their initial data set before they train the initial model whereas i've rarely come across a team where i said hey you really should have spent more time collecting data and after you've trained your initial model care and analysis there's plenty of time to go back and collect more data i found for a lot of projects i've led when i go to the team and say hey everyone we're gonna spend at most seven days collecting data so what can we do i found that posing the question that way often leads to much more creative ways ways that still 100 respect user privacy and follow regulatory considerations of any but much more creative scrappy ways to get a lot of data quickly and that allows you to enter this iteration loop much more quickly and lets the project make faster progress one exception to this guideline is if you have worked on this problem before and if from experience you know you need at least a certain training set size then it might be okay to invest more effort up front to collect that much data so because i've worked on speech recognition i have a good sense of how much data i'll need to do certain things and i know it's just not worth trying to train certain models if i have less than certain number of hours of data but a lot of the time if you're working on a brand new problem and if you're not sure and it's often hard to tell even from the literature but if you're not sure just how much data is needed then it's much better to quickly\", metadata={'source': 'qt9tXjtlQt4', 'title': '#32 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 8]', 'description': 'Unknown', 'view_count': 2478, 'thumbnail_url': 'https://i.ytimg.com/vi/qt9tXjtlQt4/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVyhAMA8=&rs=AOn4CLAZ15fMH17NqAT32-PzpH69uGTrKw', 'publish_date': '2022-04-20 00:00:00', 'length': 747, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"not sure and it's often hard to tell even from the literature but if you're not sure just how much data is needed then it's much better to quickly collect a small amount of data trade the model and then use error analysis to tell you if it's worth your while to go out to collect more data in terms of getting the data you need one other step i often carry out is to take inventory of possible data sources let's continue to use speech recognition as an example if you were to brainstorm a list of data sources this this is maybe what you might come up with maybe you already own 100 hours of transcribed speech data and because you already own it the cost of that is zero or you may be able to use a crowdsourcing platform and pay people to read text so you provide them a piece of text and ask them to read it out loud and this creates text data where you already have the transcript because we're reading a piece of text that you have or you may decide to take audio that you have that hasn't been labeled yet and to pay for it to be transcribed it turns out this is more expensive on a per hour basis than paying people to read text but this results in audio that sounds more natural because people aren't reading so for a hundred hours of data it may cost six thousand dollars to get high quality transcripts or you may find some commercial organizations that could sell you data through an exercise like this you can brainstorm what are the different types of data you might use as well as\", metadata={'source': 'qt9tXjtlQt4', 'title': '#32 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 8]', 'description': 'Unknown', 'view_count': 2478, 'thumbnail_url': 'https://i.ytimg.com/vi/qt9tXjtlQt4/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVyhAMA8=&rs=AOn4CLAZ15fMH17NqAT32-PzpH69uGTrKw', 'publish_date': '2022-04-20 00:00:00', 'length': 747, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"organizations that could sell you data through an exercise like this you can brainstorm what are the different types of data you might use as well as their associated costs one column that's missing from this that i find very important is the time cost so how long will it take you to execute the project to get these different types of data for the own data you could get that instantaneously for crowd source reading you may need to implement a bunch of software find the right crowd sourcing platform carry out software integration so you might estimate that that's two weeks of engineering work paying for data to be labeled is simpler but still is work to organize and manage whereas purchasing data maybe there's a purchase order process that may be much quicker i find that some teams won't go through an inventory process like this and would just pick a random idea and maybe decide to use crowdsourcing and reading to collect data but if you can sit down write all the different data sources and think through the trade-offs including cost and time then that can help you to make often better decisions about what sources of data to use and so if you are especially pressed with time based on this analysis you may decide to use the data video and maybe purchase some data and use that over the middle two options in order to get going more quickly in addition to the amount of data you can acquire and the financial cost and the time cost other important factors does application\", metadata={'source': 'qt9tXjtlQt4', 'title': '#32 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 8]', 'description': 'Unknown', 'view_count': 2478, 'thumbnail_url': 'https://i.ytimg.com/vi/qt9tXjtlQt4/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVyhAMA8=&rs=AOn4CLAZ15fMH17NqAT32-PzpH69uGTrKw', 'publish_date': '2022-04-20 00:00:00', 'length': 747, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"more quickly in addition to the amount of data you can acquire and the financial cost and the time cost other important factors does application dependence will include data quality where you may decide for example that paying for labels actually gives more natural audio than having people sound like they're reading as well as really importantly privacy and regulatory constraints if you decide to get data labeled here are some options you might think through as well the three most common ways to get data labeled are in-house where you have your own team labeled data versus outsource where you might find some company that labels data and have them do it for you versus crowdsource where you might use a crowdsourcing platform to have a large group collectively label the data the difference between outsourced versus crowdsource is that depending on what type of data you have there may be specialized companies that could help you get the label quite efficiently some of the trade-offs between these options having machine learning engineers label data is often expensive but i find that to get a project going quickly having machine learning engineers do this just for a few days is usually fine and in fact this can help build the machine learning engineer's intuition about the data when i'm working on a new project i often don't mind spending a few hours or maybe a day or two labeling data myself if that helps me to build my intuition about the project but beyond a certain point you\", metadata={'source': 'qt9tXjtlQt4', 'title': '#32 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 8]', 'description': 'Unknown', 'view_count': 2478, 'thumbnail_url': 'https://i.ytimg.com/vi/qt9tXjtlQt4/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVyhAMA8=&rs=AOn4CLAZ15fMH17NqAT32-PzpH69uGTrKw', 'publish_date': '2022-04-20 00:00:00', 'length': 747, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"a few hours or maybe a day or two labeling data myself if that helps me to build my intuition about the project but beyond a certain point you may not want to spend all your time as a machine learning engineer labeling data and you might want to shift to more scalable labeling processes depending on your application there may be also different groups or subgroups of individuals that are going to be more qualified to provide the labels why if you're working on speech recognition then maybe almost any reasonably fluent speaker can listen to audio and transcribe it so speech recognition because of the number of people that speak a certain language has a very large pool of potential laborers or hopefully they will be careful and diligent for more specialized applications like factory inspection or medical image diagnosis a typical person off the street probably can't look at a medical x-ray image and diagnose from it or look at a smartphone and determine what is and what isn't a defect so most specialized tasks like these usually require an sme or subject matter expert in order to provide accurate labels and then finally there are some applications where it's very difficult to get anyone to give good labels take product recommendations there are probably product recommendation systems that are giving better recommendations to you than even your best friends or maybe your significant other and for this you may just have to rely on purchase data by the user as the label rather\", metadata={'source': 'qt9tXjtlQt4', 'title': '#32 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 8]', 'description': 'Unknown', 'view_count': 2478, 'thumbnail_url': 'https://i.ytimg.com/vi/qt9tXjtlQt4/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVyhAMA8=&rs=AOn4CLAZ15fMH17NqAT32-PzpH69uGTrKw', 'publish_date': '2022-04-20 00:00:00', 'length': 747, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"than even your best friends or maybe your significant other and for this you may just have to rely on purchase data by the user as the label rather than get humans to label this when you're working on an application figuring out which of these categories of applications you're working on and identifying the right type of person or persons to help you label will be an important step to making sure your labels are high quality one last tip let's say you have a thousand examples and you've decided you need a bigger data set how much bigger should you make your data set one tip i've given a lot of teams is don't increase your data by more than 10x at the time so if you have a thousand examples and you've changed your model on a thousand examples maybe it's worth investing to try to increase your data set to 3000 examples or maybe at most 10 000 examples but i would first do a 10x or less than 10x increase first train another model carry out error analysis and only then figure out if it's worth increasing it substantially beyond that because once you increase your data set size by 10x so many things change is really difficult i've found it's really hard to predict what will happen when your data set size increases even beyond that it's also fine to increase your data set size 10 or 50 or just your 2x at the time so this is only an upper bound for how much you might invest to increase your data set size and this guideline hopefully will help teams avoid over-investing in tons of\", metadata={'source': 'qt9tXjtlQt4', 'title': '#32 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 8]', 'description': 'Unknown', 'view_count': 2478, 'thumbnail_url': 'https://i.ytimg.com/vi/qt9tXjtlQt4/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVyhAMA8=&rs=AOn4CLAZ15fMH17NqAT32-PzpH69uGTrKw', 'publish_date': '2022-04-20 00:00:00', 'length': 747, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"upper bound for how much you might invest to increase your data set size and this guideline hopefully will help teams avoid over-investing in tons of data only to realize that collecting quite damaged data wasn't the most useful thing they could have done i hope the tips in this video will help you to be more efficient in how you go about collecting your data now when you collect your data one of the things you might run into is the need to build a data pipeline where your data doesn't come all at once but there are multiple pre-processing steps that your data has to go through let's go on to the next video to take a look at some best practices for building data pipelines\", metadata={'source': 'qt9tXjtlQt4', 'title': '#32 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 8]', 'description': 'Unknown', 'view_count': 2478, 'thumbnail_url': 'https://i.ytimg.com/vi/qt9tXjtlQt4/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVyhAMA8=&rs=AOn4CLAZ15fMH17NqAT32-PzpH69uGTrKw', 'publish_date': '2022-04-20 00:00:00', 'length': 747, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"data pipelines sometimes also called data cascades refers to when your data has multiple steps of processing before getting to the final output there's some best practices relevant for managing such data pipelines let's start to an example let's say that given some user information you would like to predict if a given user is looking for a job because if they're looking for a job at this moment in time you may want to surface job ads or other pieces of particularly useful information to them so given raw data such as the data on top there's often some sort of pre-processing or data cleaning before the data is fed to learning algorithm that then tries to predict why are they looking for a job and the data cleaning may include things like spam cleanup such as removing the spam accounts and maybe also user id merge which we talked about in an earlier video for the sake of this example let's say that spam cleanup and user id merge are done with just scripting so explicit sequences of instructions that tells your code when is an account to be considered spammy and when should two user ids be merged of course these systems could be built using machine learning algorithms as well which makes them even a little bit more complex to manage now when you have scripts for the data cleaning one of the issues you run into is replicability when you take these systems into production deployment let's say during the development of the system you have input data fed through pre-processing\", metadata={'source': 'gz-44N3MMOA', 'title': '#33 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 9]', 'description': 'Unknown', 'view_count': 2346, 'thumbnail_url': 'https://i.ytimg.com/vi/gz-44N3MMOA/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgXyhGMA8=&rs=AOn4CLBKBxiNTOpFUFNOtiwMavgq6tB5tA', 'publish_date': '2022-04-20 00:00:00', 'length': 346, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"when you take these systems into production deployment let's say during the development of the system you have input data fed through pre-processing scripts and the pre-processed data is fed to machine learning algorithm and after some amount of work your learning algorithm does well on the test set during the development phase you may have seen that pre-processing scripts can be quite messy it may be you hacking something up processing data mailing a file to a different member of your team having them have a few incantations in python or some scripting language to process the data and then having them mail the process data back to you when you take this system to production you then have new data which has to be fed through a similar set of scripts because this data is going to be fed to the same machine learning algorithm and your machine learning algorithm on this data is what will run in your product so the key question is if your pre-processing was done with a bunch of scripts spread out on a bunch of different people's computers and laptops how do you replicate the strips to make sure that the input distribution to your machine learning algorithm was the same for the developed data and the production data i find that the amount of effort that you should invest to make sure that the pre-processing scripts are highly replicable can depend a little bit on the phase of the project i know that it may be fashionable to say that everything you do should be 100 replicable and\", metadata={'source': 'gz-44N3MMOA', 'title': '#33 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 9]', 'description': 'Unknown', 'view_count': 2346, 'thumbnail_url': 'https://i.ytimg.com/vi/gz-44N3MMOA/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgXyhGMA8=&rs=AOn4CLBKBxiNTOpFUFNOtiwMavgq6tB5tA', 'publish_date': '2022-04-20 00:00:00', 'length': 346, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"can depend a little bit on the phase of the project i know that it may be fashionable to say that everything you do should be 100 replicable and i'll probably get some criticism for not hewing to that line but i find that a lot of projects do go through a proof of concept of poc phase and then a production phase where during the proof of concept phase the primary goal is just to decide if the application is workable and worth building and deploying my advice to most teams is during the proof of concept phase focus on getting the prototype to work and it's okay if some of the data pre-processing is manual if the project succeeds you need to replicate all this pre-processing later so my advice would be take extensive notes write extensive comments to increase the odds that you can replicate all this pre-processing later but this is also not the time to get bogged down in tons of process just to ensure replicability when the focus is really to just decide if the application is workable and is worth taking to the next phase once you've decided that this project is worth taking to production then you know it's going to be really important to really replicate any pre-processing scripts so in this phase that's when i would use more sophisticated tools to make sure the entire data pipeline is replicable and this is when tools which can be a little bit more heavyweight but tools like tensorflow transform apache beam airflow and so on become very valuable and in fact you learn more\", metadata={'source': 'gz-44N3MMOA', 'title': '#33 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 9]', 'description': 'Unknown', 'view_count': 2346, 'thumbnail_url': 'https://i.ytimg.com/vi/gz-44N3MMOA/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgXyhGMA8=&rs=AOn4CLBKBxiNTOpFUFNOtiwMavgq6tB5tA', 'publish_date': '2022-04-20 00:00:00', 'length': 346, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"be a little bit more heavyweight but tools like tensorflow transform apache beam airflow and so on become very valuable and in fact you learn more about tensorflow transform later into specialization as well in this video you learned about data pipelines and when to invest in their replicability it turns out many applications have significantly more complex data pipelines than what we saw in this video and for those settings you also have to think about what metadata you want and perhaps also keep track and take care of data provenance and lineage let's go on to the next video to look at these topics\", metadata={'source': 'gz-44N3MMOA', 'title': '#33 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 9]', 'description': 'Unknown', 'view_count': 2346, 'thumbnail_url': 'https://i.ytimg.com/vi/gz-44N3MMOA/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgXyhGMA8=&rs=AOn4CLBKBxiNTOpFUFNOtiwMavgq6tB5tA', 'publish_date': '2022-04-20 00:00:00', 'length': 346, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"for some applications having and tracking metadata data provenance and data lineage can be a big help what do these words even mean let's look at an example here's a more complex example of a data pipeline building on our previous example of using user records to predict if someone is looking for a job at a given moment in time let's say you start off with a spam data set this may include a list of known spam accounts as well as features such as a list of blacklisted ip addresses that spammers are known to use you might also implement a learning algorithm so piece of machine learning code and train your learning algorithm on the spam data set thus giving you an anti-spam model so these arrows indicate flow of information or flow of computation where training your ml code on the spam data set gives you your anti-spam model you then take your user data and apply the anti-spam model to it to get the dspam user data we're following our usual convention that things with a purple rectangle around it represent pieces of code now taking your dspam user data next you might want to carry out user id merge to do that you might start off with some id merge data so this would be labeled data telling you some pairs of accounts that actually correspond to the same person have a machine learning album implementation train the model on that and this gives you a learned id merge model that tells you when to combine two accounts into a single user id you take your id merge model apply it to the\", metadata={'source': 'hbqxEJisBHo', 'title': '#34 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 10]', 'description': 'Unknown', 'view_count': 2310, 'thumbnail_url': 'https://i.ytimg.com/vi/hbqxEJisBHo/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVyhAMA8=&rs=AOn4CLCJpo607K9yg245bw2Kl1ounjm_Vw', 'publish_date': '2022-04-20 00:00:00', 'length': 596, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"gives you a learned id merge model that tells you when to combine two accounts into a single user id you take your id merge model apply it to the dspam user data this gives you your cleaned up user data then finally based on the clean user data hopefully some of this labels with whether someone's looking for a job you would then have another machine learning model trained on it to give you a model to predict if a given user is looking for a job or not and this is then used to make predictions on other users or maybe across your whole database of users so this level of complexity of a data pipeline is not atypical in large commercial systems and i've seen data pipelines or data cascades that are even far more complicated than this one of the challenges of working with data pipelines like this is what if after running this system for months you discover that oops the ip address blacklist you're using has some mistakes in it in particular what if you discover that there were some ip addresses that were incorrectly blacklisted maybe because the provider from whom you had purchased the blacklisted ip addresses found out that there were some ip addresses that multiple users use right such as if multiple users on a corporate campus or university campus share an ip address for security reasons but the organization creating the blacklist ipi just thought it was spammy because so many people shared an ip address this has happened before so the question is having built up this big\", metadata={'source': 'hbqxEJisBHo', 'title': '#34 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 10]', 'description': 'Unknown', 'view_count': 2310, 'thumbnail_url': 'https://i.ytimg.com/vi/hbqxEJisBHo/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVyhAMA8=&rs=AOn4CLCJpo607K9yg245bw2Kl1ounjm_Vw', 'publish_date': '2022-04-20 00:00:00', 'length': 596, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"ipi just thought it was spammy because so many people shared an ip address this has happened before so the question is having built up this big complex system if you were to update your spam data set won't that change your spam model and therefore that and therefore that and therefore that and therefore that and how do you go back and fix this problem especially if each of these systems was developed by a different engineer and you have files spread across the laptops of your machine learning engineering development team so to make sure your system is maintainable especially when a piece of data upstream ends up needing to be changed it can be very helpful to keep track of data provenance as well as lineage data provenance refers to where the data came from so who did you purchase the spam ip address from and lineage refers to the sequence of steps needed to get to the end of the pipeline at the very least having a extensive documentation could help you reconstruct data provenance and lineage but to build robust maintainable systems not in the proof of concept stage but in the production stage there are more sophisticated tools to help you keep track of what happened so you can change part of the system and hopefully replicate the rest of the data pipeline without too much unnecessary complexity to be honest the tools for keeping track of data provenance and lineage are still immature in today's machine learning world i find that extensive documentation can help and some\", metadata={'source': 'hbqxEJisBHo', 'title': '#34 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 10]', 'description': 'Unknown', 'view_count': 2310, 'thumbnail_url': 'https://i.ytimg.com/vi/hbqxEJisBHo/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVyhAMA8=&rs=AOn4CLCJpo607K9yg245bw2Kl1ounjm_Vw', 'publish_date': '2022-04-20 00:00:00', 'length': 596, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"track of data provenance and lineage are still immature in today's machine learning world i find that extensive documentation can help and some formal tools like tensorflow transform can also help but solving this type of problem is still not something that we are great at as a community yet to make life easier both for managing data pipelines as well as for error analysis and driving machine learning development there's one tip i want to share which is to make extensive use of metadata so metadata is data about data for example in manufacturing visual inspection the data would be the pictures of phones and the labels but if you have metadata that tells you at what time was this picture of a phone taken what factory was this picture from what's the line number what were the camera settings such as camera exposure time and camera aperture what's the number of the phone you're inspecting what is the id of the inspector that provided this label these are examples of data about your data set x and y and this type of metadata can turn out to be really useful because if you discover during machine learning development that for some strange reason line number 17 in factory 2 [Music] generates images that produce a lot more errors for some reason then this allows you to go back to see what was funny about line 17 and factory two but if you had not stored the factory and line number of metadata in the first place then it would have been really difficult to discover this during error\", metadata={'source': 'hbqxEJisBHo', 'title': '#34 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 10]', 'description': 'Unknown', 'view_count': 2310, 'thumbnail_url': 'https://i.ytimg.com/vi/hbqxEJisBHo/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVyhAMA8=&rs=AOn4CLCJpo607K9yg245bw2Kl1ounjm_Vw', 'publish_date': '2022-04-20 00:00:00', 'length': 596, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"you had not stored the factory and line number of metadata in the first place then it would have been really difficult to discover this during error analysis so i found many times when i happened to maybe get lucky and store the right metadata only to discover a month later that that metadata helped generate a key insight that helped the project move forward so my tip is if you have a framework for storing metadata that will definitely make life easier but even if you don't just like you rarely regret commenting your code i think you will rarely regret storing metadata that could then turn out to be useful later and just like if you don't comment your code in a timely way it's much harder to go back to commenting later in the same way if you don't store the metadata in a timely way it can be much harder to go back to recapture and organize that data one more example for speech recognition if you have audio recorded from different brands of smartphones let's say that in advance or if you have different labelers labeling your speech or if you use a voice activity detection model then let's keep track of what was the version number of the voice activity detection model that you use and all of these means that in case for some reason one version of the vad voice activity detection system results in much larger errors this significantly increases the odds of your discovering that and be able to use that to improve your learning over and performance so to summarize metadata can be\", metadata={'source': 'hbqxEJisBHo', 'title': '#34 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 10]', 'description': 'Unknown', 'view_count': 2310, 'thumbnail_url': 'https://i.ytimg.com/vi/hbqxEJisBHo/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVyhAMA8=&rs=AOn4CLCJpo607K9yg245bw2Kl1ounjm_Vw', 'publish_date': '2022-04-20 00:00:00', 'length': 596, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"increases the odds of your discovering that and be able to use that to improve your learning over and performance so to summarize metadata can be very useful for error analysis and spotting unexpected effects or tags or categories of data that have some unusually poor performance or something else to suggest how to improve your system and of course maybe not surprisingly this type of metadata is also very useful for keeping track of where the data came from of data provenance the takeaway from this video is that for large complex machine learning systems that you might need to maintain keeping track of data provenance and lineage can make your life much easier and as part of building out these systems consider keeping track of metadata which can help you with tracking data provenance but also error analysis before we wrap up this section there's just one more tip i hope to share with you which is the importance of balanced train death test splits let's go on to the next video\", metadata={'source': 'hbqxEJisBHo', 'title': '#34 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 10]', 'description': 'Unknown', 'view_count': 2310, 'thumbnail_url': 'https://i.ytimg.com/vi/hbqxEJisBHo/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVyhAMA8=&rs=AOn4CLCJpo607K9yg245bw2Kl1ounjm_Vw', 'publish_date': '2022-04-20 00:00:00', 'length': 596, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"many of us are used to taking a data set and randomly splitting it into train depth and tests it turns out when your data set is small having balance trained dev and test sets can significantly improve your machine learning development process let's take a look let's use our manufacturing visual inspection example say your training set has a hundred images so pretty small data sets and with 30 positive examples so 30 defective phones and 70 non-defective if you were to use a train depth test split of sixty percent of the data in the training set twenty percent in the depth or holdout validation set and 20 in the test set say then if you were to use a random split just by chance it's not inconceivable that you may end up with 21 positive examples in train two in-depth and seven in test this would be quite likely just by random chance and this means the training set is 35 percent positive not that far from 30 positive in the overall data set but your depth set is 10 positive and your test set is 35 positive so 2 out of 20 is 10 7 out of 20 is 35 and this makes your death sets quite non-representative because in your death set you have only two or ten percent positive examples rather than 30 positive examples but when your data set is small then all of your 20 def set examples is just a higher chance of this slightly less representative split so what we would really want is for the training set to have exactly 18 positive examples def sets have exactly six positive examples and\", metadata={'source': 'mFD5hUZubTI', 'title': '#35 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 1, Lesson 11]', 'description': 'Unknown', 'view_count': 2239, 'thumbnail_url': 'https://i.ytimg.com/vi/mFD5hUZubTI/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgXChEMA8=&rs=AOn4CLDy6jMjGpvSN9CQnwXzAUFhUqnEBQ', 'publish_date': '2022-04-20 00:00:00', 'length': 277, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"split so what we would really want is for the training set to have exactly 18 positive examples def sets have exactly six positive examples and the test set to have exactly six positive examples and this would be thirty percent thirty percent thirty percent and if you could get this type of split this would be called a balance split where each of your train dev and tests has exactly 30 positive examples and this makes your data set more representative of the true data distribution there's no need to worry about this effect when you have a large data set if you have a very large data set a random split will very likely be representative meaning that the percentage of positive examples will be quite close to your overall data set but when you have a small data set with just 20 def set examples and 20 test set examples then explicitly making sure you have a balanced split can make your death set and test set more reliable measures of your learning algorithms performance this is one of those little techniques that turns out to make a big difference to your performance when you're working on a small data problem but that you don't really need to worry about if you have a very large data set so when you have a smaller data set i hope you consider using a balanced train dev test splits as well in terms of how you set up your data sets so when you're working on a smaller data problem i hope that using a balanced chain depth test split will help you with your learning algorithm and\", metadata={'source': 'mFD5hUZubTI', 'title': '#35 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 1, Lesson 11]', 'description': 'Unknown', 'view_count': 2239, 'thumbnail_url': 'https://i.ytimg.com/vi/mFD5hUZubTI/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgXChEMA8=&rs=AOn4CLDy6jMjGpvSN9CQnwXzAUFhUqnEBQ', 'publish_date': '2022-04-20 00:00:00', 'length': 277, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"so when you're working on a smaller data problem i hope that using a balanced chain depth test split will help you with your learning algorithm and so that's it congratulations on getting to this point in this course you've finished the data section of videos and in the last two weeks you also learned about modeling and deployment there's just one last optional section that you can watch if you want on scoping i hope you come with me to watch the optional scoping videos as well we'll talk about how to select a project to work on but either way congrats on finishing all the required videos of this course i hope you've learned a lot and that these ideas will be useful for all your machine learning projects\", metadata={'source': 'mFD5hUZubTI', 'title': '#35 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 1, Lesson 11]', 'description': 'Unknown', 'view_count': 2239, 'thumbnail_url': 'https://i.ytimg.com/vi/mFD5hUZubTI/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgXChEMA8=&rs=AOn4CLDy6jMjGpvSN9CQnwXzAUFhUqnEBQ', 'publish_date': '2022-04-20 00:00:00', 'length': 277, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"picking the right project to work on is one of the most rare and valuable skills in ai today in the next few videos i'd like to share with you some best practices for scoping picking what project to work on and also planning out the scope of the project i remember when i was younger i tended to just jump into the first project that i got excited about and you know sometimes i was lucky and it worked out okay now that i've had a little bit more experience i find that if you by yourself or your team is going to spend a lot of time weeks or months or even longer working on a project it's well worth your while to think through a few options and try to select the most promising products to work on before putting so much effort into it so that let's dive into scoping let's use the example of an e-commerce retailer looking to increase sales if you were to sit down and brainstorm what an ecom company could do you might come up with many ideas such as maybe a better product recommendation system or better search so people can find what they're looking for or you may find that the catalog data is missing fields or is incomplete and this affects search or recommendations results so you might start the project to improve the quality of the catalog data or you may help them with inventory management such as deciding how many shirts to buy and where to ship the shirts or what price optimization with a quick brainstorming session you may be able to come up with dozens of ideas for how to\", metadata={'source': 'UEMMOdFbT94', 'title': '#36 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 12]', 'description': 'Unknown', 'view_count': 2426, 'thumbnail_url': 'https://i.ytimg.com/vi/UEMMOdFbT94/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVChCMA8=&rs=AOn4CLBHFOq_Q0F6qVNjWTnaYDfJ7c4o-A', 'publish_date': '2022-04-20 00:00:00', 'length': 153, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"and where to ship the shirts or what price optimization with a quick brainstorming session you may be able to come up with dozens of ideas for how to help this ecommerce retailer the questions that we'd like to answer in the scoping process are what project or projects should we work on what are the metrics for success and what are the resources such as data time people needed to execute this project what i've seen in a lot of businesses is that of all the ideas you could work on some are going to be much more valuable than others maybe two times or five times or ten times more valuable than a different idea and being able to pick the most valuable project will significantly increase the impact of your work machine learning is a general purpose too there are a lot of things we can do with machine learning how do we take valuable projects to work on let's dive more deeply into the scoping process in the next video\", metadata={'source': 'UEMMOdFbT94', 'title': '#36 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 12]', 'description': 'Unknown', 'view_count': 2426, 'thumbnail_url': 'https://i.ytimg.com/vi/UEMMOdFbT94/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVChCMA8=&rs=AOn4CLBHFOq_Q0F6qVNjWTnaYDfJ7c4o-A', 'publish_date': '2022-04-20 00:00:00', 'length': 153, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"i'd like to share with you a process for scoping projects that hope will be valuable for how you decide what to work on when i'm speaking with a company for the first time about their ai projects this is the process that i use as well let's dive in when brainstorming projects work on the first thing i do is usually get together with a business or product owner often not an ai person but someone that understands a business or an application and to brainstorm with them what are their business or application problems and at this stage i'm trying to identify a business problem not an ai problem so if i'm speaking with an econ retail business like the example from the previous video i might ask what are the top few things top three things you wish were working better and maybe they'll share business problems like they'd like to increase conversions number of people that go to the website and convert to a sale or reduce inventory so you don't need as much stuff sitting around in the warehouse or increase margin increase the profit per item sold at this point in the process i'm not trying to identify an ai problem in fact i'll often tell my partners i don't want to hear about your ai problems i want to hear about your business problems and then it's my job to work with you to see if there is an ai solution and sometimes there isn't and that's fine too feel free to use the exact same words as well when brainstorming projects with your non-ai partners if you want having identified a\", metadata={'source': '43CZ0HjIC7U', 'title': '#37 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 13]', 'description': 'Unknown', 'view_count': 2864, 'thumbnail_url': 'https://i.ytimg.com/vi/43CZ0HjIC7U/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgWShFMA8=&rs=AOn4CLA_ithcmA7ehGH1jVQkgpgisG8eMw', 'publish_date': '2022-04-20 00:00:00', 'length': 415, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"that's fine too feel free to use the exact same words as well when brainstorming projects with your non-ai partners if you want having identified a few business problems like the three examples on the right only then do i see or start to brainstorm if there are possible ai solutions not all problems can be solved by ai and that's okay but hopefully we'll come up with some ideas for using machine learning algorithms to address some of the business problems i find that it's helpful for this process to separate out the identification of the problem from the identification of the solution as engineers we are pretty good at coming up with solutions but having a clear articulation of what is the problem first often helps us come up with better solutions this type of separation between problem and solution is something you might hear about in the writings on design thinking as well after brainstorming a variety of different solutions i would then assess the feasibility and the value of these different solutions sometimes you hear me use the word diligence to refer to this phrase diligence is a term that actually comes from the legal field but it basically means double checking if an ai solution really is technically feasible and valuable or double checking something that you're hoping is true really is true after validating technical feasibility and the value or roi return on investments of your giving project if it still looks promising right if it still looks promising we then\", metadata={'source': '43CZ0HjIC7U', 'title': '#37 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 13]', 'description': 'Unknown', 'view_count': 2864, 'thumbnail_url': 'https://i.ytimg.com/vi/43CZ0HjIC7U/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgWShFMA8=&rs=AOn4CLA_ithcmA7ehGH1jVQkgpgisG8eMw', 'publish_date': '2022-04-20 00:00:00', 'length': 415, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"feasibility and the value or roi return on investments of your giving project if it still looks promising right if it still looks promising we then flesh out the milestones for the project and finally budget for resources let's take a deeper look at this process of identifying problems and solutions and we'll use these three examples from e-comm so the first one increase conversion if a business wants to increase conversions you may have different ideas for doing that for example you may want to improve the quality of the website's search results so people find more relevant products when they search or you might decide to try to offer up better product recommendations based on their purchase history it is quite common that one problem may lead to multiple ideas for solutions and you may be able to brainstorm other ideas as well such as maybe a redesign of how products are displayed on a page or you may find interesting ways to surface the most relevant product reviews to help users understand the product and thus hopefully purchase it so there could be many ways to increase conversions take the next problem from the previous slide of reducing inventory maybe you will you could imagine a demand prediction project to better estimate how many people buy something from you so you don't purchase too many or too few and have more accurate inventory in your warehouses or you may decide to come up with a marketing campaign to drive sales for specifically the products that you\", metadata={'source': '43CZ0HjIC7U', 'title': '#37 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 13]', 'description': 'Unknown', 'view_count': 2864, 'thumbnail_url': 'https://i.ytimg.com/vi/43CZ0HjIC7U/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgWShFMA8=&rs=AOn4CLA_ithcmA7ehGH1jVQkgpgisG8eMw', 'publish_date': '2022-04-20 00:00:00', 'length': 415, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"accurate inventory in your warehouses or you may decide to come up with a marketing campaign to drive sales for specifically the products that you bought too many of so as to steer more purchases of stuff sitting in your warehouse and that could also reduce inventory and there could be many other ideas for solutions or for the problem of increasing margin you may come up with some ways to use machine learning to optimize what to sell what is worth selling and what is not worth selling in econ retail sometimes this is called merchandising just deciding what to sell or you can recommend bundles where if someone buys a camera maybe you can recommend to them a protective camera case and these bundles can also increase margin the problem identification is a step of thinking through what are the things you want to achieve and solution identification is a process of thinking through how to achieve those objectives one thing i still see too many teams do today is jump into the first project that they're excited about in my experience if you have deep domain knowledge about an application or industry maybe the first thing your gut gets excited about could be okay but even then i find it worthwhile to first engage in diversion thinking where you brainstorm a lot of possibilities to be followed by convergent thinking where you then narrow it down to one or a small handful of the most promising projects to focus on one thing i hope you might avoid is working really hard on the project\", metadata={'source': '43CZ0HjIC7U', 'title': '#37 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 13]', 'description': 'Unknown', 'view_count': 2864, 'thumbnail_url': 'https://i.ytimg.com/vi/43CZ0HjIC7U/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgWShFMA8=&rs=AOn4CLA_ithcmA7ehGH1jVQkgpgisG8eMw', 'publish_date': '2022-04-20 00:00:00', 'length': 415, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"it down to one or a small handful of the most promising projects to focus on one thing i hope you might avoid is working really hard on the project and creating a certain amount of monetary or social value if for the same amount of work there's a different project that could have created 10 times more you know monetary or social or other positive types of value and i think this type of scoping process will help you to do that\", metadata={'source': '43CZ0HjIC7U', 'title': '#37 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 13]', 'description': 'Unknown', 'view_count': 2864, 'thumbnail_url': 'https://i.ytimg.com/vi/43CZ0HjIC7U/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgWShFMA8=&rs=AOn4CLA_ithcmA7ehGH1jVQkgpgisG8eMw', 'publish_date': '2022-04-20 00:00:00', 'length': 415, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"in the last video you heard about the step of assessing a project for technical feasibility and for value let's take a deeper look at how you can carry out this diligent step to figure out if a project really is feasible and also how valuable it really is let's start with feasibility is this project idea technically feasible before you've started on the machine learning project how do you know if this thing can even be built one way to get a quick sense of feasibility is to use an external benchmark such as the research literature or other forms of publications or if a different company or even a competitor has managed to build a certain type of online search system before or recommendation system or inventory management but if there's some external benchmark that might help give you a sense that this project may be technically feasible because someone else has managed to do something similar either to complement this type of external benchmark or in the absence of this type of external benchmark here are some other ways to assess feasibility and i'm going to build a two by two matrix that looks at different cases depending on whether your problem has unstructured data like speech images or structured data like transaction records and on the other axis i'm going to put new versus existing whereby new i mean you're trying to build a system to do a toss for the first time such as if you've never done demand forecasting before and you're thinking of building one whereas existing\", metadata={'source': 'opWrnW5v25w', 'title': '#38 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 14]', 'description': 'Unknown', 'view_count': 3429, 'thumbnail_url': 'https://i.ytimg.com/vi/opWrnW5v25w/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVShAMA8=&rs=AOn4CLD202LIMzxGRxgxJhFngHfj0579Hw', 'publish_date': '2022-04-20 00:00:00', 'length': 867, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"a system to do a toss for the first time such as if you've never done demand forecasting before and you're thinking of building one whereas existing refers to if you already have some existing system maybe a machine learning one maybe not that is carry out this toss and you're thinking of scoping out an improvement to an existing system right so new means you are delivering a brand new capability and existing means you're scoping out the project to improve on an existing capability in the upper left hand quadrant to see if a project is technically feasible i find human level performance hrp to be very useful and give you an initial sense of whether a project is doable so when evaluating hrp i would give a human the same data as would be fed to a learning algorithm and just ask you know can a human given the same data perform the task such as can a human given a picture of a scratch smartphone perform the task of detecting scratches reliably and if a human can do it then that significantly increases the hope that you can also get a learning algorithm to do it for existing projects i would use hlp as a reference as well where if you have a visual defect inspection system and you're hoping to improve it to a certain level of performance if humans can achieve the level you're hoping to get it to then that might give you more hope that it is technically feasible whereas if you're hoping to increase performance well beyond human level performance then that suggested project might\", metadata={'source': 'opWrnW5v25w', 'title': '#38 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 14]', 'description': 'Unknown', 'view_count': 3429, 'thumbnail_url': 'https://i.ytimg.com/vi/opWrnW5v25w/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVShAMA8=&rs=AOn4CLD202LIMzxGRxgxJhFngHfj0579Hw', 'publish_date': '2022-04-20 00:00:00', 'length': 867, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"it is technically feasible whereas if you're hoping to increase performance well beyond human level performance then that suggested project might be harder or may not be possible in addition to hlp i often also use the history of the project as a predictor for future progress and we'll say more about both hlp and history of project in the next few slides but the previous rate of progress on the project can be a reasonable predictor for the future rate of progress on the project you'll see more of this later in this video moving over to the right column if you're working on a brand new project with structured data the question i would ask is are predictive features available do you have reason to think that the data you have the inputs x are strongly predictive or sufficiently predictive of the target output y in this box on the lower right for a structured data problem if you're trying to improve an existing system one thing that will help a lot is if you can identify new predictive features so are there features that you aren't yet using but you can identify that could really help predict why and also by looking at the history of the project so on this slide you heard about three concepts human level performance the question of whether predictive features are available and also the history of a project let's take a deeper look at these three concepts and let's start with using hlp on unstructured data images so i use hlp to benchmark what might be doable for unstructured\", metadata={'source': 'opWrnW5v25w', 'title': '#38 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 14]', 'description': 'Unknown', 'view_count': 3429, 'thumbnail_url': 'https://i.ytimg.com/vi/opWrnW5v25w/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVShAMA8=&rs=AOn4CLD202LIMzxGRxgxJhFngHfj0579Hw', 'publish_date': '2022-04-20 00:00:00', 'length': 867, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"at these three concepts and let's start with using hlp on unstructured data images so i use hlp to benchmark what might be doable for unstructured data because people are very good on unstructured data tasks and so the key criteria for assessing project feasibility is can a human given the exact same data as would be given to learning algorithm perform the task let's look at an example let's say you're building a self-driving car and you want an algorithm to classify whether traffic light is currently red yellow or green i would i would take pictures from your self-driving car and ask a person to look at an image like this and see if a person looking only at the image can tell which lamp is illuminated and in this example it's pretty clear green but if you find that you also have pictures like this then well i can't tell which lamp is illuminated in this example and this is why it's important for this hlp benchmark to make sure the human is given only the same data as your learning algorithm it turns out maybe a human sitting in the car and seeing the traffic light with their own eye could have told you which lamp was illuminated in this example on the right but that's because the human eye has superior contrast to most digital cameras but a useful test is not whether the human eye can recognize which light which lamp is illuminated the useful test is if the person was sitting back in the office and they can only see the image from the camera can they still do the task and\", metadata={'source': 'opWrnW5v25w', 'title': '#38 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 14]', 'description': 'Unknown', 'view_count': 3429, 'thumbnail_url': 'https://i.ytimg.com/vi/opWrnW5v25w/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVShAMA8=&rs=AOn4CLD202LIMzxGRxgxJhFngHfj0579Hw', 'publish_date': '2022-04-20 00:00:00', 'length': 867, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"the useful test is if the person was sitting back in the office and they can only see the image from the camera can they still do the task and that gives you a better read on feasibility and specifically it helps you make a better guess and whether a learning algorithm which will only have access to this image can also accurately detect which lamp in the traffic light is illuminated making sure that a human sees only the same data as the learning iron will see is really important i've seen a lot of projects where for a long time a team was working on a computer vision system say and they thought they could do it because a human physically inspecting the cell phone or something could detect the defect but it took a long time to realize that even a human looking only at the image couldn't figure out what was going on then you can figure out much earlier that with the current camera setup it just wasn't feasible and the more efficient thing to do would have been to invest early on in a better camera or a better lighting setup or something rather than keep working on a machine learning algorithm on a problem that i think just wasn't doable with the imaging setup available at the time next for structured data problems one of the key criteria to assess for technical feasibility is do we have input features x that seem to be predictive whenever we're trying to predict why let's look at a few examples in our ecom example if you have features that show what are the past purchases of\", metadata={'source': 'opWrnW5v25w', 'title': '#38 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 14]', 'description': 'Unknown', 'view_count': 3429, 'thumbnail_url': 'https://i.ytimg.com/vi/opWrnW5v25w/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVShAMA8=&rs=AOn4CLD202LIMzxGRxgxJhFngHfj0579Hw', 'publish_date': '2022-04-20 00:00:00', 'length': 867, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"whenever we're trying to predict why let's look at a few examples in our ecom example if you have features that show what are the past purchases of a user and you like to predict future purchases that seems plausible to me because most people's previous purchases are predictive of future purchases so if you have past purchase data you do have features that seem predictive of future purchases and this project might be worth a try or if you work with a physical store given data on weather if you want to predict shopping mall foot traffic so how many people will go to the mall well we know that when it rains a lot fewer people leave their house so weather is predictive of foot traffic and shopping malls and so i would say you do have predictive features whoever try let's look at some more examples given dna of an individual let's try to predict if this individual will have heart disease this one i don't know the mapping from your dna to whether or not you get heart disease is a very noisy mapping in biology this is referred to the genotype and phenotype but the mapping from genotype to phenotype or your genetics to your health condition is a very noisy mapping so i would have mixed feelings about this project because it turns out your genetic sequence is only slightly maybe mildly predictive of whether you get heart disease so with a question so i'm going gonna put a question mark there or given social media chatter can you predict demand for a clothing style this is another\", metadata={'source': 'opWrnW5v25w', 'title': '#38 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 14]', 'description': 'Unknown', 'view_count': 3429, 'thumbnail_url': 'https://i.ytimg.com/vi/opWrnW5v25w/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVShAMA8=&rs=AOn4CLD202LIMzxGRxgxJhFngHfj0579Hw', 'publish_date': '2022-04-20 00:00:00', 'length': 867, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"a question so i'm going gonna put a question mark there or given social media chatter can you predict demand for a clothing style this is another iffy one i think you may be able to predict demand for clothing style right now but given social media chatter can you predict what will be the hot fashionable trend six months from now that actually seems very difficult so one of the ways i've seen ai projects go poorly is if there's an idea like let's use social media to figure out what people are chatting about in fashion and they will manufacture the clothing and sell it in six months and sometimes the data just is not that predictive and you end up with a learning algorithm that does barely better than random guessing and that's why looking at whether you have features that you believe are predictive is an important step of diligence for assessing technical feasibility of a project one last example that that may be even clearer which is given a history of a particular stock or a particular shares price let's try to predict the future price of that stock all the evidence i've seen is that this is not doable unless you get some other clever set of features looking at the single shares historical price to predict the future price of that stock is exceedingly difficult and i would say if those are the only features you have those features are not predictive of the future price of that stock based on the evidence i've seen and so even leaving aside the question of how much\", metadata={'source': 'opWrnW5v25w', 'title': '#38 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 14]', 'description': 'Unknown', 'view_count': 3429, 'thumbnail_url': 'https://i.ytimg.com/vi/opWrnW5v25w/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVShAMA8=&rs=AOn4CLD202LIMzxGRxgxJhFngHfj0579Hw', 'publish_date': '2022-04-20 00:00:00', 'length': 867, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"features are not predictive of the future price of that stock based on the evidence i've seen and so even leaving aside the question of how much predicting share prices or trading creates any social value i have some questions about that sometimes i think this project is also just not technically feasible finally on this diagram one last criteria i mentioned a couple times is the history of a project let's take a look at that when i've worked on a machine learning application for many months i found that the rate of previous improvement can be maybe a surprisingly good predictor for the rate of future improvement here's a simple model you could use let's take speech recognition as an example and let's say that this is human level performance and i'm going to use human level performance as our estimate for bayes era or the irreducible level of error that we hope to get to let's say that when you started the project you know say in the first quarter or q1 or some year the system had 10 error rate and over time in subsequent quarters the error you know went down like so so q2 q3 q4 and so on it turns out that it's not a terrible model to estimate this curve so if you want to estimate how well the team could do in the future one simple model i've used is to estimate the rate of progress as for every fixed period of time say every quarter the team will reduce the error rate by some percentage relative to human level performance so in this case it looks like this gap between the\", metadata={'source': 'opWrnW5v25w', 'title': '#38 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 14]', 'description': 'Unknown', 'view_count': 3429, 'thumbnail_url': 'https://i.ytimg.com/vi/opWrnW5v25w/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVShAMA8=&rs=AOn4CLD202LIMzxGRxgxJhFngHfj0579Hw', 'publish_date': '2022-04-20 00:00:00', 'length': 867, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"quarter the team will reduce the error rate by some percentage relative to human level performance so in this case it looks like this gap between the current level of performance and human level performance is shrinking by maybe 30 every quarter which is why you get this curve that is exponentially decaying towards hlp and by estimating this rate of progress you may project into the future that hopefully in future quarters you continue to reduce the error by 30 percent relative to hlp and this will give you a sense of what might be reasonable for the future rate of progress on this project and thus this gives you a sense of what may be feasible for an existing project for which you already have this type of history and can try to extrapolate into the future in this video you saw how to use human level performance the question of whether you have predictive features and the history of a project in order to assess technical feasibility next let's dive more deeply into assessing the value of a project we'll do that in the next video\", metadata={'source': 'opWrnW5v25w', 'title': '#38 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 14]', 'description': 'Unknown', 'view_count': 3429, 'thumbnail_url': 'https://i.ytimg.com/vi/opWrnW5v25w/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVShAMA8=&rs=AOn4CLD202LIMzxGRxgxJhFngHfj0579Hw', 'publish_date': '2022-04-20 00:00:00', 'length': 867, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"how do you estimate the value of machine learning project this is sometimes not easy to estimate but let me share with you a few best practices tick speech recognition let's say you're working on building a more accurate speech recognition system for the purpose of voice search to let people speak to the smartphone app to do web searches it turns out that in most businesses there will be some metrics that machine learning engineers are used to optimizing and some metrics that the owners of the product or the business will want to maximize and there's often a gap between these two building machine learning systems the objective that the learning algorithm may optimize might be something like word level accuracy so if a user says a certain number of words how many of the words do we get right so maybe the learning algorithm actually does great in the sense on log likelihood or some other criteria but many machine learning teams would be comfortable trying to get good word level accuracy but when using this in a business context one other key metric is query level accuracy which is how often do you get all the words in a query write and for some businesses word level accuracy is important but query level accuracy may be even more important and we've now taken one step away from the objective that the learning algorithm is almost directly optimizing even after you get the query right which is important for the user experience what users care even more about is the search result\", metadata={'source': 'CEBwVqRdKWc', 'title': '#39 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 15]', 'description': 'Unknown', 'view_count': 3170, 'thumbnail_url': 'https://i.ytimg.com/vi/CEBwVqRdKWc/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgXihGMA8=&rs=AOn4CLCDEeeWvtZuj-r0hTx0O4nAfw5x2w', 'publish_date': '2022-04-20 00:00:00', 'length': 445, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"optimizing even after you get the query right which is important for the user experience what users care even more about is the search result quality and the reason the business may want to ensure search result quality is that this gives users a better experience and just increases user engagement so they come back to the search engine more often and this is important but this is just one step towards actually driving the revenue of the business one gap i've often seen between machine learning teams and business teams is the engineering team will usually want to work on this whereas the business leader may want promises on that and in order for a project to move forward i usually try to have the technical and the business teams try to agree on metrics that both are comfortable with this often takes a little bit of compromise where the machine learning team might stretch a little bit further to the right and the business teams stretch a little bit further to the left and the further we go to the right the harder it is for a machine learning team to really give a guarantee and i wish more problems could be solved by grading the sense or by optimizing test set accuracy but that's just not the state of the world today a lot of practical problems require we do something more than just optimizing test and accuracy so having the technical team and the business teams both step a little bit outside their comfort zone is often important for reaching compromise to pick some set of\", metadata={'source': 'CEBwVqRdKWc', 'title': '#39 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 15]', 'description': 'Unknown', 'view_count': 3170, 'thumbnail_url': 'https://i.ytimg.com/vi/CEBwVqRdKWc/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgXihGMA8=&rs=AOn4CLCDEeeWvtZuj-r0hTx0O4nAfw5x2w', 'publish_date': '2022-04-20 00:00:00', 'length': 445, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"team and the business teams both step a little bit outside their comfort zone is often important for reaching compromise to pick some set of metrics that the technical team feels like could stretch a bit to deliver on and that the business team can stretch a bit to feel comfortable will create sufficient value for the business one other practice i've found useful is that if you can do even very rough back of the envelope calculations to relate word level accuracy to some of the metrics on the right so if word level accuracy improves by one percent if you have any rough guess for will that improve query level accuracy maybe by 0.7 percent or 0.8 percent and how much will that improve search result quality and user engagement and maybe revenue if you're able to come up with even a very crude back of the envelope calculation sometimes these are also called fermi estimates you can read about this on wikipedia that can also be a way to help bridge the machine learning engineering metrics and the business metrics now it goes without saying that as part of estimating the value of a project i would encourage you to give thought to any ethical considerations as well such as is this project creating net positive societal value and if not i hope you won't do it or is this project reasonably fair and free from bias and have any ethical or values based concerns being openly aired and debated i find that issues of values and ethics is very domain dependent is very different in making\", metadata={'source': 'CEBwVqRdKWc', 'title': '#39 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 15]', 'description': 'Unknown', 'view_count': 3170, 'thumbnail_url': 'https://i.ytimg.com/vi/CEBwVqRdKWc/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgXihGMA8=&rs=AOn4CLCDEeeWvtZuj-r0hTx0O4nAfw5x2w', 'publish_date': '2022-04-20 00:00:00', 'length': 445, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"or values based concerns being openly aired and debated i find that issues of values and ethics is very domain dependent is very different in making loans versus healthcare versus recommending products online so i encourage you to look up any ethical frameworks that have been developed for your industry and your application and if you have any concerns raise it for debates within your team ultimately if you don't think the project you're working on will help other people or will help humanity move forward i hope you keep searching for other more meaningful projects to jump into in my work i have faced difficult choices where i really wasn't sure if a particular project was something i should work on because i really didn't know if it would make people net net better off and i found that having a team debate and discuss it openly often helps us get to a better answer and feel more comfortable with whatever decision we make and i have killed multiple projects on ethical considerations when i felt the project was economically sound but i didn't think it would help people and i just told the team i don't want to do it and i won't do it so i hope this gives you a framework for evaluating the value of a project and on the ethics and value piece i think all of us collectively should only work on projects that create net positive social value that help other people that move humanity forward i personally kill projects just on that basis there are multiple projects that i felt the\", metadata={'source': 'CEBwVqRdKWc', 'title': '#39 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 15]', 'description': 'Unknown', 'view_count': 3170, 'thumbnail_url': 'https://i.ytimg.com/vi/CEBwVqRdKWc/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgXihGMA8=&rs=AOn4CLCDEeeWvtZuj-r0hTx0O4nAfw5x2w', 'publish_date': '2022-04-20 00:00:00', 'length': 445, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"value that help other people that move humanity forward i personally kill projects just on that basis there are multiple projects that i felt the economic value was completely sound the economic case was completely fine but i looked at the project and i said i don't think this actually helps people and i've killed projects just on that basis and told my teams let's find something else to work on because i'm not going to do that so i hope that you also be able to focus your efforts just on projects that help people and that help move humanity forward\", metadata={'source': 'CEBwVqRdKWc', 'title': '#39 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 15]', 'description': 'Unknown', 'view_count': 3170, 'thumbnail_url': 'https://i.ytimg.com/vi/CEBwVqRdKWc/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgXihGMA8=&rs=AOn4CLCDEeeWvtZuj-r0hTx0O4nAfw5x2w', 'publish_date': '2022-04-20 00:00:00', 'length': 445, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"say you've identified the problem found a worthy solution finished diligence for technical feasibility and value and you think this is worth doing let's take a look at the last steps of the scoping process of milestones and resourcing determining milestones and resourcing involves writing out the key specifications for your project this will include machine learning metrics such as accuracy or precision recall for some applications this may also include fairness types of metrics the specification will often also include software metrics regarding the software system such as latency throughput queries per second and so on given the computational resources available and if possible you might also write out estimates of the business metrics you hope to move for the project you're scoping such as how much incremental revenue if you have a way of estimating that in addition writing out the resources needed how much data from which teams personnel any help you need from cross-functional teams what software integrations data labeling support or other support you need from other teams and finally the timeline [Music] on which you hope to achieve certain milestones or deliverables now if you're looking at a machine learning project and you find that you're having a very hard time writing on some of these key specifications then you might also consider carrying out a benchmarking exercise to compare it to other similar projects that others may have worked on before or building a proof\", metadata={'source': '9p7WWapTrpA', 'title': '#40 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 16]', 'description': 'Unknown', 'view_count': 4621, 'thumbnail_url': 'https://i.ytimg.com/vi/9p7WWapTrpA/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVihBMA8=&rs=AOn4CLCLlzY9Gv22eYV77m6hHBLmBtxWHA', 'publish_date': '2022-04-20 00:00:00', 'length': 155, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"also consider carrying out a benchmarking exercise to compare it to other similar projects that others may have worked on before or building a proof of concept first in order to get a better sense of what accuracy precision or latency throughput or other metrics might be feasible and only after you've done that plc proof of concept to then use that information to more confidently scope out the milestones and resources needed for a larger scale execution of the project you have in mind so that's it congratulations on making it to the end of this section on scoping i hope that these ideas will help you to pick valuable and meaningful projects to work on and thank you also for sticking with me from deployment through modeling through training all the way back to scoping and i hope this framework of the full cycle of machine learning project will also be useful for all the projects i hope you will build and deploy\", metadata={'source': '9p7WWapTrpA', 'title': '#40 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 16]', 'description': 'Unknown', 'view_count': 4621, 'thumbnail_url': 'https://i.ytimg.com/vi/9p7WWapTrpA/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVihBMA8=&rs=AOn4CLCLlzY9Gv22eYV77m6hHBLmBtxWHA', 'publish_date': '2022-04-20 00:00:00', 'length': 155, 'author': 'DeepLearningAI'})]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# class Embedding:\n",
        "#     def embed_documents(self, texts):\n",
        "#         response = requests.post(embedding_api_url, headers=headers, json={\"inputs\": texts, \"options\":{\"wait_for_model\":True}})\n",
        "#         self.embed_query = f\"Context: {texts}\"\n",
        "#         return response.json()"
      ],
      "metadata": {
        "id": "UjdWeLUOEO6z"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain.vectorstores import FAISS\n",
        "# from langchain.vectorstores import Chroma\n",
        "# from langchain.vectorstores import DocArrayInMemorySearch\n",
        "from langchain.vectorstores import Qdrant\n",
        "from langchain.embeddings import HuggingFaceEmbeddings"
      ],
      "metadata": {
        "id": "sCO7oBnLBY25"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# embedding = Embedding()"
      ],
      "metadata": {
        "id": "YWcP96fUEYyv"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "\n",
        "embeddings = HuggingFaceEmbeddings(model_name=embeddings_model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465,
          "referenced_widgets": [
            "9f7db084984e4745b29bfe8bc6f714d1",
            "26f81f45b2384d6aa15f56d5df68d69b",
            "d157c22ad6514f54924f301733c06725",
            "1f3ffc522eaf4803aa71e2a1fd1d0589",
            "49a26fc6e3c74287a1925c31bc8cd276",
            "14a53a75203946a9b674f84b8053368c",
            "d8f24e2d1d7848bebe931387c9f780db",
            "69b304eb65c442e3a1de937c7b79af69",
            "7781919818c744ee9fb336953b3308c0",
            "d8b9c5dc2e7b4262b1d58d320be9206e",
            "d87e9e505417474a9aaedf9c509e56d9",
            "c9044e293b424b339d04713490485280",
            "02c800204a2241f29a38a11f2998d405",
            "a7d20fe341e84d9b81561dcf9f09247d",
            "8f85803ee41347bea3a79a819ad02533",
            "c900ba972153439a84952e652425f693",
            "be41d4df00fe4e609b8beffa2960fb31",
            "859a89840d8b4f8b890a11d27268b3dc",
            "d7dbac47037a42deb9125290295ea4e0",
            "fc966b38749446c4b45be36e0a6cbcbe",
            "5e46e4dfa6f540b48fb4bba179a3b83f",
            "17cc0ce0cc2540baa767930ec8901d48",
            "ce927dedc3784ef79edb1efe88f2f315",
            "7fdb9da053ee4d30b1a23d601efd2d46",
            "d4061583486540a1805936e2fabacc29",
            "13bbe06b917d43ceae884ce6d4b614c2",
            "00c0c64d2eb14204b13825bcf1ee4426",
            "9194bf880ddc4c4aab86196de8572d99",
            "0dd97f7e5ac0458ab1d0f9c93ff0df2f",
            "487940b6b58e4096b22c8e2c52fad127",
            "9a1e22dce1d84b808a5569a6ff3e162c",
            "94f63639f0b64b78bac435389a2351b4",
            "a89654e1a04948f19f1b3cf06064263c",
            "914a11ae7f4f44b4949691a6b6347c69",
            "b24858c516e84096830a684fabcee56e",
            "ce65ce5ccc6a478dbc4e21cca1f61566",
            "32df813418c34e7ebe226b570d38b3ca",
            "4a3bd8e525d848129ceabd57af7827ff",
            "140dccedda1744feae98f84a0b902a0e",
            "fc2302b037fc4382bbc66d12f6735a02",
            "3f864398f47740999996e79d97141747",
            "120fffc9ed3a4ce09a142fe04da4d6cd",
            "ed3cbfaf69cc4bfabf7a5500388ebee3",
            "9d51cd5ab391458daf7bb49b9202ff25",
            "0014459f3fab42fbae42895620610e86",
            "d76c905bf34947e18c42df6677076c50",
            "3573409971834f629bc42041191e59e8",
            "a0582a35e7e244d1b87e317a986b4475",
            "cc354f550a9a4d57a12870da609ad92b",
            "b89f993d3f62486c80bfb6cd4e671a62",
            "0c2d1167cfc943e5ba69ca739beeccf6",
            "889376b874774e0f9beee4054c38d8ed",
            "a0d5c7d28b2742c380b0c30d8752801a",
            "6440516d97ad46278bfcfee00ae69a95",
            "f086a89ceb384a8e8eb45e96f7c7c11a",
            "3dff52cd9ed94533bffd052481c61fd7",
            "0c0bf474f8c241d9a8ea15d4ece74126",
            "d20eb40635bb4b78ba55c2013e96f793",
            "6e9ca7792d124d72ac016be260ab15de",
            "4ad67fac9f5741e8b3a68fd020445bec",
            "b0f9038aa0da46e7b2758d63efd6990b",
            "0cccdaaaa88b4b38bbc9bdded60146fb",
            "da4aa8a092764790bc3eaa669f6c7e93",
            "e4d8e538e8ac4c39b10380055c73b287",
            "26bd2a6e163144bc8a28c479557c1b6b",
            "79e15e07252a4663a680f5628e74eeb3",
            "07d1b02404634670a88261286c66e9fb",
            "bb2ac6e8bef14b7f970fa2db65f1a0fa",
            "1c669e799e404621a26648bd81ef6f39",
            "f6e04add1228402ab3f1d03cb285a187",
            "bd3f700d9c644a65a79d6c382d0be0b7",
            "71af245e0f1243989861607a117299e0",
            "0b6cf28cd0134df2ac7a7be5d6bd843d",
            "c05e41ffb9b948ab9df2554a6c77e09a",
            "2520208fc4f24485ae1b12759848d873",
            "42984d199d804c4a854f25c88e097478",
            "52aea179e27a47b8b8547cdafa9cf710",
            "0678062ef85c4f71b9ea7f2a7eb56f31",
            "def285ca1bd345d9953d608f5d7fbb1c",
            "45fca412163b4fd2b4b72a8b1b32e31f",
            "782cb3d0112347c4b41f3d8f17ec5f7d",
            "4a8753cf0dfd4a13ab7cb4a0ef79c640",
            "ce68fee544bb4dd8a457783d74318db7",
            "6ac80dfa154e4cd69fbb1f255db58fa5",
            "09e7853b60c740a19aec6a7560f9fcbf",
            "5c37b8971f634ecc8cfd7a0aaa8fb3c8",
            "7b7f2715142340418b5fcd4f7c790cc4",
            "d74759dc3f554c1c81f3f01bfbe1e5ed",
            "39940632eb5840cbbedbcf63689198f8",
            "57d4fcccac7445e4ba23c84468d0aeaf",
            "22c7526b3163439a8535ba24b11cfcf2",
            "2fd07013f3794020aa8529c18c043a3f",
            "9ba9eb3f2cd34e51a5afe04bb31c62e6",
            "d13ecf88b7f64ed0b768a483d51fbc0f",
            "4538fd3e2ec64d6e970eec800bc15f96",
            "7c9299887b9146aaa3add2046485b4ff",
            "e0d9737516864f37ad097a8422976ab1",
            "2a4fb17e017d4d33926ec49f9b72dc97",
            "2eaa8fd35a5e4f7eac7bf570659cbb8f",
            "b0a0dd7a99d242fbbec43bd2a613d85e",
            "3409c1879b184349bf1ba1ec0d5e3389",
            "299e205e97b3409185709f738764fb01",
            "ad522e0f6f3f488ea1eab475dfcbd875",
            "b38f6cca15b84e489e0f8bc392ed2d16",
            "32d6c08b620a4530a062bfe74e514eb6",
            "1ffec70132884252b2725994c13cc9f0",
            "27b00fe995284f94aca6e8c03521464d",
            "a3a7594179c74a8fa1f8768dbcd8be10",
            "d50be17fbf164f90aef513045dea79ae",
            "94e43161ce4246d781fe6242dfa27a48",
            "b5b7f5f01df243238f66d6a14bb189fe",
            "1526aea4a0da43c5851d3c7047a62e25",
            "f262ddefebfc42b695635712a8a315be",
            "4304be32ba42451a96bb775ea9270876",
            "356be72340eb4d45a8d70546a29e72a3",
            "b8583dce617e4a6c8dc78de04b4e653a",
            "d2456b9aaa1040d296a442fc766d21a0",
            "a0e0b7b4905a427e9e50aeca5c00d987",
            "5aa85ab0f9174fc7bd63c9b3bf40230c",
            "a45d1a35434a4476a3e6d6f2a131ce0d",
            "30ffc3520a634f519c0c42b374f0a9f0",
            "73af498410a240e38c5f7fbe770841d0",
            "160eed4db475439384699fe136637fe6",
            "0a7e64e07ca441c89e396a73fae8d2d7",
            "9dbfbc3499204647946f649eb9814897",
            "e35eb948a98846b492ea4727a570cccd",
            "98d3f7b057254b0f8bf9ba74f429856a",
            "344f78e838bf4d3998093ec9a1d8b665",
            "415b9e9f86fc42daafc5b3389a16c329",
            "39586497488c49c38bc8cf6422b3ef26",
            "f143ad1fce284071a77b390049d3c44d",
            "28ea193c050e4ff0a3e49898ee32f997",
            "6d30b2b5a14d4e85854a47ce770d285a",
            "c6f0a4d5134642cfb863eadb6bdf1391",
            "30027b80ae73432d82406560608215a9",
            "eb0512534a72443881b62c2bab2537d8",
            "39f4cb484eed4418965f45cb5487d954",
            "0d00f64c3bd14befb0207351a29a6ddd",
            "c02ed5c64e734015a42d46438d75e3ad",
            "854a63ffffae41c28585260a7e47fc99",
            "6a0a3b9c530747528132e45dbe766311",
            "b3c624795e924f94b3ee097a31a9fc3f",
            "931ae813e42b46e7a2def789f36cc420",
            "98358893f60e436181c663d4477f3cf3",
            "a05050d8788e45fa96eba1fc4ab6e29f",
            "84a8fb46e04640549d3cbcf4a803fdbd",
            "23461ddeb6d14ccda33a59addaaa2044",
            "edc376b5bf8640798909b25f8c7cea73",
            "e42e1aac7d2b470ca1c2e3ceee91fc6c",
            "20bb034f8cc943ef8250ffa263ff135c",
            "3d8ae784f6fa453898203229447da3ee",
            "c09ce8ff99794409ad6d3ad9921c0fb6",
            "b1818f84179a4afb9bee7539fd11789e",
            "5725e0e195c24832aee8379e3d853834"
          ]
        },
        "id": "uVR4XS2Ykr97",
        "outputId": "85cc2b08-92e1-4b5a-fbef-c7a6a3e344f9"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)e9125/.gitattributes:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9f7db084984e4745b29bfe8bc6f714d1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c9044e293b424b339d04713490485280"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)7e55de9125/README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ce927dedc3784ef79edb1efe88f2f315"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)55de9125/config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "914a11ae7f4f44b4949691a6b6347c69"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)ce_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0014459f3fab42fbae42895620610e86"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)125/data_config.json:   0%|          | 0.00/39.3k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3dff52cd9ed94533bffd052481c61fd7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "07d1b02404634670a88261286c66e9fb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0678062ef85c4f71b9ea7f2a7eb56f31"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "39940632eb5840cbbedbcf63689198f8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)e9125/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b0a0dd7a99d242fbbec43bd2a613d85e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b5b7f5f01df243238f66d6a14bb189fe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)9125/train_script.py:   0%|          | 0.00/13.2k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "73af498410a240e38c5f7fbe770841d0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)7e55de9125/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6d30b2b5a14d4e85854a47ce770d285a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)5de9125/modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "98358893f60e436181c663d4477f3cf3"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# vectordb = FAISS.from_documents(splits, embeddings)\n",
        "# To use self query retriever use Chroma/Qdrant vector store which is supported\n",
        "# vectordb = Chroma.from_documents(splits, embeddings)\n",
        "# vectordb = DocArrayInMemorySearch.from_documents(splits, embeddings)\n",
        "vectordb = Qdrant.from_documents(splits,\n",
        "                                 embeddings,\n",
        "                                 location=\":memory:\",\n",
        "                                 collection_name=\"youtube\")"
      ],
      "metadata": {
        "id": "E7K9JFiaD6PZ"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectordb.similarity_search(\"hello\", k=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMTlHlD4EDT4",
        "outputId": "78644f24-8a9d-4b66-fdc5-54ab06e7250c"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content=\"also look forward to seeing you in next week's videos where we'll dive together much more deeply into the modeling part of the full cycle of machine learning project i look forward to seeing you next week\", metadata={'source': '79UqdjnPEZ0', 'title': '#8 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 1, Lesson 8]', 'description': 'Unknown', 'view_count': 7758, 'thumbnail_url': 'https://i.ytimg.com/vi/79UqdjnPEZ0/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgXShFMA8=&rs=AOn4CLAqXCTKfEKzDr-1CVkNX7ytvQQxUA', 'publish_date': '2022-04-20 00:00:00', 'length': 572, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"in this week you learned about some best practices for building a machine learning model that is worthy of a production deployment one of my friends adam coats joked that the way he listened to me give advice to machine learning teams he felt the way i gave advice was quite consistent from project to project so that he could almost replace me with an if then else sequence of statements and i found too when several senior machine learning engineers look at the project the advice they tend to give is also remarkably consistent what you learned in this week is what are some of the key challenges of trying to build a production ready machine learning model things like how do you handle skewed data sets or what if you do well in the test set but for some reason that still isn't good enough for your actual application and i hope that after this week's materials you'll be able to very efficiently know how to improve your machine learning model to solve the most important problems that then make it deployment ready let's dive in this week our focus will be on the modeling part of the full cycle of a machine learning project and you learn some suggestions for how to select and train the model and how to perform error analysis and use that to drive model improvements one of the themes you hear me refer to multiple times is model centric ai development versus data centric ai development the way that ai has grown up there's been a lot of emphasis on how to choose the right model such as\", metadata={'source': 'lHXd2hBnlJk', 'title': '#9 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 2, Lesson 1]', 'description': 'Unknown', 'view_count': 5825, 'thumbnail_url': 'https://i.ytimg.com/vi/lHXd2hBnlJk/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgWyhCMA8=&rs=AOn4CLAFFQIYhlOu6kNiN2BZrc_RI1XamQ', 'publish_date': '2022-04-20 00:00:00', 'length': 161, 'author': 'DeepLearningAI'})]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use selfquery retriever and attribute info to include metadata info while searching alone with Maximum Marginal Relevance (MMR)"
      ],
      "metadata": {
        "id": "ZAp7mEzkFY8C"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
        "from langchain.chains.query_constructor.base import AttributeInfo"
      ],
      "metadata": {
        "id": "T2s9ZLOAnAJL"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metadata_field_info = [\n",
        "    AttributeInfo(\n",
        "        name=\"title\",\n",
        "        description=\"The title of the video and the topic the instructor is expalaining\",\n",
        "        type=\"string or list[string]\",\n",
        "    ),\n",
        "    AttributeInfo(\n",
        "        name=\"view_count\",\n",
        "        description=\"The amount of views the content has got till date\",\n",
        "        type=\"integer\",\n",
        "    ),\n",
        "    AttributeInfo(\n",
        "        name=\"publish_date\",\n",
        "        description=\"The date on which the content was published online by the instructor\",\n",
        "        type=\"datetime\"\n",
        "    )\n",
        "]"
      ],
      "metadata": {
        "id": "VP7-wJx1ndjm"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document_content_description = \"Lectures of Machine Learning Operations for production level machine learning model deployment\"\n",
        "retriever = SelfQueryRetriever.from_llm(\n",
        "    flan_t5, vectordb, document_content_description, metadata_field_info, verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "GooGidbxoQfp"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# retriever.get_relevant_documents(\"What is machine learning\")"
      ],
      "metadata": {
        "id": "AMA8rgE0owsR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.memory import ConversationBufferMemory"
      ],
      "metadata": {
        "id": "CIy-rNgTwfGw"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AnswerConversationBufferMemory(ConversationBufferMemory):\n",
        "    def save_context(self, inputs, outputs) -> None:\n",
        "        return super(AnswerConversationBufferMemory, self).save_context(inputs,{'response': outputs['answer']})"
      ],
      "metadata": {
        "id": "ndWTt_a3185U"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "memory = AnswerConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)"
      ],
      "metadata": {
        "id": "xwshgVgC2Uy-"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa = ConversationalRetrievalChain.from_llm(flan_t5,\n",
        "                                           vectordb.as_retriever(search_type=\"mmr\", k=1),\n",
        "                                           memory=memory,\n",
        "                                           return_source_documents=True)"
      ],
      "metadata": {
        "id": "kgbmdUkYyABA"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is ML Ops\"\n",
        "result = qa({\"question\": query})"
      ],
      "metadata": {
        "id": "XXgSPSosyKBy"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result[\"answer\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "h2QKW1F8yNw5",
        "outputId": "335462be-9226-4084-8ff4-d050a211c258"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'an emerging discipline that comprises a set of tools and principles to support progress through the machine learning'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result[\"source_documents\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOdzbAcI1JIh",
        "outputId": "c14c572c-76c5-43a3-9cba-1c16f6002ee4"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content=\"i've learned on how to define effective machine learning projects throughout this course you also learn about ml ops or machine learning operations which is an emerging discipline that comprises a set of tools and principles to support progress through the machine learning project life cycle but especially these three steps for example at landing ai where on co we used to do a lot of these steps manually which is okay but slow but after building an emma ops 2 called landing lens for computer vision applications all these steps became much quicker the key idea in ml ops is that systematic ways to think about scoping data modeling and deployment and also software tools to support the best practices so that's it in this course we're going to start at the end goal start from deployment and then work our way backwards as you already know being the deploy a system is one of the most important and valuable skills in machine learning today so let's go on to the next video where we'll dive deep into the most important lessons most important ideas needed to deploy machine learning systems i will see you in the next video\", metadata={'source': '1zhmudvZAs4', 'title': '#4 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 1, Lesson 4]', 'description': 'Unknown', 'view_count': 10354, 'thumbnail_url': 'https://i.ytimg.com/vi/1zhmudvZAs4/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgVSg_MA8=&rs=AOn4CLCjx3M4zOGG3DUM828U49cMKTa7eA', 'publish_date': '2022-04-20 00:00:00', 'length': 163, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"of software is needed to execute this emma ops tools can help with implementing these deployment patterns or you can implement it yourself one of the most useful frameworks i have found for thinking about how to deploy a system is to think about deployment not as a zero one is either deploy or not deploy but instead to design a system thinking about what is the appropriate degree of automation for example in visual inspection of smartphones one extreme would be if there's no automation so the human only system slightly more automated would be if your system is running in shadow mode so your learning albums are putting predictions but it's not actually used in the factory so that would be shadow mode a slightly greater degree of automation would be ai assistance in which given a picture like this of a smartphone you may have a human inspector make the decision but maybe an ai system can affect the user interface to highlight the regions where there's a scratch to help draw the person's attention to where it may be most useful for them to look the user interface or ui design is critical for human assistance but this could be a way to get a slightly greater degree of automation while still keeping the human in the loop an even greater degree of automation may be partial automation where given a smartphone if the learning algorithm is sure it's fine then that's his decision if it's sure it's defective then we just go with the ai already's decision but if the learning algorithm\", metadata={'source': 'ErNp43wcudY', 'title': '#6 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 1, Lesson 6]', 'description': 'Unknown', 'view_count': 9615, 'thumbnail_url': 'https://i.ytimg.com/vi/ErNp43wcudY/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgWShCMA8=&rs=AOn4CLDXpx65XXcQdGXgUMnu_TmwnkBCTQ', 'publish_date': '2022-04-20 00:00:00', 'length': 713, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"for some applications having and tracking metadata data provenance and data lineage can be a big help what do these words even mean let's look at an example here's a more complex example of a data pipeline building on our previous example of using user records to predict if someone is looking for a job at a given moment in time let's say you start off with a spam data set this may include a list of known spam accounts as well as features such as a list of blacklisted ip addresses that spammers are known to use you might also implement a learning algorithm so piece of machine learning code and train your learning algorithm on the spam data set thus giving you an anti-spam model so these arrows indicate flow of information or flow of computation where training your ml code on the spam data set gives you your anti-spam model you then take your user data and apply the anti-spam model to it to get the dspam user data we're following our usual convention that things with a purple rectangle around it represent pieces of code now taking your dspam user data next you might want to carry out user id merge to do that you might start off with some id merge data so this would be labeled data telling you some pairs of accounts that actually correspond to the same person have a machine learning album implementation train the model on that and this gives you a learned id merge model that tells you when to combine two accounts into a single user id you take your id merge model apply it to the\", metadata={'source': 'hbqxEJisBHo', 'title': '#34 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 10]', 'description': 'Unknown', 'view_count': 2310, 'thumbnail_url': 'https://i.ytimg.com/vi/hbqxEJisBHo/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVyhAMA8=&rs=AOn4CLCJpo607K9yg245bw2Kl1ounjm_Vw', 'publish_date': '2022-04-20 00:00:00', 'length': 596, 'author': 'DeepLearningAI'}),\n",
              " Document(page_content=\"will help you to get better data for your machine learning tools one of the gaps i see in the machine learning world today is that there's still a lack of tools and ml also machine learning ops tools for helping teams to carry out this type of process more consistently and repeatedly so it's not you know us trying to figure this out in a jupiter notebook but instead to have tools help us to detect when labels are consistent and to help facilitate the process in improving the quality of the data so this is something i look forward to hopefully our community working on and developing in terms of improving label quality one of the questions that often comes up is what is human level performance on a task i find human level performance be important and sometimes misused concept let's take a deeper look at this in the next video\", metadata={'source': 'a-oCxdzFapE', 'title': '#29 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 5]', 'description': 'Unknown', 'view_count': 2464, 'thumbnail_url': 'https://i.ytimg.com/vi/a-oCxdzFapE/hqdefault.jpg?sqp=-oaymwExCJADEOABSFryq4qpAyMIARUAAIhCGAHwAQH4Af4JgALQBYoCDAgAEAEYRSBLKGUwDw==&rs=AOn4CLCEhc2Z01CiZrw15lDpnTCR1-D7ug', 'publish_date': '2022-04-20 00:00:00', 'length': 549, 'author': 'DeepLearningAI'})]"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0k8gAEBE1LNT",
        "outputId": "e916dfab-641a-412d-e4f6-cdf464bd202b"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': 'What is ML Ops',\n",
              " 'chat_history': [HumanMessage(content='What is ML Ops', additional_kwargs={}, example=False),\n",
              "  AIMessage(content='a set of tools and principles to support progress through the machine learning project life cycle', additional_kwargs={}, example=False),\n",
              "  HumanMessage(content='What is ML Ops', additional_kwargs={}, example=False),\n",
              "  AIMessage(content='an emerging discipline that comprises a set of tools and principles to support progress through the machine learning', additional_kwargs={}, example=False)],\n",
              " 'answer': 'an emerging discipline that comprises a set of tools and principles to support progress through the machine learning',\n",
              " 'source_documents': [Document(page_content=\"i've learned on how to define effective machine learning projects throughout this course you also learn about ml ops or machine learning operations which is an emerging discipline that comprises a set of tools and principles to support progress through the machine learning project life cycle but especially these three steps for example at landing ai where on co we used to do a lot of these steps manually which is okay but slow but after building an emma ops 2 called landing lens for computer vision applications all these steps became much quicker the key idea in ml ops is that systematic ways to think about scoping data modeling and deployment and also software tools to support the best practices so that's it in this course we're going to start at the end goal start from deployment and then work our way backwards as you already know being the deploy a system is one of the most important and valuable skills in machine learning today so let's go on to the next video where we'll dive deep into the most important lessons most important ideas needed to deploy machine learning systems i will see you in the next video\", metadata={'source': '1zhmudvZAs4', 'title': '#4 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 1, Lesson 4]', 'description': 'Unknown', 'view_count': 10354, 'thumbnail_url': 'https://i.ytimg.com/vi/1zhmudvZAs4/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGHIgVSg_MA8=&rs=AOn4CLCjx3M4zOGG3DUM828U49cMKTa7eA', 'publish_date': '2022-04-20 00:00:00', 'length': 163, 'author': 'DeepLearningAI'}),\n",
              "  Document(page_content=\"of software is needed to execute this emma ops tools can help with implementing these deployment patterns or you can implement it yourself one of the most useful frameworks i have found for thinking about how to deploy a system is to think about deployment not as a zero one is either deploy or not deploy but instead to design a system thinking about what is the appropriate degree of automation for example in visual inspection of smartphones one extreme would be if there's no automation so the human only system slightly more automated would be if your system is running in shadow mode so your learning albums are putting predictions but it's not actually used in the factory so that would be shadow mode a slightly greater degree of automation would be ai assistance in which given a picture like this of a smartphone you may have a human inspector make the decision but maybe an ai system can affect the user interface to highlight the regions where there's a scratch to help draw the person's attention to where it may be most useful for them to look the user interface or ui design is critical for human assistance but this could be a way to get a slightly greater degree of automation while still keeping the human in the loop an even greater degree of automation may be partial automation where given a smartphone if the learning algorithm is sure it's fine then that's his decision if it's sure it's defective then we just go with the ai already's decision but if the learning algorithm\", metadata={'source': 'ErNp43wcudY', 'title': '#6 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 1, Lesson 6]', 'description': 'Unknown', 'view_count': 9615, 'thumbnail_url': 'https://i.ytimg.com/vi/ErNp43wcudY/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgWShCMA8=&rs=AOn4CLDXpx65XXcQdGXgUMnu_TmwnkBCTQ', 'publish_date': '2022-04-20 00:00:00', 'length': 713, 'author': 'DeepLearningAI'}),\n",
              "  Document(page_content=\"for some applications having and tracking metadata data provenance and data lineage can be a big help what do these words even mean let's look at an example here's a more complex example of a data pipeline building on our previous example of using user records to predict if someone is looking for a job at a given moment in time let's say you start off with a spam data set this may include a list of known spam accounts as well as features such as a list of blacklisted ip addresses that spammers are known to use you might also implement a learning algorithm so piece of machine learning code and train your learning algorithm on the spam data set thus giving you an anti-spam model so these arrows indicate flow of information or flow of computation where training your ml code on the spam data set gives you your anti-spam model you then take your user data and apply the anti-spam model to it to get the dspam user data we're following our usual convention that things with a purple rectangle around it represent pieces of code now taking your dspam user data next you might want to carry out user id merge to do that you might start off with some id merge data so this would be labeled data telling you some pairs of accounts that actually correspond to the same person have a machine learning album implementation train the model on that and this gives you a learned id merge model that tells you when to combine two accounts into a single user id you take your id merge model apply it to the\", metadata={'source': 'hbqxEJisBHo', 'title': '#34 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 10]', 'description': 'Unknown', 'view_count': 2310, 'thumbnail_url': 'https://i.ytimg.com/vi/hbqxEJisBHo/hq720.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGGUgVyhAMA8=&rs=AOn4CLCJpo607K9yg245bw2Kl1ounjm_Vw', 'publish_date': '2022-04-20 00:00:00', 'length': 596, 'author': 'DeepLearningAI'}),\n",
              "  Document(page_content=\"will help you to get better data for your machine learning tools one of the gaps i see in the machine learning world today is that there's still a lack of tools and ml also machine learning ops tools for helping teams to carry out this type of process more consistently and repeatedly so it's not you know us trying to figure this out in a jupiter notebook but instead to have tools help us to detect when labels are consistent and to help facilitate the process in improving the quality of the data so this is something i look forward to hopefully our community working on and developing in terms of improving label quality one of the questions that often comes up is what is human level performance on a task i find human level performance be important and sometimes misused concept let's take a deeper look at this in the next video\", metadata={'source': 'a-oCxdzFapE', 'title': '#29 Machine Learning Engineering for Production (MLOps) Specialization [Course 1, Week 3, Lesson 5]', 'description': 'Unknown', 'view_count': 2464, 'thumbnail_url': 'https://i.ytimg.com/vi/a-oCxdzFapE/hqdefault.jpg?sqp=-oaymwExCJADEOABSFryq4qpAyMIARUAAIhCGAHwAQH4Af4JgALQBYoCDAgAEAEYRSBLKGUwDw==&rs=AOn4CLCEhc2Z01CiZrw15lDpnTCR1-D7ug', 'publish_date': '2022-04-20 00:00:00', 'length': 549, 'author': 'DeepLearningAI'})]}"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iqKQiqVw4sPC"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9f7db084984e4745b29bfe8bc6f714d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_26f81f45b2384d6aa15f56d5df68d69b",
              "IPY_MODEL_d157c22ad6514f54924f301733c06725",
              "IPY_MODEL_1f3ffc522eaf4803aa71e2a1fd1d0589"
            ],
            "layout": "IPY_MODEL_49a26fc6e3c74287a1925c31bc8cd276"
          }
        },
        "26f81f45b2384d6aa15f56d5df68d69b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14a53a75203946a9b674f84b8053368c",
            "placeholder": "​",
            "style": "IPY_MODEL_d8f24e2d1d7848bebe931387c9f780db",
            "value": "Downloading (…)e9125/.gitattributes: 100%"
          }
        },
        "d157c22ad6514f54924f301733c06725": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69b304eb65c442e3a1de937c7b79af69",
            "max": 1175,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7781919818c744ee9fb336953b3308c0",
            "value": 1175
          }
        },
        "1f3ffc522eaf4803aa71e2a1fd1d0589": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8b9c5dc2e7b4262b1d58d320be9206e",
            "placeholder": "​",
            "style": "IPY_MODEL_d87e9e505417474a9aaedf9c509e56d9",
            "value": " 1.18k/1.18k [00:00&lt;00:00, 79.5kB/s]"
          }
        },
        "49a26fc6e3c74287a1925c31bc8cd276": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14a53a75203946a9b674f84b8053368c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8f24e2d1d7848bebe931387c9f780db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "69b304eb65c442e3a1de937c7b79af69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7781919818c744ee9fb336953b3308c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d8b9c5dc2e7b4262b1d58d320be9206e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d87e9e505417474a9aaedf9c509e56d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9044e293b424b339d04713490485280": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_02c800204a2241f29a38a11f2998d405",
              "IPY_MODEL_a7d20fe341e84d9b81561dcf9f09247d",
              "IPY_MODEL_8f85803ee41347bea3a79a819ad02533"
            ],
            "layout": "IPY_MODEL_c900ba972153439a84952e652425f693"
          }
        },
        "02c800204a2241f29a38a11f2998d405": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be41d4df00fe4e609b8beffa2960fb31",
            "placeholder": "​",
            "style": "IPY_MODEL_859a89840d8b4f8b890a11d27268b3dc",
            "value": "Downloading (…)_Pooling/config.json: 100%"
          }
        },
        "a7d20fe341e84d9b81561dcf9f09247d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7dbac47037a42deb9125290295ea4e0",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fc966b38749446c4b45be36e0a6cbcbe",
            "value": 190
          }
        },
        "8f85803ee41347bea3a79a819ad02533": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e46e4dfa6f540b48fb4bba179a3b83f",
            "placeholder": "​",
            "style": "IPY_MODEL_17cc0ce0cc2540baa767930ec8901d48",
            "value": " 190/190 [00:00&lt;00:00, 14.5kB/s]"
          }
        },
        "c900ba972153439a84952e652425f693": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be41d4df00fe4e609b8beffa2960fb31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "859a89840d8b4f8b890a11d27268b3dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7dbac47037a42deb9125290295ea4e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc966b38749446c4b45be36e0a6cbcbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5e46e4dfa6f540b48fb4bba179a3b83f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17cc0ce0cc2540baa767930ec8901d48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ce927dedc3784ef79edb1efe88f2f315": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7fdb9da053ee4d30b1a23d601efd2d46",
              "IPY_MODEL_d4061583486540a1805936e2fabacc29",
              "IPY_MODEL_13bbe06b917d43ceae884ce6d4b614c2"
            ],
            "layout": "IPY_MODEL_00c0c64d2eb14204b13825bcf1ee4426"
          }
        },
        "7fdb9da053ee4d30b1a23d601efd2d46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9194bf880ddc4c4aab86196de8572d99",
            "placeholder": "​",
            "style": "IPY_MODEL_0dd97f7e5ac0458ab1d0f9c93ff0df2f",
            "value": "Downloading (…)7e55de9125/README.md: 100%"
          }
        },
        "d4061583486540a1805936e2fabacc29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_487940b6b58e4096b22c8e2c52fad127",
            "max": 10610,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9a1e22dce1d84b808a5569a6ff3e162c",
            "value": 10610
          }
        },
        "13bbe06b917d43ceae884ce6d4b614c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94f63639f0b64b78bac435389a2351b4",
            "placeholder": "​",
            "style": "IPY_MODEL_a89654e1a04948f19f1b3cf06064263c",
            "value": " 10.6k/10.6k [00:00&lt;00:00, 698kB/s]"
          }
        },
        "00c0c64d2eb14204b13825bcf1ee4426": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9194bf880ddc4c4aab86196de8572d99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0dd97f7e5ac0458ab1d0f9c93ff0df2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "487940b6b58e4096b22c8e2c52fad127": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a1e22dce1d84b808a5569a6ff3e162c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "94f63639f0b64b78bac435389a2351b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a89654e1a04948f19f1b3cf06064263c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "914a11ae7f4f44b4949691a6b6347c69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b24858c516e84096830a684fabcee56e",
              "IPY_MODEL_ce65ce5ccc6a478dbc4e21cca1f61566",
              "IPY_MODEL_32df813418c34e7ebe226b570d38b3ca"
            ],
            "layout": "IPY_MODEL_4a3bd8e525d848129ceabd57af7827ff"
          }
        },
        "b24858c516e84096830a684fabcee56e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_140dccedda1744feae98f84a0b902a0e",
            "placeholder": "​",
            "style": "IPY_MODEL_fc2302b037fc4382bbc66d12f6735a02",
            "value": "Downloading (…)55de9125/config.json: 100%"
          }
        },
        "ce65ce5ccc6a478dbc4e21cca1f61566": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f864398f47740999996e79d97141747",
            "max": 612,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_120fffc9ed3a4ce09a142fe04da4d6cd",
            "value": 612
          }
        },
        "32df813418c34e7ebe226b570d38b3ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed3cbfaf69cc4bfabf7a5500388ebee3",
            "placeholder": "​",
            "style": "IPY_MODEL_9d51cd5ab391458daf7bb49b9202ff25",
            "value": " 612/612 [00:00&lt;00:00, 12.5kB/s]"
          }
        },
        "4a3bd8e525d848129ceabd57af7827ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "140dccedda1744feae98f84a0b902a0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc2302b037fc4382bbc66d12f6735a02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f864398f47740999996e79d97141747": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "120fffc9ed3a4ce09a142fe04da4d6cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ed3cbfaf69cc4bfabf7a5500388ebee3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d51cd5ab391458daf7bb49b9202ff25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0014459f3fab42fbae42895620610e86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d76c905bf34947e18c42df6677076c50",
              "IPY_MODEL_3573409971834f629bc42041191e59e8",
              "IPY_MODEL_a0582a35e7e244d1b87e317a986b4475"
            ],
            "layout": "IPY_MODEL_cc354f550a9a4d57a12870da609ad92b"
          }
        },
        "d76c905bf34947e18c42df6677076c50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b89f993d3f62486c80bfb6cd4e671a62",
            "placeholder": "​",
            "style": "IPY_MODEL_0c2d1167cfc943e5ba69ca739beeccf6",
            "value": "Downloading (…)ce_transformers.json: 100%"
          }
        },
        "3573409971834f629bc42041191e59e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_889376b874774e0f9beee4054c38d8ed",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a0d5c7d28b2742c380b0c30d8752801a",
            "value": 116
          }
        },
        "a0582a35e7e244d1b87e317a986b4475": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6440516d97ad46278bfcfee00ae69a95",
            "placeholder": "​",
            "style": "IPY_MODEL_f086a89ceb384a8e8eb45e96f7c7c11a",
            "value": " 116/116 [00:00&lt;00:00, 7.49kB/s]"
          }
        },
        "cc354f550a9a4d57a12870da609ad92b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b89f993d3f62486c80bfb6cd4e671a62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c2d1167cfc943e5ba69ca739beeccf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "889376b874774e0f9beee4054c38d8ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0d5c7d28b2742c380b0c30d8752801a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6440516d97ad46278bfcfee00ae69a95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f086a89ceb384a8e8eb45e96f7c7c11a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3dff52cd9ed94533bffd052481c61fd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0c0bf474f8c241d9a8ea15d4ece74126",
              "IPY_MODEL_d20eb40635bb4b78ba55c2013e96f793",
              "IPY_MODEL_6e9ca7792d124d72ac016be260ab15de"
            ],
            "layout": "IPY_MODEL_4ad67fac9f5741e8b3a68fd020445bec"
          }
        },
        "0c0bf474f8c241d9a8ea15d4ece74126": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0f9038aa0da46e7b2758d63efd6990b",
            "placeholder": "​",
            "style": "IPY_MODEL_0cccdaaaa88b4b38bbc9bdded60146fb",
            "value": "Downloading (…)125/data_config.json: 100%"
          }
        },
        "d20eb40635bb4b78ba55c2013e96f793": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da4aa8a092764790bc3eaa669f6c7e93",
            "max": 39265,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e4d8e538e8ac4c39b10380055c73b287",
            "value": 39265
          }
        },
        "6e9ca7792d124d72ac016be260ab15de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26bd2a6e163144bc8a28c479557c1b6b",
            "placeholder": "​",
            "style": "IPY_MODEL_79e15e07252a4663a680f5628e74eeb3",
            "value": " 39.3k/39.3k [00:00&lt;00:00, 637kB/s]"
          }
        },
        "4ad67fac9f5741e8b3a68fd020445bec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0f9038aa0da46e7b2758d63efd6990b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cccdaaaa88b4b38bbc9bdded60146fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da4aa8a092764790bc3eaa669f6c7e93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4d8e538e8ac4c39b10380055c73b287": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "26bd2a6e163144bc8a28c479557c1b6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79e15e07252a4663a680f5628e74eeb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "07d1b02404634670a88261286c66e9fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bb2ac6e8bef14b7f970fa2db65f1a0fa",
              "IPY_MODEL_1c669e799e404621a26648bd81ef6f39",
              "IPY_MODEL_f6e04add1228402ab3f1d03cb285a187"
            ],
            "layout": "IPY_MODEL_bd3f700d9c644a65a79d6c382d0be0b7"
          }
        },
        "bb2ac6e8bef14b7f970fa2db65f1a0fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71af245e0f1243989861607a117299e0",
            "placeholder": "​",
            "style": "IPY_MODEL_0b6cf28cd0134df2ac7a7be5d6bd843d",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "1c669e799e404621a26648bd81ef6f39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c05e41ffb9b948ab9df2554a6c77e09a",
            "max": 90888945,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2520208fc4f24485ae1b12759848d873",
            "value": 90888945
          }
        },
        "f6e04add1228402ab3f1d03cb285a187": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42984d199d804c4a854f25c88e097478",
            "placeholder": "​",
            "style": "IPY_MODEL_52aea179e27a47b8b8547cdafa9cf710",
            "value": " 90.9M/90.9M [00:00&lt;00:00, 288MB/s]"
          }
        },
        "bd3f700d9c644a65a79d6c382d0be0b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71af245e0f1243989861607a117299e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b6cf28cd0134df2ac7a7be5d6bd843d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c05e41ffb9b948ab9df2554a6c77e09a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2520208fc4f24485ae1b12759848d873": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "42984d199d804c4a854f25c88e097478": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52aea179e27a47b8b8547cdafa9cf710": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0678062ef85c4f71b9ea7f2a7eb56f31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_def285ca1bd345d9953d608f5d7fbb1c",
              "IPY_MODEL_45fca412163b4fd2b4b72a8b1b32e31f",
              "IPY_MODEL_782cb3d0112347c4b41f3d8f17ec5f7d"
            ],
            "layout": "IPY_MODEL_4a8753cf0dfd4a13ab7cb4a0ef79c640"
          }
        },
        "def285ca1bd345d9953d608f5d7fbb1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce68fee544bb4dd8a457783d74318db7",
            "placeholder": "​",
            "style": "IPY_MODEL_6ac80dfa154e4cd69fbb1f255db58fa5",
            "value": "Downloading (…)nce_bert_config.json: 100%"
          }
        },
        "45fca412163b4fd2b4b72a8b1b32e31f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09e7853b60c740a19aec6a7560f9fcbf",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5c37b8971f634ecc8cfd7a0aaa8fb3c8",
            "value": 53
          }
        },
        "782cb3d0112347c4b41f3d8f17ec5f7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b7f2715142340418b5fcd4f7c790cc4",
            "placeholder": "​",
            "style": "IPY_MODEL_d74759dc3f554c1c81f3f01bfbe1e5ed",
            "value": " 53.0/53.0 [00:00&lt;00:00, 2.82kB/s]"
          }
        },
        "4a8753cf0dfd4a13ab7cb4a0ef79c640": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce68fee544bb4dd8a457783d74318db7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ac80dfa154e4cd69fbb1f255db58fa5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "09e7853b60c740a19aec6a7560f9fcbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c37b8971f634ecc8cfd7a0aaa8fb3c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7b7f2715142340418b5fcd4f7c790cc4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d74759dc3f554c1c81f3f01bfbe1e5ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39940632eb5840cbbedbcf63689198f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_57d4fcccac7445e4ba23c84468d0aeaf",
              "IPY_MODEL_22c7526b3163439a8535ba24b11cfcf2",
              "IPY_MODEL_2fd07013f3794020aa8529c18c043a3f"
            ],
            "layout": "IPY_MODEL_9ba9eb3f2cd34e51a5afe04bb31c62e6"
          }
        },
        "57d4fcccac7445e4ba23c84468d0aeaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d13ecf88b7f64ed0b768a483d51fbc0f",
            "placeholder": "​",
            "style": "IPY_MODEL_4538fd3e2ec64d6e970eec800bc15f96",
            "value": "Downloading (…)cial_tokens_map.json: 100%"
          }
        },
        "22c7526b3163439a8535ba24b11cfcf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c9299887b9146aaa3add2046485b4ff",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e0d9737516864f37ad097a8422976ab1",
            "value": 112
          }
        },
        "2fd07013f3794020aa8529c18c043a3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a4fb17e017d4d33926ec49f9b72dc97",
            "placeholder": "​",
            "style": "IPY_MODEL_2eaa8fd35a5e4f7eac7bf570659cbb8f",
            "value": " 112/112 [00:00&lt;00:00, 8.24kB/s]"
          }
        },
        "9ba9eb3f2cd34e51a5afe04bb31c62e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d13ecf88b7f64ed0b768a483d51fbc0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4538fd3e2ec64d6e970eec800bc15f96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c9299887b9146aaa3add2046485b4ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0d9737516864f37ad097a8422976ab1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2a4fb17e017d4d33926ec49f9b72dc97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2eaa8fd35a5e4f7eac7bf570659cbb8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b0a0dd7a99d242fbbec43bd2a613d85e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3409c1879b184349bf1ba1ec0d5e3389",
              "IPY_MODEL_299e205e97b3409185709f738764fb01",
              "IPY_MODEL_ad522e0f6f3f488ea1eab475dfcbd875"
            ],
            "layout": "IPY_MODEL_b38f6cca15b84e489e0f8bc392ed2d16"
          }
        },
        "3409c1879b184349bf1ba1ec0d5e3389": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32d6c08b620a4530a062bfe74e514eb6",
            "placeholder": "​",
            "style": "IPY_MODEL_1ffec70132884252b2725994c13cc9f0",
            "value": "Downloading (…)e9125/tokenizer.json: 100%"
          }
        },
        "299e205e97b3409185709f738764fb01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27b00fe995284f94aca6e8c03521464d",
            "max": 466247,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a3a7594179c74a8fa1f8768dbcd8be10",
            "value": 466247
          }
        },
        "ad522e0f6f3f488ea1eab475dfcbd875": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d50be17fbf164f90aef513045dea79ae",
            "placeholder": "​",
            "style": "IPY_MODEL_94e43161ce4246d781fe6242dfa27a48",
            "value": " 466k/466k [00:00&lt;00:00, 3.57MB/s]"
          }
        },
        "b38f6cca15b84e489e0f8bc392ed2d16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32d6c08b620a4530a062bfe74e514eb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ffec70132884252b2725994c13cc9f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "27b00fe995284f94aca6e8c03521464d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3a7594179c74a8fa1f8768dbcd8be10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d50be17fbf164f90aef513045dea79ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94e43161ce4246d781fe6242dfa27a48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b5b7f5f01df243238f66d6a14bb189fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1526aea4a0da43c5851d3c7047a62e25",
              "IPY_MODEL_f262ddefebfc42b695635712a8a315be",
              "IPY_MODEL_4304be32ba42451a96bb775ea9270876"
            ],
            "layout": "IPY_MODEL_356be72340eb4d45a8d70546a29e72a3"
          }
        },
        "1526aea4a0da43c5851d3c7047a62e25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8583dce617e4a6c8dc78de04b4e653a",
            "placeholder": "​",
            "style": "IPY_MODEL_d2456b9aaa1040d296a442fc766d21a0",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "f262ddefebfc42b695635712a8a315be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0e0b7b4905a427e9e50aeca5c00d987",
            "max": 350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5aa85ab0f9174fc7bd63c9b3bf40230c",
            "value": 350
          }
        },
        "4304be32ba42451a96bb775ea9270876": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a45d1a35434a4476a3e6d6f2a131ce0d",
            "placeholder": "​",
            "style": "IPY_MODEL_30ffc3520a634f519c0c42b374f0a9f0",
            "value": " 350/350 [00:00&lt;00:00, 26.9kB/s]"
          }
        },
        "356be72340eb4d45a8d70546a29e72a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8583dce617e4a6c8dc78de04b4e653a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2456b9aaa1040d296a442fc766d21a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a0e0b7b4905a427e9e50aeca5c00d987": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5aa85ab0f9174fc7bd63c9b3bf40230c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a45d1a35434a4476a3e6d6f2a131ce0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30ffc3520a634f519c0c42b374f0a9f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "73af498410a240e38c5f7fbe770841d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_160eed4db475439384699fe136637fe6",
              "IPY_MODEL_0a7e64e07ca441c89e396a73fae8d2d7",
              "IPY_MODEL_9dbfbc3499204647946f649eb9814897"
            ],
            "layout": "IPY_MODEL_e35eb948a98846b492ea4727a570cccd"
          }
        },
        "160eed4db475439384699fe136637fe6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98d3f7b057254b0f8bf9ba74f429856a",
            "placeholder": "​",
            "style": "IPY_MODEL_344f78e838bf4d3998093ec9a1d8b665",
            "value": "Downloading (…)9125/train_script.py: 100%"
          }
        },
        "0a7e64e07ca441c89e396a73fae8d2d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_415b9e9f86fc42daafc5b3389a16c329",
            "max": 13156,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_39586497488c49c38bc8cf6422b3ef26",
            "value": 13156
          }
        },
        "9dbfbc3499204647946f649eb9814897": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f143ad1fce284071a77b390049d3c44d",
            "placeholder": "​",
            "style": "IPY_MODEL_28ea193c050e4ff0a3e49898ee32f997",
            "value": " 13.2k/13.2k [00:00&lt;00:00, 992kB/s]"
          }
        },
        "e35eb948a98846b492ea4727a570cccd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98d3f7b057254b0f8bf9ba74f429856a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "344f78e838bf4d3998093ec9a1d8b665": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "415b9e9f86fc42daafc5b3389a16c329": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39586497488c49c38bc8cf6422b3ef26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f143ad1fce284071a77b390049d3c44d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28ea193c050e4ff0a3e49898ee32f997": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d30b2b5a14d4e85854a47ce770d285a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c6f0a4d5134642cfb863eadb6bdf1391",
              "IPY_MODEL_30027b80ae73432d82406560608215a9",
              "IPY_MODEL_eb0512534a72443881b62c2bab2537d8"
            ],
            "layout": "IPY_MODEL_39f4cb484eed4418965f45cb5487d954"
          }
        },
        "c6f0a4d5134642cfb863eadb6bdf1391": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d00f64c3bd14befb0207351a29a6ddd",
            "placeholder": "​",
            "style": "IPY_MODEL_c02ed5c64e734015a42d46438d75e3ad",
            "value": "Downloading (…)7e55de9125/vocab.txt: 100%"
          }
        },
        "30027b80ae73432d82406560608215a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_854a63ffffae41c28585260a7e47fc99",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6a0a3b9c530747528132e45dbe766311",
            "value": 231508
          }
        },
        "eb0512534a72443881b62c2bab2537d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3c624795e924f94b3ee097a31a9fc3f",
            "placeholder": "​",
            "style": "IPY_MODEL_931ae813e42b46e7a2def789f36cc420",
            "value": " 232k/232k [00:00&lt;00:00, 1.85MB/s]"
          }
        },
        "39f4cb484eed4418965f45cb5487d954": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d00f64c3bd14befb0207351a29a6ddd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c02ed5c64e734015a42d46438d75e3ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "854a63ffffae41c28585260a7e47fc99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a0a3b9c530747528132e45dbe766311": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b3c624795e924f94b3ee097a31a9fc3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "931ae813e42b46e7a2def789f36cc420": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "98358893f60e436181c663d4477f3cf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a05050d8788e45fa96eba1fc4ab6e29f",
              "IPY_MODEL_84a8fb46e04640549d3cbcf4a803fdbd",
              "IPY_MODEL_23461ddeb6d14ccda33a59addaaa2044"
            ],
            "layout": "IPY_MODEL_edc376b5bf8640798909b25f8c7cea73"
          }
        },
        "a05050d8788e45fa96eba1fc4ab6e29f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e42e1aac7d2b470ca1c2e3ceee91fc6c",
            "placeholder": "​",
            "style": "IPY_MODEL_20bb034f8cc943ef8250ffa263ff135c",
            "value": "Downloading (…)5de9125/modules.json: 100%"
          }
        },
        "84a8fb46e04640549d3cbcf4a803fdbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d8ae784f6fa453898203229447da3ee",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c09ce8ff99794409ad6d3ad9921c0fb6",
            "value": 349
          }
        },
        "23461ddeb6d14ccda33a59addaaa2044": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1818f84179a4afb9bee7539fd11789e",
            "placeholder": "​",
            "style": "IPY_MODEL_5725e0e195c24832aee8379e3d853834",
            "value": " 349/349 [00:00&lt;00:00, 14.9kB/s]"
          }
        },
        "edc376b5bf8640798909b25f8c7cea73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e42e1aac7d2b470ca1c2e3ceee91fc6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20bb034f8cc943ef8250ffa263ff135c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d8ae784f6fa453898203229447da3ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c09ce8ff99794409ad6d3ad9921c0fb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b1818f84179a4afb9bee7539fd11789e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5725e0e195c24832aee8379e3d853834": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}